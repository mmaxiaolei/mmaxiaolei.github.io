<?xml version="1.0" encoding="utf-8"?>
<search>
  
    
    <entry>
      <title><![CDATA[mysql等数据库索引为什么偏爱b+tree]]></title>
      <url>%2F2018%2F03%2F30%2Fmysql-b-tree%2F</url>
      <content type="text"><![CDATA[背景类似mysql等数据库偏爱用b+tree这个数据结构作为索引，这是为什么呢？要解释这个原因，必须先讲下计算机组成原理中的磁盘数据存取原理。 磁盘数据读取原理这里指普通的机械磁盘。 先看下磁盘的结构: 如上图，磁盘由盘片构成,每个盘片有两面，又称为盘面(Surface)，这些盘面覆盖有磁性材料。盘片中央有一个可以旋转的主轴(spindle)，他使得盘片以固定的旋转速率旋转，通常是5400转每分钟(Revolution Per Minute,RPM)或者是7200RPM。磁盘包含多个这样的盘片并封装在一个密封的容器内。上图左，展示了一个典型的磁盘表面结构。每个表面是由一组称为磁道(track)的同心圆组成的，每个磁道被划分为了一组扇区(sector).每个扇区包含相等数量的数据位，通常是512子节。扇区之间由一些间隔(gap)隔开,不存储数据。 磁盘的读写操作： 如上图，磁盘用读/写头(磁头)来读写存储在磁性表面的位，而读写头连接到一个传动臂的一端。通过沿着半径轴前后移动传动臂，驱动器可以将读写头定位到任何磁道上，这称之为寻道操作。一旦定位到磁道后，盘片转动，磁道上的每个位经过磁头时，读写磁头就可以感知到位的值，也可以修改值。对磁盘的访问时间分为寻道时间，旋转时间，以及传送时间。 由于存储介质的特性，磁盘本身存取就比主存慢很多，再加上机械运动耗费，因此为了提高效率，要尽量减少磁盘I/O，减少读写操作。为了达到这个目的，磁盘往往不是严格按需读取，而是每次都会预读，即使只需要一个字节，磁盘也会从这个位置开始，顺序向后读取一定长度的数据放入内存。这样做的理论依据是计算机科学中著名的局部性原理： 当一个数据被用到时，其附近的数据也通常会马上被使用。 程序运行期间所需要的数据通常比较集中。 由于磁盘顺序读取的效率很高（不需要寻道时间，只需很少的旋转时间），因此对于具有局部性的程序来说，预读可以提高I/O效率。 预读的长度一般为页（page）的整倍数。页是计算机管理存储器的逻辑块，硬件及操作系统往往将主存和磁盘存储区分割为连续的大小相等的块，每个存储块称为一页（在许多操作系统中，页的大小通常为4KB），主存和磁盘以页为单位交换数据。当程序要读取的数据不在主存中时，会触发一个缺页异常，此时系统会向磁盘发出读盘信号，磁盘会找到数据的起始位置并向后连续读取一页或几页载入内存中，然后异常返回，程序继续运行。 磁盘读取原理总结一次磁盘I/O：读n页(因为存在预读)，1页包含m个扇区。 先实际看下linux系统（centos）的一个扇区大小和一个页(逻辑块，一次I/O的大小)大小： 12345&gt;fdisk -l&gt;磁盘 /dev/sda：500.1 GB, 500107862016 字节，976773168 个扇区Units = 扇区 of 1 * 512 = 512 bytes扇区大小(逻辑/物理)：512 字节 / 4096 字节I/O 大小(最小/最佳)：4096 字节 / 4096 字节 可以看到一个扇区大小是512B,一个页大小为4096B,也就是一个页包含8个扇区 再看看预读的扇区数量： 12&gt;/sbin/blockdev --getra /dev/sda&gt;256 这里指的的是最大预读256个扇区，也就是32页。但是OS会有个自适应的过程，一般从4页(16KB)开始，在一定的时间窗口中倍增 为什么不用平衡二叉树比如红黑树。 由于数据库索引其实也是很大的，不可能全部存储在内存中，索引往往以索引文件的形式存储的磁盘上。这样的话，索引查找过程中就要产生磁盘I/O消耗，相对于内存存取，I/O存取的消耗要高几个数量级，所以评价一个数据结构作为索引的优劣最重要的指标就是在查找过程中磁盘I/O操作次数的渐进复杂度 所以，不使用平衡二叉树的原因如下： 最大原因：深度太大(因为一个节点最多只有2个子节点)，一次查询需要的I/O复杂度为O(lgN),而b+tree只需要O(log_mN),而其出度m非常大，其深度一般不会超过4 平衡二叉树逻辑上很近的父子节点，物理上可能很远，无法充分发挥磁盘顺序读和预读的高效特性。 举例： InnoDB存储引擎中页的大小为16KB，我们假设主键类型为BIGINT（占用8个字节，8B），指针类型为8个字节。也就是说一个页（B+Tree中的一个节点）中大概存储16KB/(8B+8B)=1K≈1000个键值。也就是说一个深度为3的B+Tree索引可以维护10^3 * 10^3 * 10^3 = 10亿条记录，而且磁盘I/O最多3次。 同样10亿条数据，红黑树的深度为30，也就是最多需要30次磁盘I/O才能查询到数据。远高于b+tree 为什么用b+tree而不用b-tree先来看看b-tree和b+tree结构比较图： 一颗b-tree: 一颗b+tree: b+tree相对于b-tree的区别： 有n棵子树的结点中含有n个索引key信息(而b-tree是n棵子树有n-1个) b+tree的非叶子仅仅存储索引key信息，不包含其他列内容 b+tree所有的叶子结点中包含了全部索引key信息，及指向含有这些关键字记录的指针，且叶子结点本身按照索引key的大小自小而大的顺序链接（叶子节点有个指向下一个叶子节点的指针 所以，b+tree的优势在于： 深度更低，磁盘I/O更少。因为b+tree非叶子节点仅仅包含索引key信息，想比较b-tree,一个节点能够容纳更多的索引key信息，也就是树的出度更大，树的深度也就更小 查询效率更加稳定。由于非叶子节点并不包含其他列内容，所以任何关键字的查找必须走完从根结点到叶子结点的路。所有关键字查询的路径长度相同，导致每一个数据的查询效率相当 范围查找、有序遍历非常方便。因为叶子节点之间有指针，遍历非常便捷。而b-tree就需要中序遍历才能做到]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[elasticsearch写入优化记录]]></title>
      <url>%2F2018%2F03%2F27%2Fes-write-optimize%2F</url>
      <content type="text"><![CDATA[背景 基于elasticsearch-5.6.0 机器配置：3个阿里云ecs节点，16G,4核，机械硬盘 优化前，写入速度平均3000条/s，一遇到压测，写入速度骤降，甚至es直接频率gc、oom等；优化后，写入速度平均8000条/s，遇到压测，能在压测结束后30分钟内消化完数据，各项指标回归正常。 优化设置 精细设置全文域：string类型字段默认会分词，不仅会额外占用资源，而且会影响创建索引的速度。所以，把不需要分词的字段设置为not_analyzed 禁用_all字段:对于日志和apm数据，目前没有场景会使用到 副本数量设置为0:因为我们目前日志数据和apm数据在es只保留最近7天的量，全量日志保存在hadoop，可以根据需要通过spark读回到es – 况且副本数量是可以随时修改的，区别分片数量 使用es自动生成id：es对于自动生成的id有优化，避免了版本查找。因为其生成的id是唯一的 设置index.refresh_interval：索引刷新间隔，默认为1s。因为不需要如此高的实时性，我们修改为30s – 扩展学习：刷新索引到底要做什么事情？ 设置段合并的线程数量： 123curl -XPUT &apos;your-es-host:9200/nginx_log-2018-03-20/_settings&apos; -d &apos;&#123; &quot;index.merge.scheduler.max_thread_count&quot; : 1&#125;&apos; 段合并的计算量庞大，而且还要吃掉大量磁盘I/O。合并在后台定期操作，因为他们可能要很长时间才能完成，尤其是比较大的段 机械磁盘在并发I/O支持方面比较差，所以我们需要降低每个索引并发访问磁盘的线程数。这个设置允许max_thread_count + 2个线程同时进行磁盘操作，也就是设置为1允许三个线程 扩展学习：什么是段(segment)？如何合并段？为什么要合并段？（what、how、why） 设置异步刷盘事务日志文件： 12&quot;index.translog.durability&quot;: &quot;async&quot;, &quot;index.translog.sync_interval&quot;: &quot;30s&quot; 对于日志场景，能够接受部分数据丢失。同时有全量可靠日志存储在hadoop，丢失了也可以从hadoop恢复回来 扩展学习：事务日志translog何时刷盘？具体流程是什么？ elasticsearch.yml中增加如下设置： 12indices.memory.index_buffer_size: 20%indices.memory.min_index_buffer_size: 96mb 已经索引好的文档会先存放在内存缓存中，等待被写到到段(segment)中。缓存满的时候会触发段刷盘(吃i/o和cpu的操作)。默认最小缓存大小为48m，不太够，最大为堆内存的10%。对于大量写入的场景也显得有点小。 扩展学习：数据写入流程是怎么样的(具体到如何构建索引)？ 设置index、merge、bulk、search的线程数和队列数。例如以下elasticsearch.yml设置： 1234567891011# Search poolthread_pool.search.size: 5thread_pool.search.queue_size: 100# 这个参数慎用！强制修改cpu核数，以突破写线程数限制# processors: 16# Bulk poolthread_pool.bulk.size: 16thread_pool.bulk.queue_size: 300# Index poolthread_pool.index.size: 16thread_pool.index.queue_size: 300 设置filedata cache大小，例如以下elasticsearch.yml配置： 1indices.fielddata.cache.size: 15% filedata cache的使用场景是一些聚合操作(包括排序),构建filedata cache是个相对昂贵的操作。所以尽量能让他保留在内存中 然后日志场景聚合操作比较少，绝大多数也集中在半夜，所以限制了这个值的大小，默认是不受限制的，很可能占用过多的堆内存 扩展学习：什么是filedata？构建流程是怎样的？为什么要用filedata？（what、how、why） 设置节点之间的故障检测配置，例如以下elasticsearch.yml配置： 123discovery.zen.fd.ping_timeout: 120sdiscovery.zen.fd.ping_retries: 6discovery.zen.fd.ping_interval: 30s 大数量写入的场景，会占用大量的网络带宽，很可能使节点之间的心跳超时。并且默认的心跳间隔也相对过于频繁（1s检测一次） 此项配置将大大缓解节点间的超时问题 后记这里仅仅是记录对我们实际写入有提升的一些配置项，没有针对个别配置项做深入研究。 扩展学习后续填坑。基本都遵循（what、how、why）原则去学习。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[阿里中间件6轮面试被砍的血泪总结]]></title>
      <url>%2F2018%2F03%2F20%2Falibaba-middleware-interview%2F</url>
      <content type="text"><![CDATA[背景年前在v2ex遇到阿里中间件的哥们，内推面试。从2018.02.01开始到今天2018.03.20，一场浩浩荡荡，跨年，持续了1个半月时间的残酷面试终于尘埃落定。遗憾的未能加入阿里中间件部门这个大家庭，让我深感痛惜。 最终未能如愿的原因是“名额有限，有更适合的同学”。这也可能是内推大哥为了顾及我的感受的说辞，可能是最后一面面的不好。 这里凭借隐约的记忆，总结下面试经过。让我自己引以为戒，奋发自强，继续前行 一面主要问一些java基础。包括集合、多线程、ClassLoader、锁、juc类库等都要知道大致的原理、使用规范、约定等 二面根据项目，深入探讨。你需要清楚你所做项目的关键细节、优化、特点、原理。所用第三方库&amp;中间件等的原理，即使不知道，也要有自己的想法能够说出如何代替实现！而且需要一定的技术知识的广度，对于如何选型，为何这么选型能够说出自己的理由 三面个人感觉着重技术深度。 从ConcurrentHashMap一路问到锁&amp;锁优化-&gt;LongAdder-&gt;伪共享-&gt;缓存行填充-&gt;cas等诸多技术细节； 从hystrix一路问到原理-&gt;自己如何实现-&gt;如何优化-&gt;响应流编程(reactive streams); 从简单的生产者消费者模式设计到如何高效健壮实现； 等等。 四面纯coding。 如何倒序输出单向链表？ 个人直接想法是用栈先进后出的特点，把链表数据读到栈里然后输出。 有更好的实现方式吗？ 仔细一想，确实不够优雅，还好之前刷过一阵子的leetcode，一般能用栈解决的都能用递归搞定。换了一种递归实现： 具体看本人的github传送门 五面hr面，唯一一次现场面，一直以为是最后一面呢。 给大家抛出几大深坑问题： 个人的职业规划是什么 你遇到的最大问题或者是困难是什么 你如何看待阿里 你能为阿里带来什么 你的优缺点是什么 这几个问题，大家深思啊，不多说。 六面大概晚上20:00的时候接的电面。那会刚刚游泳游了大概2，300百米，然后又没有吃饭，肚子咕咕叫。忍着接听。 主要问项目情况，然后根据一个项目，问如果量级扩大1000倍，你会怎么做？有哪些优化措施？高性能&amp;高可用措施？ 后面有点饿的眩晕，不知道怎么结束的。。。 总结感觉阿里更偏重扎实的基础和解决问题的创意与能力。个人感觉自己缺乏大并发、大流量下面对各种复杂问题的处理经验与解决方案，继续沉淀学习吧。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[分布式锁研究]]></title>
      <url>%2F2018%2F03%2F20%2Fdistributed-lock%2F</url>
      <content type="text"><![CDATA[背景公司使用基于redis setNX的分布式锁偶现失效，对此深入研究一番 场景大体来说，分布式锁的场景有两种： 为了效率：相当于去重，避免各个系统做重复的事情。比如重复发送一封email 为了正确性：不允许出现任何的失效，不然就可能造成数据不一致 基于单节点的redis实现 为什么强调单节点？因为我们就一个redis主从，没有redis集群。而且redis有官方的分布式锁redlock是基于redis集群的，这个对我们不适用，而且感觉有点过重。 我们一开始的方案是基于setNX(key,value,timeout)。后来发现原来这是jedis的封装，这其实是2个redis命令：setnx+expire。也就是说这不是个原子操作，很可能setnx成功，但是设置过期时间失败导致锁永远无法释放 翻看redlock的套路才知道，应该这样操作： 获取锁：set key randomValue NX PX 3000 redis的set操作有NX(if not exist)选项和PX(过期时间)选项，可以实现原子操作 释放锁：需要使用LUA脚本实现复合操作的原子性： 123(1) get key(2) 比较random value(3) random value一致即删除key 分析一些疑问： 必须要设置过期时间吗？ 必须要。因为假如获取锁的程序阻塞/崩溃/与redis网络异常等情况，锁将永远不能被释放 必须要设置一个随机值吗？ 必须要。考虑以下执行序列： (1) 程序1获取了锁 (2) 程序1假死导致锁超时被释放 (3) 程序2获取了锁 (4) 程序1从假死中恢复，直接释放了锁（没有比较随机值，相当于把程序2的锁给释放了） (5) 程序2的执行将得不到锁的保护 必须使用lua脚本来释放锁吗？ 必须要。因为释放锁需要3步（get-&gt;比较random value-&gt;del）,需要保证3个复合操作的原子性。也不能用redis的事务消息，因为redis没有比较和if else这样命令啊…redis要是有类似cas这种操作就好了，compare and delete一步就能搞定 这样处理的redis锁已经是万无一失了吗？其实还存在2个主要问题： 过期时间设置多久合适？如果设置太短，锁就可能在程序完成对共享资源的操作之前失效，从而得不到保护；如果设置的太长，一旦某个获取锁的程序释放锁失败(比如与redis网络异常)，那么就可能导致其他系统长时间无法获取锁而无法正常工作 如果程序假死(例如长时间的GC pause)将导致锁过期失效，这时候共享资源其实已经失去了保护(可能这时候有另一个程序获取了锁，而假死的程序恢复过来后同时在操作共享资源) 另外redlock还存在另一个问题就是强依赖于几个节点之间的系统时钟，一旦发生时钟跳跃，redlock很可能就失效 很多人说可以用更可靠的zookeeper来解决，那基于zookeeper的分布式锁真的万无一失吗？先来看看zookeeper分布式锁的套路 zookeeper分布式锁具体参考官网文档：传送门 获取锁： (1) 客户端调用create()在/lock下创建临时的且有序的子节点，第一个客户端对应的子节点为/lock/lock-0000000000，第二个为/lock/lock-0000000001，以此类推 (2) 客户端调用getChildren()获取/lock下的子节点列表，判断自己创建的子节点是否为当前子节点列表中序号最小的子节点，如果是则认为获得了锁，获取锁流程结束 (3) 否则在前一个节点调用exists()并设置watch监听节点删除消息 (4) 如果exists()返回false，重试第(2)步；否则等待节点删除通知再重试第(2)步直到获取锁 删除锁：删除创建的节点即可 这样设计有以下优点： 删除节点即释放锁时，只会导致最多一个客户端被唤醒，避免了“惊群效应（herd effect）” 不存在轮询或者超时 临时节点，会在客户端奔溃/假死等情况自动释放锁 能够直观的知道竞争锁的数量，甚至能退出锁，debug锁问题等 分析zookeeper实现的分布式锁相对于redis确实更完善，功能也更丰富。没有redis过期时间的问题，而且能在需要的时候让锁自动释放。然而redis存在的问题中第2点，zookeeper也依然存在。假设有以下执行序列： (1) 客户端1创建了节点/lock/lock-0000000000并且获取到了锁 (2) 客户端1进入长时间的GC pause (3) 客户端1与zookeeper的session过期(心跳检测失败)，lock-0000000000被自动删除 (4) 客户端2创建了/lock/lock-0000000001并获得了锁 (5) 客户端1从GC pause中恢复，依然认为自己持有锁 (6) 客户端1和2都认为自己持有锁，就产生了冲突 类似这种假死造成的锁失效问题，redis和zookeeper目前貌似没有完美的解决方案 这里肯定有人会说google的Chubby可以做到完美，那就来看下Chubby对这个问题的解决方案 Chubby分布式锁Chubby分布式锁有2种实现，主要是针对之前提到问题的解决和缓解 完美实现：获取Chubby锁的时候，锁包含了一个sequencer，里面有个单调递增的数字，要求资源服务器在对资源做修改的时候需要检查这个sequencer Chubby提供了2种检查方式： 调用Chubby提供的API，CheckSequencer()，将整个sequencer传进去进行检查。这个检查是为了保证客户端持有的锁在进行资源访问的时候仍然有效 将客户端传来的sequencer与资源服务器当前观察到的最新的sequencer进行对比检查 这种实现方式类似乐观锁，有个版本号作为控制。但是要求有个“资源服务器”能在共享资源做修改的时候检查当前的sequencer。也就是说很可能需要修改“资源服务器（比如数据库）”对共享资源的操作方式。我觉得，绝大多数的“资源服务器”都不能做这个修改，这个完美方案不太普适 缓解实现获取锁的时候，同时会设置一个lock-deploy(默认一分钟)。当Chubby服务端发现客户端被动失效后，并不是立即释放锁，而是会在lock-delay指定的时间内阻止其它客户端获得这个锁。但是正常的Release操作释放的锁可以立刻被再次获取 这种方式相当于牺牲了一定的可用性换来更普适的使用场景 分析google Chubby的做法貌似更加优雅一点，提供了足够的方案，把选择权留给了使用者。使用者可以根据特定的场景选择特定的解决方案。 但是Chubby没有开源，非常可惜。我们只能借鉴其思想。 个人觉得zookeeper完全可以借鉴Chubby的做法，获取锁的时候同样设置lock-deloy或者使用节点序列号作为Chubby中的sequencer，对共享资源的操作可以原子的比较sequencer 总结 基于场景1的分布式锁（即为了效率），使用单点的redis已经足够了，简单高效。 基于场景2的分布式锁（即为了正确性），基于zookeeper已经比较适合，能够满足比redis有更好的正确性，但也无法做到绝对的正确。 基于场景2的分布式锁（即为了正确性），并且需要绝对的正确，需要定制zookeeper与“资源服务器”]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[rocketmq源码阅读之message发送]]></title>
      <url>%2F2018%2F03%2F18%2Frocketmq-1-send-message%2F</url>
      <content type="text"><![CDATA[背景基于rocketmq 4.2.0 先不关注顺序消息和事务消息，后面独立看。 发送消息入口DefaultMQProducer#send(Message) 默认的是同步发送。最终调用的是DefaultMQProducerImpl#sendDefaultImpl，直接看代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778private SendResult sendDefaultImpl( Message msg, final CommunicationMode communicationMode, final SendCallback sendCallback, final long timeout) throws MQClientException, RemotingException, MQBrokerException, InterruptedException &#123; // 确保producer已经启动 this.makeSureStateOK(); // 校验message，例如topic不能为空 Validators.checkMessage(msg, this.defaultMQProducer); // 目前来看，仅在日志输出时标示此次调用 final long invokeID = random.nextLong(); long beginTimestampFirst = System.currentTimeMillis(); long beginTimestampPrev = beginTimestampFirst; long endTimestamp = beginTimestampFirst; // 获取topic发布路由信息 -- 会先尝试缓存中获取，其次从namesrv中获取 TopicPublishInfo topicPublishInfo = this.tryToFindTopicPublishInfo(msg.getTopic()); if (topicPublishInfo != null &amp;&amp; topicPublishInfo.ok()) &#123; MessageQueue mq = null; Exception exception = null; SendResult sendResult = null; // 同步发送默认重试3次 int timesTotal = communicationMode == CommunicationMode.SYNC ? 1 + this.defaultMQProducer.getRetryTimesWhenSendFailed() : 1; int times = 0; String[] brokersSent = new String[timesTotal]; for (; times &lt; timesTotal; times++) &#123; String lastBrokerName = null == mq ? null : mq.getBrokerName(); /* * 选择一个消息队列 * 规则：1）默认情况，不开启发送的延迟容错策略时，RoundRobin形式的选择一个不属于上一次发送的broker队列 * 2）开启延迟容错策略时： * 2.1）优先从上一次的发送的broker中RoundRobin形式选择一个可用队列 * 2.2）其次按照可用性排名（是否可用&gt;延迟时间&gt;开始时间）从前半数中RoundRobin选 * 2.3）最次，啥都不管，RoundRobin选 */ MessageQueue mqSelected = this.selectOneMessageQueue(topicPublishInfo, lastBrokerName); if (mqSelected != null) &#123; mq = mqSelected; brokersSent[times] = mq.getBrokerName(); try &#123; beginTimestampPrev = System.currentTimeMillis(); // 核心消息投递方法 sendResult = this.sendKernelImpl(msg, mq, communicationMode, sendCallback, topicPublishInfo, timeout); endTimestamp = System.currentTimeMillis(); // 更新延迟容错信息 this.updateFaultItem(mq.getBrokerName(), endTimestamp - beginTimestampPrev, false); switch (communicationMode) &#123; case ASYNC: return null; case ONEWAY: return null; case SYNC: if (sendResult.getSendStatus() != SendStatus.SEND_OK) &#123; if (this.defaultMQProducer.isRetryAnotherBrokerWhenNotStoreOK()) &#123; continue; &#125; &#125; return sendResult; default: break; &#125; &#125; catch (RemotingException e) &#123; // ...省略部分代码 &#125; &#125; else &#123; break; &#125; &#125; // ...省略部分代码 &#125; // ...省略部分代码&#125; 思考 final long invokeID = random.nextLong(); 这个invokeID仅在日志输出时标示此次调用，却可能造成性能问题。共享的random虽然是线程安全的，但是每次调用都需要循环cas操作来替换每次的随机种子，高并发下，可能造成线程饥饿 这里建议JDK7及以上使用ThreadLocalRandom代替。（不过RocketMQ可能是因为要兼容jdk6才没有用，不过我仍然觉得即使jdk6没有现成的类，也应该自己设计一个类似的类，追求性能的路上没有终点~） 如何选择一个消息队列最终由MQFaultStrategy#selectOneMessageQueue处理，源码如下： 12345678910111213141516171819202122232425262728293031323334353637383940public MessageQueue selectOneMessageQueue(final TopicPublishInfo tpInfo, final String lastBrokerName) &#123; if (this.sendLatencyFaultEnable) &#123; try &#123; // 优先从上一次的发送的broker中RoundRobin形式选择一个可用队列 int index = tpInfo.getSendWhichQueue().getAndIncrement(); for (int i = 0; i &lt; tpInfo.getMessageQueueList().size(); i++) &#123; int pos = Math.abs(index++) % tpInfo.getMessageQueueList().size(); if (pos &lt; 0) pos = 0; MessageQueue mq = tpInfo.getMessageQueueList().get(pos); if (latencyFaultTolerance.isAvailable(mq.getBrokerName())) &#123; if (null == lastBrokerName || mq.getBrokerName().equals(lastBrokerName)) return mq; &#125; &#125; // 其次按照可用性排名（是否可用&gt;延迟时间&gt;开始时间）从前半数中RoundRobin选 final String notBestBroker = latencyFaultTolerance.pickOneAtLeast(); int writeQueueNums = tpInfo.getQueueIdByBroker(notBestBroker); if (writeQueueNums &gt; 0) &#123; final MessageQueue mq = tpInfo.selectOneMessageQueue(); if (notBestBroker != null) &#123; mq.setBrokerName(notBestBroker); mq.setQueueId(tpInfo.getSendWhichQueue().getAndIncrement() % writeQueueNums); &#125; return mq; &#125; else &#123; latencyFaultTolerance.remove(notBestBroker); &#125; &#125; catch (Exception e) &#123; log.error("Error occurred when selecting message queue", e); &#125; // 最次，啥都不管，直接RoundRobin选 return tpInfo.selectOneMessageQueue(); &#125; // 默认情况，不开启发送的延迟容错策略时，RoundRobin形式的选择一个不属于上一次发送的broker队列 return tpInfo.selectOneMessageQueue(lastBrokerName);&#125; 总结选择规则 默认情况，不开启发送的延迟容错策略时，RoundRobin形式的选择一个不属于上一次发送的broker队列 开启延迟容错策略时： 优先从上一次的发送的broker中RoundRobin形式选择一个可用队列 其次按照可用性排名（是否可用&gt;延迟时间&gt;开始时间）从前半数中RoundRobin选 最次，啥都不管，直接RoundRobin选 思考个人感觉这块代码不够整洁。先看以下代码片段： 123456int index = tpInfo.getSendWhichQueue().getAndIncrement();for (int i = 0; i &lt; tpInfo.getMessageQueueList().size(); i++) &#123; int pos = Math.abs(index++) % tpInfo.getMessageQueueList().size(); if (pos &lt; 0) pos = 0;// 省略其他代码 同时看下tpInfo.getSendWhichQueue().getAndIncrement()具体的代码： 12345678910111213141516public int getAndIncrement() &#123; Integer index = this.threadLocalIndex.get(); if (null == index) &#123; index = Math.abs(random.nextInt()); if (index &lt; 0) index = 0; this.threadLocalIndex.set(index); &#125; index = Math.abs(index + 1); if (index &lt; 0) index = 0; this.threadLocalIndex.set(index); return index;&#125; 这里有2个问题： Math.abs(index++)这操作绝大多数情况下没有必要的，因为getAndIncrement()保证了其为正数。只有当在循环体内，且index取值为[Integer.MAX_VALUE-tpInfo.getMessageQueueList().size(),Integer.MAX_VALUE]才可能需要，同时后面的if (pos &lt; 0)也是如此。 pos没有回设到Threadlocal中，导致会有那么几次选择的是同一个消息队列，不过这个倒是影响不大。RocketMQ可能是为了性能考虑。 个人觉得这段直接使用getAndIncrement会更简洁明确一点： 12345678910for (int i = 0; i &lt; tpInfo.getMessageQueueList().size(); i++) &#123; int pos = tpInfo.getSendWhichQueue().getAndIncrement() % tpInfo.getMessageQueueList().size(); MessageQueue mq = tpInfo.getMessageQueueList().get(pos); if (latencyFaultTolerance.isAvailable(mq.getBrokerName())) &#123; if (null == lastBrokerName || mq.getBrokerName().equals(lastBrokerName)) &#123; return mq; &#125; &#125;&#125;// 剩余代码省略 可以看到，精简之后，出现了对同一个对象连续调用了其实例方法，感觉有点混乱。其实这里本质就是从上一个发送成功的broker选择队列，为何要独立到MQFaultStrategy中呢？可以仍然由TopicPublishInfo直接出一个方法selectMessageQueueWithBroker： 1234567891011public MessageQueue selectOneMessageQueueWithBroker(String lastBrokerName) &#123; int size = messageQueueList.size(); for (int i = 0; i &lt; size; i++) &#123; int pos = sendWhichQueue.getAndIncrement() % size; MessageQueue mq = messageQueueList.get(pos); if (lastBrokerName == null || mq.getBrokerName().equals(lastBrokerName)) &#123; return mq; &#125; &#125; return null;&#125; 进一步思考，选择一个消息队列的时候，由一个延迟容错的策略类(MQFaultStrategy)代理，然后基本所有的选择逻辑又都在topic路由类(TopicPublishInfo)中。总感觉有点奇怪。 个人想法: MQFaultStrategy应该设计为由MessageQueueSelector和SendMessageHook组合实现，这样就能和DefaultMQProducerImpl#send(Message msg, MessageQueueSelector selector, Object arg)统一，流程一致。 目前是MQFaultStrategy强耦合到了默认的消息发送流程中，一方面这个策略类难以被替换，另一方面，和其他重载的的消息发送方法流程不太一致 核心消息发送方法调用的是DefaultMQProducerImpl#sendKernelImpl，直接看源码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171private SendResult sendKernelImpl(final Message msg, final MessageQueue mq, final CommunicationMode communicationMode, final SendCallback sendCallback, final TopicPublishInfo topicPublishInfo, final long timeout) throws MQClientException, RemotingException, MQBrokerException, InterruptedException &#123; // 获取broker地址 String brokerAddr = this.mQClientFactory.findBrokerAddressInPublish(mq.getBrokerName()); if (null == brokerAddr) &#123; tryToFindTopicPublishInfo(mq.getTopic()); brokerAddr = this.mQClientFactory.findBrokerAddressInPublish(mq.getBrokerName()); &#125; SendMessageContext context = null; if (brokerAddr != null) &#123; // 是否使用broker vip通道,broker会开启两个端口对外服务 brokerAddr = MixAll.brokerVIPChannel(this.defaultMQProducer.isSendMessageWithVIPChannel(), brokerAddr); byte[] prevBody = msg.getBody(); try &#123; // 设置消息唯一id //for MessageBatch,ID has been set in the generating process if (!(msg instanceof MessageBatch)) &#123; // 唯一id生成逻辑：pid+ip+ClassLoader.hashCode+(当前时间-开始时间)+递增数 MessageClientIDSetter.setUniqID(msg); &#125; // 消息压缩 int sysFlag = 0; if (this.tryToCompressMessage(msg)) &#123; sysFlag |= MessageSysFlag.COMPRESSED_FLAG; &#125; // 事务消息 final String tranMsg = msg.getProperty(MessageConst.PROPERTY_TRANSACTION_PREPARED); if (tranMsg != null &amp;&amp; Boolean.parseBoolean(tranMsg)) &#123; sysFlag |= MessageSysFlag.TRANSACTION_PREPARED_TYPE; &#125; // 钩子：检查是否允许发送消息的扩展点 if (hasCheckForbiddenHook()) &#123; CheckForbiddenContext checkForbiddenContext = new CheckForbiddenContext(); checkForbiddenContext.setNameSrvAddr(this.defaultMQProducer.getNamesrvAddr()); checkForbiddenContext.setGroup(this.defaultMQProducer.getProducerGroup()); checkForbiddenContext.setCommunicationMode(communicationMode); checkForbiddenContext.setBrokerAddr(brokerAddr); checkForbiddenContext.setMessage(msg); checkForbiddenContext.setMq(mq); checkForbiddenContext.setUnitMode(this.isUnitMode()); this.executeCheckForbiddenHook(checkForbiddenContext); &#125; // 钩子：发送消息前的扩展点 if (this.hasSendMessageHook()) &#123; context = new SendMessageContext(); context.setProducer(this); context.setProducerGroup(this.defaultMQProducer.getProducerGroup()); context.setCommunicationMode(communicationMode); context.setBornHost(this.defaultMQProducer.getClientIP()); context.setBrokerAddr(brokerAddr); context.setMessage(msg); context.setMq(mq); String isTrans = msg.getProperty(MessageConst.PROPERTY_TRANSACTION_PREPARED); if (isTrans != null &amp;&amp; isTrans.equals("true")) &#123; context.setMsgType(MessageType.Trans_Msg_Half); &#125; if (msg.getProperty("__STARTDELIVERTIME") != null || msg.getProperty(MessageConst.PROPERTY_DELAY_TIME_LEVEL) != null) &#123; context.setMsgType(MessageType.Delay_Msg); &#125; this.executeSendMessageHookBefore(context); &#125; // 构建发送消息请求 SendMessageRequestHeader requestHeader = new SendMessageRequestHeader(); requestHeader.setProducerGroup(this.defaultMQProducer.getProducerGroup()); requestHeader.setTopic(msg.getTopic()); requestHeader.setDefaultTopic(this.defaultMQProducer.getCreateTopicKey()); requestHeader.setDefaultTopicQueueNums(this.defaultMQProducer.getDefaultTopicQueueNums()); requestHeader.setQueueId(mq.getQueueId()); requestHeader.setSysFlag(sysFlag); requestHeader.setBornTimestamp(System.currentTimeMillis()); requestHeader.setFlag(msg.getFlag()); requestHeader.setProperties(MessageDecoder.messageProperties2String(msg.getProperties())); requestHeader.setReconsumeTimes(0); requestHeader.setUnitMode(this.isUnitMode()); requestHeader.setBatch(msg instanceof MessageBatch); if (requestHeader.getTopic().startsWith(MixAll.RETRY_GROUP_TOPIC_PREFIX)) &#123; String reconsumeTimes = MessageAccessor.getReconsumeTime(msg); if (reconsumeTimes != null) &#123; requestHeader.setReconsumeTimes(Integer.valueOf(reconsumeTimes)); MessageAccessor.clearProperty(msg, MessageConst.PROPERTY_RECONSUME_TIME); &#125; String maxReconsumeTimes = MessageAccessor.getMaxReconsumeTimes(msg); if (maxReconsumeTimes != null) &#123; requestHeader.setMaxReconsumeTimes(Integer.valueOf(maxReconsumeTimes)); MessageAccessor.clearProperty(msg, MessageConst.PROPERTY_MAX_RECONSUME_TIMES); &#125; &#125; // 发送消息，这里真正要调用网络层发送消息 SendResult sendResult = null; switch (communicationMode) &#123; case ASYNC: // 整整12个入参... sendResult = this.mQClientFactory.getMQClientAPIImpl().sendMessage( brokerAddr, mq.getBrokerName(), msg, requestHeader, timeout, communicationMode, sendCallback, topicPublishInfo, this.mQClientFactory, this.defaultMQProducer.getRetryTimesWhenSendAsyncFailed(), context, this); break; case ONEWAY: case SYNC: sendResult = this.mQClientFactory.getMQClientAPIImpl().sendMessage( brokerAddr, mq.getBrokerName(), msg, requestHeader, timeout, communicationMode, context, this); break; default: assert false; break; &#125; // 钩子：消息发送后的扩展点 if (this.hasSendMessageHook()) &#123; context.setSendResult(sendResult); this.executeSendMessageHookAfter(context); &#125; return sendResult; &#125; catch (RemotingException e) &#123; if (this.hasSendMessageHook()) &#123; context.setException(e); this.executeSendMessageHookAfter(context); &#125; throw e; &#125; catch (MQBrokerException e) &#123; if (this.hasSendMessageHook()) &#123; context.setException(e); this.executeSendMessageHookAfter(context); &#125; throw e; &#125; catch (InterruptedException e) &#123; if (this.hasSendMessageHook()) &#123; context.setException(e); this.executeSendMessageHookAfter(context); &#125; throw e; &#125; finally &#123; msg.setBody(prevBody); &#125; &#125; // broker地址为空抛出异常 throw new MQClientException("The broker[" + mq.getBrokerName() + "] not exist", null);&#125; 思考这里感觉最大的问题就是api和spi没有分离好。 扩展点(hook)不一致：有CheckForbiddenHook和SendMessageHook这2个hook，目前看CheckForbiddenHook完全可以由SendMessageHook#sendMessageBefore实现 可以定义一个发送消息的流程类SendMessageProcesser,定义消息发送的流程。然后定义一个一致的hook类，比如ProducerHook。然后出个注解定义hook类型(before或者after)，在流程类中对ProducerHook组装 扩展点(hook)设置略显简陋：hook设置是通过DefaultMQProducerImpl#registerXXXHook方法add到一个ArrayList中的,这样一方面sdk使用者这法明确添加hook的执行顺序，一方面不能精细设置某个hook必须要在某个hook之前或之后调用 可以出个注解定义顺序，然后使用类似TreeSet来排序 说明里面的思考都是基于个人初步阅读源码这个前提的看法，欢迎各位大神斧正！]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[分布式追踪系统x-apm拾遗之伪共享与缓存行填充]]></title>
      <url>%2F2018%2F02%2F26%2Ffalse-share%2F</url>
      <content type="text"><![CDATA[背景之前开发分布式追踪系统x-apm的时候，确认了2个目标： x-apm的异常绝不能影响业务系统 x-apm应该尽可能的少暂用系统资源的前提下，尽可能的快(实时) 针对第2点，用来暂存追踪数据的数据结构碰到了伪共享的问题，导致收集发送的效率不够高，所以使用的缓存行填充。 这里记录下伪共享和缓存行填充的相关内容。 基础简介cpu cache一个典型的cpu cache架构： 访问速度：寄存器&lt;L1 cache&lt;L2 cache&lt;L3 cache&lt;主存 所以，充分利用它的结构和机制，可以有效的提高程序的性能 这里需要注意：一个cpu中的多核共享L3 cache,而L1、L2 cache是每个核心各自拥有的;一个缓存行一般缓存64byte大小的数据 cpu缓存一致性协议 - MESI在MESI协议中，每个Cache line有4个状态，可用2个bit表示，它们分别是： 状态 描述 M(Modified) 这行数据有效，数据被修改了，和主存冲的数据不一致，数据只存在本Cache中 E(Exclusive) 这行数据有效，数据和内存中的数据一致，数据只存在于本Cache中 S(Shard) 这行数据有效，数据和内存中的数据一致，数据存在于很多Cache中 I(Invalid) 这行数据无效 MESI协议中的状态 M: 被修改（Modified) 该缓存行只被缓存在该CPU的缓存中，并且是被修改过的（dirty),即与主存中的数据不一致，该缓存行中的内存需要在未来的某个时间点（允许其它CPU读取请主存中相应内存之前）写回（write back）主存。 当被写回主存之后，该缓存行的状态会变成独享（exclusive)状态。 E: 独享的（Exclusive) 该缓存行只被缓存在该CPU的缓存中，它是未被修改过的（clean)，与主存中数据一致。该状态可以在任何时刻当有其它CPU读取该内存时变成共享状态（shared)。 同样地，当CPU修改该缓存行中内容时，该状态可以变成Modified状态。 S: 共享的（Shared) 该状态意味着该缓存行可能被多个CPU缓存，并且各个缓存中的数据与主存数据一致（clean)，当有一个CPU修改该缓存行中， 其它CPU中该缓存行可以被作废（变成无效状态（Invalid））。 I: 无效的 (Invalid) 该缓存行数据无效。 M(Modified)和E(Exclusive)状态的Cache line，数据是独有的，不同点在于M状态的数据是dirty的(和内存的不一致)，E状态的数据是clean的(和内存的一致)。 S(Shared)状态的Cache line，数据和其他Core的Cache共享。只有clean的数据才能被多个Cache共享。 一个缓存除在Invalid状态外都可以满足cpu的读请求，一个invalid的缓存行必须从主存中读取（变成S或者E状态）来满足该CPU的读请求 cache line数据在缓存中不是以独立的项来存储的，如不是一个单独的变量，也不是一个单独的指针。缓存是由缓存行组成的，通常是64字节，并且它有效地引用主内存中的一块地址。一个Java的long类型是8字节，因此在一个缓存行中可以存8个long类型的变量。 当缓存行加载数据的时候，会同时加载其后连续的一部分数据。所以你可以非常快速的遍历在连续的内存块中分配的任意数据结构。因此如果你数据结构中的项在内存中不是彼此相邻的（比如链表），你将得不到免费缓存加载所带来的优势。并且在这些数据结构中的每一个项都可能会出现缓存未命中 伪共享伪共享就是2个不同的数据恰好被加载到同一个缓存行中，不同cpu的核分别去修改该缓存行中的不同数据，却导致了相互竞争同一个缓存行。例如以下例子： 数据X、Y、Z被加载到同一Cache Line中，线程A在Core1修改X，线程B在Core2上修改Y。根据MESI大法，假设是Core1是第一个发起操作的CPU核，Core1上的L1 Cache Line由S（共享）状态变成M（修改，脏数据）状态，然后告知其他的CPU核，图例则是Core2，引用同一地址的Cache Line已经无效了；当Core2发起写操作时，首先导致Core1将X写回主存，Cache Line状态由M变为I（无效），而后才是Core2从主存重新读取该地址内容，Cache Line状态由I变成E（独占），最后进行修改Y操作， Cache Line从E变成M。可见多个线程操作在同一Cache Line上的不同数据，相互竞争同一Cache Line，导致线程彼此牵制影响，变成了串行程序，降低了并发性。 缓存行填充一般解决伪共享的方式就是缓存行填充，将频繁写的变量填充到64byte，不和其他变量加载到同一个缓存行即可。 例如以下代码：(参考Disruptor作者的博客改写而来) 123456789101112131415161718192021222324252627282930313233343536373839404142public class FalseSharingTest &#123; public static final int THREAD_NUMBER = 4; public static final long WIRTER_NUMBER = 800_000_000L; public static final PaddedLong[] ARRAY = new PaddedLong[4]; public static class PaddingLong &#123; private long p1, p2, p3, p4, p5, p6 = 7L; /** * 阻止jvm优化掉无用的字段 */ public long preventOptimisation() &#123; return p1 + p2 + p3 + p4 + p5 + p6; &#125; &#125; public static class PaddedLong extends PaddingLong &#123; public volatile long value = 0L; &#125; public static void main(String[] args) throws InterruptedException &#123; long start = System.currentTimeMillis(); CountDownLatch countDownLatch = new CountDownLatch(THREAD_NUMBER); for (int i = 0; i &lt; THREAD_NUMBER; i++) &#123; final int index = i; new Thread(() -&gt; &#123; ARRAY[index] = new PaddedLong(); long count = WIRTER_NUMBER; while (count-- != 0) &#123; ARRAY[index].value = count; &#125; countDownLatch.countDown(); &#125;).start(); &#125; countDownLatch.await(); System.out.println("耗时：" + (System.currentTimeMillis() - start)); &#125;&#125; PaddedLong不继承PaddingLong的时候，即没有使用缓存行填充，程序执行时间甚至2倍于填充后 JDK8后更智能，可以直接使用@sun.misc.Contended来标注需要填充的字段或者类（标注类表示，类中的所有字段都需要填充）。注意，jvm需要添加参数-XX:-RestrictContended才能开启此功能 例如JDK8中的ConcurrentHashMap： 1234567891011// ConcurrentHashMap.java line:2506 /** * A padded cell for distributing counts. Adapted from LongAdder * and Striped64. See their internal docs for explanation. */ @sun.misc.Contended static final class CounterCell &#123; volatile long value; CounterCell(long x) &#123; value = x; &#125; &#125; 思考@sun.misc.Contended虽然很智能，但是需要jvm开启特定参数。对于中间件产品来说可能手动填充更合适。请看以下常见填充方式： 123456789101112131415public class PaddingLong &#123; private long p1, p2, p3, p4, p5, p6 = 7L; /** * 阻止jvm优化掉无用的字段 */ public long preventOptimisation() &#123; return p1 + p2 + p3 + p4 + p5 + p6; &#125; &#125; public class PaddedLong extends PaddingLong &#123; public volatile long value = 0L; &#125; 以上是参考Disruptor作者的填充方式，也是很多开源产品的填充方式。 作者只填充了6个long变量，也就是PaddedLong实例对象的内存占用大小为：16(对象头大小)+6*8(填充变量大小)+1*8(被填充变量大小)=72byte&gt;64byte 可以使用JOL工具(下载传送门)查看对象内存布局来验证我们的预想： 1234567891011121314151617$ java -jar ~/tools/jol-cli-0.9-full.jar internals -cp algorithm-1.0-SNAPSHOT.jar com.zacard.algorithm.test.falseshare.PaddedLong$ com.zacard.algorithm.test.falseshare.PaddedLong object internals: OFFSET SIZE TYPE DESCRIPTION VALUE 0 4 (object header) 01 00 00 00 (00000001 00000000 00000000 00000000) (1) 4 4 (object header) 00 00 00 00 (00000000 00000000 00000000 00000000) (0) 8 4 (object header) 44 08 02 f8 (01000100 00001000 00000010 11111000) (-134084540) 12 4 (alignment/padding gap) 16 8 long PaddingLong.p1 0 24 8 long PaddingLong.p2 0 32 8 long PaddingLong.p3 0 40 8 long PaddingLong.p4 0 48 8 long PaddingLong.p5 0 56 8 long PaddingLong.p6 7 64 8 long PaddedLong.value 0Instance size: 72 bytesSpace losses: 4 bytes internal + 0 bytes external = 4 bytes total 可以看到填充的对象确实占用了72byte。 看一下作者的解释（传送门）： I do not want the mark word to be in the cache line which can be modified by taking out locks or the garbage collector ageing the object 我不希望在缓存行中的对象头中的“mark word”在设置锁标记或者垃圾回收器在老化对象的时候被修改 这里修改对象头中的锁标记应该能理解，因为当synchronized一个对象的时候，确实会修改对象头中的锁标记，这个也很可能会造成伪共享的问题。 “garbage collector ageing the object”应该指的是对象挨过一次gc存活下来，需要修改对象头中的对象年龄。 对于作者的严谨，我服…]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[分布式追踪系统x-apm开发拾遗之synthetic与bridge方法]]></title>
      <url>%2F2018%2F02%2F13%2Fjava-syntethic-and-bridge-methods%2F</url>
      <content type="text"><![CDATA[背景之前开发x-apm的时候，自定义增强一个spring bean的时候，出现了一个奇怪的异常 – 找不到无参构造方法，导致bean初始化失败。原来是bytebuddy这个类库在增强类的时候，会自动增加一个synthetic的构造方法，导致spring无法找打正确的构造方法初始化。这里记录下synthetic方法和bridge方法。 synthetic方法synthetic方法是什么呢？先来看个实际例子： 123456789101112131415161718192021222324252627public class SyntheticTest &#123; private int i; public void setI(int i) &#123; this.i = i; &#125; public class A &#123; private int j; public int sum() &#123; return j + i; &#125; public void setJ(int j) &#123; this.j = j; &#125; &#125; public static void main(String[] args) &#123; SyntheticTest syntheticTest = new SyntheticTest(); A a = syntheticTest.new A(); a.setJ(1); System.out.println("sum=" + a.sum()); &#125;&#125; 当你创建一个嵌套类（内部类）时，顶层类的私有属性和私有方法对内部类是可见的。然而jvm是如何处理这种情况的呢？jvm可不清楚什么是内部嵌套类，什么是顶层类。jvm对所有的类都一视同仁，它都认为是顶级类。所有类都会被编译成顶级类，而那些内部类编译完后会生成…$… class的类文件，如下javac编译： 123$ javac SyntheticTest.java$ lsSyntheticTest$A.class SyntheticTest.class SyntheticTest.java 当你创建内部类时，他会被编译成顶级类。那顶层类的私有属性和私有方法是如何被外部类访问的呢？ javac是这样解决这个问题的，对于任何private的字段，方法或者构造函数，如果它们也被其它顶层类所使用，就会生成一个synthetic方法。这些synthetic方法是用来访问最初的私有变量/方法/构造函数的。这些方法的生成也很智能：只有确实被外部类用到了，才会生成这样的方法 通过反编译SyntheticTest$A.class： 123456789101112131415public class SyntheticTest$A &#123; private int j; public SyntheticTest$A(SyntheticTest var1) &#123; this.this$0 = var1; &#125; public int sum() &#123; return this.j + SyntheticTest.access$000(this.this$0); &#125; public void setJ(int var1) &#123; this.j = var1; &#125;&#125; 有个奇怪的方法SyntheticTest.access$000(this.this$0)，这个就是java的synthetic方法。可以用java的反射再次验证这个问题： 12345public static void main(String[] args) &#123; for (Method method : SyntheticTest.class.getDeclaredMethods()) &#123; System.out.println(method.getName() + " is synthetic method:" + method.isSynthetic()); &#125;&#125; 输出： 123main is synthetic method:falseaccess$000 is synthetic method:truesetI is synthetic method:false 可以看到access$000这个方法，确实是一个synthetic方法 synthetic方法就是java编译器(例如javac)为了实现特定需求增加的方法，不存在源码中的 bridge方法bridge方法又是什么呢？看个简单例子： 123456789101112131415public class BridgeTest &#123; public static class MyLink extends LinkedList &#123; @Override public String get(int index) &#123; return "my list " + index; &#125; &#125; public static void main(String[] args) &#123; for (Method method : MyLink.class.getDeclaredMethods()) &#123; System.out.println(method.toString() + " is bridge method:" + method.isBridge()); &#125; &#125;&#125; 输出如下: 12public java.lang.String com.zacard.algorithm.test.BridgeTest$MyLink.get(int) is bridge method:falsepublic java.lang.Object com.zacard.algorithm.test.BridgeTest$MyLink.get(int) is bridge method:true 可以看到，多出来一个方法签名一致，返回类型为Object的bridge方法，这在java语言中是不合法的，不过在jvm中是允许的。那这个bridge方法到底作了什么呢？反编译看看： 1javap -c BridgeTest\$MyLink 输出如下： 1234567891011121314151617181920212223242526public class com.zacard.algorithm.test.BridgeTest$MyLink extends java.util.LinkedList &#123; public com.zacard.algorithm.test.BridgeTest$MyLink(); Code: 0: aload_0 1: invokespecial #1 // Method java/util/LinkedList."&lt;init&gt;":()V 4: return public java.lang.String get(int); Code: 0: new #2 // class java/lang/StringBuilder 3: dup 4: invokespecial #3 // Method java/lang/StringBuilder."&lt;init&gt;":()V 7: ldc #4 // String my list 9: invokevirtual #5 // Method java/lang/StringBuilder.append:(Ljava/lang/String;)Ljava/lang/StringBuilder; 12: iload_1 13: invokevirtual #6 // Method java/lang/StringBuilder.append:(I)Ljava/lang/StringBuilder; 16: invokevirtual #7 // Method java/lang/StringBuilder.toString:()Ljava/lang/String; 19: areturn public java.lang.Object get(int); Code: 0: aload_0 1: iload_1 2: invokevirtual #8 // Method get:(I)Ljava/lang/String; 5: areturn&#125; 可以看到，这个birdge不干别的，仅仅就是调用了原始的那个方法。所以这个方法到底有什么用,为什么需要bridge方法？看一下java手册的说明： When compiling a class or interface that extends a parameterized class or implements a parameterized interface, the compiler may need to create a synthetic method, called a bridge method, as part of the type erasure process. You normally don’t need to worry about bridge methods, but you might be puzzled if one appears in a stack trace. 如果一个类继承了一个范型类或者实现了一个范型接口, 那么编译器在编译这个类的时候就会生成一个叫做桥接方法的混合方法(混合方法简单的说就是由编译器生成的方法, 方法上有synthetic修饰符), 这个方法用于范型的类型安全处理,用户一般不需要关心桥接方法 其实是java为了泛型的向下兼容的一种手段。我们看下另一个例子： 1234567891011121314151617181920public class BridgeTest2 &#123; public static class Node&lt;T&gt;&#123; private T data; public void setData(T data) &#123; System.out.println("Node.setData"); this.data = data; &#125; &#125; public static class MyNode extends Node&lt;Integer&gt; &#123; @Override public void setData(Integer data) &#123; System.out.println("MyNode.setData"); super.setData(data); &#125; &#125;&#125; 这个类在泛型擦除后，变成如下形式： 1234567891011121314151617181920public class BridgeTest2 &#123; public static class Node&#123; private Object data; public void setData(Object data) &#123; System.out.println("Node.setData"); this.data = data; &#125; &#125; public static class MyNode extends Node &#123; @Override public void setData(Integer data) &#123; System.out.println("MyNode.setData"); super.setData(data); &#125; &#125;&#125; 子类的setData方法签名和父类的已经不一致了。因此，MyNode.setData方法其实已经不再重写（override）父类Node.setData方法了。 为了解决这个问题，并且维持泛型类在泛型擦除后的多态性，java编译器会生成一个bridge方法]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Service Mesh - 服务网格]]></title>
      <url>%2F2018%2F02%2F12%2Fservice-mesh%2F</url>
      <content type="text"><![CDATA[什么是service mesh 服务网格是一个基础设施层，功能在于处理服务间通信，职责是负责实现请求的可靠传递。在实践中，服务网格通常实现为轻量级网络代理，通常与应用程序部署在一起，但是对应用程序透明 可以将它比作是微服务间的TCP/IP，负责服务之间的网络调用、限流、熔断、监控等功能。对于编写应用程序来说一般无须关心TCP/IP这一层（比如通过HTTP协议的RESTful应用），同样使用service mesh也就无须关心服务之间的那些原来是通过应用程序或者其他框架实现的事情，比如spring cloud，现在只要交给service mesh就可以了 另一方面，service mesh更强调由这些代理连接而形成的网络，而不仅仅是一个网络代理(sidecar)。 为什么要有service mesh因为，基于框架或者类库实现的网络代理存在诸多弊端 内容多，门槛高例如spring cloud： spring-cloud-common spring-cloud-netflix spring-cloud-sleuth spring-cloud-gateway spring-cloud-bus spring-cloud-consul spring-cloud-config spring-cloud-security spring-cloud-zookeeper spring-cloud-aws spring-cloud-cloudfoundry … 团队成员学习并吃透这些东西，需要大量时间与精力。然而这些技术是实现微服务化的手段，真正的目标是实现业务。时间人力可能远远不足。 微服务化我们有更艰巨的挑战：微服务拆分、边界设定、设计良好的api等 服务治理功能不够完善服务治理常见的功能如下： Spring Cloud直接提供的功能是远远不够的。很多功能都需要你在Spring Cloud的基础上自己解决 无法跨语言微服务一个重要的特性：就是不同的微服务可以采用最适合的编程语言来编写 然而我们的框架类库，需要提供多少语言的SDK呢？ 如何升级框架不可能一开始就完美无缺，所有功能都齐备，没有任何BUG，分发出去之后就再也不需要改动，这种理想状态不存在的。必然是1.0、2.0、3.0慢慢升级，功能逐渐增加，BUG逐渐被修复 然而使用者并不能都马上跟进升级，一旦客户端和服务器端版本不一致，就要非常小心维护兼容性 版本兼容性有多复杂？服务端数以百计起，客户端数以千计起，每个的版本都有可能不同。这是一个笛卡尔乘积。但是别忘了，还有一个前面说的编程语言的问题，你还得再乘个N！这种情况下，兼容性测试需要写多少个Case，这几乎是不可能的 service mesh演进 ps:sidecar就是框架或者类库的方式 service mesh演进是一个技术栈下移的过程。形成一个独立进程，代理服务所有流量，可单独升级，对应用程序透明 思考这部分基于本人对service mesh初步认知，属于个人不成熟的想法，欢迎各位大牛斧正！ service mesh有什么缺点？个人觉得，相比较框架或者类库的形式，service mesh还是有部分不好实现的功能： 熔断后的回落： 例如，service mesh熔断后的回落操作就比较局限。对于service mesh来说，服务故障的真实原因是隐蔽的，服务调用端可能只能捕获调用异常和约定来处理。而基于框架或者类库，我们有更多可选择的优雅降级方式：返回缓存值、返回缺省值甚至去调用其他不同的服务 分布式追踪系统(APM)不能精细控制到本地方法级 个人想法语言兼容与代码级精细控制，本身就是一个矛盾点。相比service mesh提供的便利，其缺点可以忽略不计 推荐阅读Service Mesh：下一代微服务]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[分布式追踪系统x-apm开发拾遗之javaagent]]></title>
      <url>%2F2018%2F02%2F09%2Fapm-lost-1%2F</url>
      <content type="text"><![CDATA[背景x-apm开发周期比较短，开发过程中用到的一些知识点没有深入理解，这里记录下apm用到的入口知识点 – javaagent 什么是javaagentjavaagent是Java中用来增强JVM上的应用的一种方式，这样的agent有机会修改目标应用或者应用所运行的环境。它可通过访问Java Instrumentation API来修改目标应用程序的class字节码 为什么要有javaagent 暴露一些特定功能。比如运行时获得所有已加载类的字节码 对于特定类做低侵入甚至无侵入的增强。比如对某个类的某个方法插入特定逻辑 所以，javaagent的主要功能其实类似aop，但是其原理是加载class文件之前做拦截，直接修改字节码，或者运行时动态修改字节码；而aop是生成一个新的代理类 如何编写javaagent核心api：java.lang.instrument.Instrumentation Instrumentation其中一个优点就是能够让我们注册ClassFileTransformers。一个已注册的ClassFileTransformer将拦截所有应用程序类的加载，并能够访问他们的字节码。同时，也可以修改类的字节码 入口是一个premain方法： 123456789101112131415public class JavaAgentTest &#123; public static void premain(String args, Instrumentation instrumentation) &#123; // 仅仅只是保存了字节码到本地文件 instrumentation.addTransformer((loader, className, classBeingRedefined, protectionDomain, classfileBuffer) -&gt; &#123; Path path = Paths.get("classes/" + className + ".class"); try &#123; Files.write(path, classfileBuffer); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; return classfileBuffer; &#125;); &#125;&#125; 启动：java -javaagent:/path/to/agent.jar -jar app.jar]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[机器学习基础 - 熵&交叉熵&相对熵]]></title>
      <url>%2F2018%2F01%2F28%2Fmachelearning-1-entropy%2F</url>
      <content type="text"><![CDATA[摘录自知乎：https://www.zhihu.com/question/41252833/answer/195901726 讨论这个问题需要从香农的信息熵开始。小明在学校玩王者荣耀被发现了，爸爸被叫去开家长会，心里悲屈的很，就想法子惩罚小明。到家后，爸爸跟小明说：既然你犯错了，就要接受惩罚，但惩罚的程度就看你聪不聪明了。这样吧，我们俩玩猜球游戏，我拿一个球，你猜球的颜色，你每猜一次，不管对错，你就一个星期不能玩王者荣耀，当然，猜对，游戏停止，否则继续猜。当然，当答案只剩下两种选择时，此次猜测结束后，无论猜对猜错都能100%确定答案，无需再猜一次，此时游戏停止（因为好多人对策略１的结果有疑问，所以请注意这个条件）。 题目1：爸爸拿来一个箱子，跟小明说：里面有橙、紫、蓝及青四种颜色的小球任意个，各颜色小球的占比不清楚，现在我从中拿出一个小球，你猜我手中的小球是什么颜色？为了使被罚时间最短，小明发挥出最强王者的智商，瞬间就想到了以最小的代价猜出答案，简称策略1，小明的想法是这样的。 在这种情况下，小明什么信息都不知道，只能认为四种颜色的小球出现的概率是一样的。所以，根据策略1，1/4概率是橙色球，小明需要猜两次，1/4是紫色球，小明需要猜两次，其余的小球类似，所以小明预期的猜球次数为：H = 1/4 * 2 + 1/4 * 2 + 1/4 * 2 + 1/4 * 2 = 2 题目2：爸爸还是拿来一个箱子，跟小明说：箱子里面有小球任意个，但其中1/2是橙色球，1/4是紫色球，1/8是蓝色球及1/8是青色球。我从中拿出一个球，你猜我手中的球是什么颜色的？小明毕竟是最强王者，仍然很快得想到了答案，简称策略2，他的答案是这样的。 在这种情况下，小明知道了每种颜色小球的比例，比如橙色占比二分之一，如果我猜橙色，很有可能第一次就猜中了。所以，根据策略2，1/2的概率是橙色球，小明需要猜一次，1/4的概率是紫色球，小明需要猜两次，1/8的概率是蓝色球，小明需要猜三次，1/8的概率是青色球，小明需要猜三次，所以小明预期的猜题次数为：H = 1/2 * 1 + 1/4 * 2 + 1/8 * 3 + 1/8 * 3= 1.75 题目3：其实，爸爸只想让小明意识到自己的错误，并不是真的想罚他，所以拿来一个箱子，跟小明说：里面的球都是橙色，现在我从中拿出一个，你猜我手中的球是什么颜色？最强王者怎么可能不知道，肯定是橙色，小明需要猜0次。上面三个题目表现出这样一种现象：针对特定概率为p的小球，需要猜球的次数 = ，例如题目2中，1/4是紫色球， = 2 次，1/8是蓝色球， = 3次。那么，针对整个整体，预期的猜题次数为： ，这就是信息熵，上面三个题目的预期猜球次数都是由这个公式计算而来，第一题的信息熵为2，第二题的信息熵为1.75，最三题的信息熵为1 * = 0 。 那么信息熵代表着什么含义呢？信息熵代表的是随机变量或整个系统的不确定性，熵越大，随机变量或系统的不确定性就越大。 题目1的熵 &gt; 题目2的熵 &gt; 题目3的熵。在题目1中，小明对整个系统一无所知，只能假设所有的情况出现的概率都是均等的，此时的熵是最大的。 题目2中，小明知道了橙色小球出现的概率是1/2及其他小球各自出现的概率，说明小明对这个系统有一定的了解，所以系统的不确定性自然会降低，所以熵小于2。 题目3中，小明已经知道箱子中肯定是橙色球，爸爸手中的球肯定是橙色的，因而整个系统的不确定性为0，也就是熵为0。 所以，在什么都不知道的情况下，熵会最大，针对上面的题目1~~题目3，这个最大值是2，除此之外，其余的任何一种情况，熵都会比2小。所以，每一个系统都会有一个真实的概率分布，也叫真实分布，题目1的真实分布为（1/4，1/4，1/4，1/4），题目2的真实分布为（1/2，1/4，1/8，1/8），而根据真实分布，我们能够找到一个最优策略，以最小的代价消除系统的不确定性，而这个代价大小就是信息熵，记住，信息熵衡量了系统的不确定性，而我们要消除这个不确定性，所要付出的【最小努力】（猜题次数、编码长度等）的大小就是信息熵。 具体来讲，题目1只需要猜两次就能确定任何一个小球的颜色，题目2只需要猜测1.75次就能确定任何一个小球的颜色。现在回到题目2，假设小明只是钻石段位而已，智商没王者那么高，他使用了策略1，即 爸爸已经告诉小明这些小球的真实分布是（1/2，1/4, 1/8，1/8），但小明所选择的策略却认为所有的小球出现的概率相同，相当于忽略了爸爸告诉小明关于箱子中各小球的真实分布，而仍旧认为所有小球出现的概率是一样的，认为小球的分布为（1/4，1/4，1/4，1/4），这个分布就是非真实分布。此时，小明猜中任何一种颜色的小球都需要猜两次，即1/2 * 2 + 1/4 * 2 + 1/8 * 2 + 1/8 * 2 = 2。很明显，针对题目2，使用策略1是一个坏的选择，因为需要猜题的次数增加了，从1.75变成了2，小明少玩了1.75的王者荣耀呢。因此，当我们知道根据系统的真实分布制定最优策略去消除系统的不确定性时，我们所付出的努力是最小的，但并不是每个人都和最强王者一样聪明，我们也许会使用其他的策略（非真实分布）去消除系统的不确定性，就好比如我将策略1用于题目2（原来这就是我在白银的原因）. 那么，当我们使用非最优策略消除系统的不确定性，所需要付出的努力的大小我们该如何去衡量呢？这就需要引入交叉熵，其用来衡量在给定的真实分布下，使用非真实分布所指定的策略消除系统的不确定性所需要付出的努力的大小。正式的讲，交叉熵的公式为： ，其中p_k表示真实分布，q_k表示非真实分布。例如上面所讲的将策略1用于题目2，真实分布: 非真实分布: 交叉熵为: 比最优策略的1.75来得大。因此，交叉熵越低，这个策略就越好，最低的交叉熵也就是使用了真实分布所计算出来的信息熵，因为此时 p_k=q_k ，交叉熵 = 信息熵。 这也是为什么在机器学习中的分类算法中，我们总是最小化交叉熵，因为交叉熵越低，就证明由算法所产生的策略最接近最优策略，也间接证明我们算法所算出的非真实分布越接近真实分布。 最后，我们如何去衡量不同策略之间的差异呢？这就需要用到相对熵，其用来衡量两个取值为正的函数或概率分布之间的差异，即：KL(f(x) || g(x)) = 现在，假设我们想知道某个策略和最优策略之间的差异，我们就可以用相对熵来衡量这两者之间的差异。即，相对熵 = 某个策略的交叉熵 - 信息熵（根据系统真实分布计算而得的信息熵，为最优策略），公式如下： KL（p || q） = H（p，q） - H（p) = 所以将策略1用于题目2，所产生的相对熵为2 - 1.75 = 0.25.]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[深度学习(deep learning)记录 - 初步概念]]></title>
      <url>%2F2018%2F01%2F12%2Fdeeplearning-1%2F</url>
      <content type="text"><![CDATA[仅以此图，催眠我学习deep learning的动力！ 深度学习的实质无非如此：根据模型产生的误差调整模型中的诸多权重，直到误差不能再减少为止 Bias（偏差）&amp;Variance（方差）&amp;Error(误差)的区别首先Error = Bias + Variance Error反映的是整个模型的准确度 Bias反映的是模型在样本上的输出与真实值之间的误差，即模型本身的精准度 Variance反映的是模型每一次输出结果与模型输出期望之间的误差，即模型的精确性 在一个实际系统中，Bias与Variance往往是不能兼得的。如果要降低模型的Bias，就一定程度上会提高模型的Variance，反之亦然。造成这种现象的根本原因是，我们总是希望试图用有限训练样本去估计无限的真实数据。当我们更加相信这些数据的真实性，而忽视对模型的先验知识，就会尽量保证模型在训练样本上的准确度，这样可以减少模型的Bias。但是，这样学习到的模型，很可能会失去一定的泛化能力，从而造成过拟合，降低模型在真实数据上的表现，增加模型的不确定性。相反，如果更加相信我们对于模型的先验知识，在学习模型的过程中对模型增加更多的限制，就可以降低模型的variance，提高模型的稳定性，但也会使模型的Bias增大。Bias与Variance两者之间的trade-off(权衡)是机器学习的基本主题之一。 准：bias描述的是根据样本拟合出的模型的输出预测结果的期望与样本真实结果的差距，简单讲，就是在样本上拟合的好不好。要想在bias上表现好，low bias，就得复杂化模型，增加模型的参数，但这样容易过拟合 (overfitting)，过拟合对应上图是high variance，点很分散。low bias对应就是点都打在靶心附近，所以瞄的是准的，但手不一定稳。 确：varience描述的是样本上训练出来的模型在测试集上的表现，要想在variance上表现好，low varience，就要简化模型，减少模型的参数，但这样容易欠拟合(unfitting)，欠拟合对应上图是high bias，点偏离中心。low variance对应就是点都打的很集中，但不一定是靶心附近，手很稳，但是瞄的不准。 什么是欠拟合(unfitting)&amp;过拟合(overfitting) 欠拟合就是模型能力不足，偏差大。(图1：higt bias) 过拟合就是模型对于训练数据拟合过于完美，方差大。(图3：high variance) 如何解决欠拟合调整模型参数，增加样本数量 如何解决过拟合减少特征数量，手动选择一些需要保留的特征，正则化(regularization)。常见正则化有L2正则(常用)，L1正则 ps:所以正则化就是为了解决过拟合，why？ 模型参数&amp;超参数 模型参数就是模型内部的配置变量，可以用数据估计它的值 模型超参数是模型外部的配置，其值不能从数据估计得到 模型参数的一些例子包括： 神经网络中的权重 支持向量机中的支持向量 线性回归或逻辑回归中的系数 参数用来处理输入数据的系数，神经网络在学习过程中不断调整参数，直至能准确预测――此时就得到了一个比较准确的模型 模型超参数的一些例子包括： 训练神经网络的学习速率(learning rate) 支持向量机的C和sigma超参数 k邻域中的k 每一项超参数就如同一道菜里的一种食材：取决于食材好坏，这道菜也许非常可口，也可能十分难吃…… 神经网络的激活函数为什么要有激活函数？加入激活函数是用来加入非线性因素的，解决线性模型所不能解决或者很难解决的问题。参考link 输出层的激活函数相当于逻辑回归函数，例如softmax。该层函数的选择具体取决于你更能容忍哪一类的错误：选择标准过低会增加取伪错误的数量，标准过高会增加弃真错误的数量 归一化归一化方法：把数变为（0，1）之间的小数。主要是为了数据处理方便提出来的，把数据映射到0～1范围之内处理，更加便捷快速。加快收敛，把各个特征的尺度控制在相同的范围内,加快梯度下降 梯度下降常见的为随机梯度下降(Stochastic Gradient Descent，SGD).是一种用于优化代价函数的常见方法. – 参考Andrew Ng的机器学习课程第2节 学习速率（learning rate）即每次迭代时对于权重的调整幅度，亦称步幅。学习速率越高，神经网络“翻越”整个误差曲面的速度就越快，但也更容易错过误差极小点。学习速率较低时，网络更有可能找到极小值，但速度会变得非常慢，因为每次权重调整的幅度都比较小. 其实就是梯度下降每次下降的步幅 动量（Momentum）动量是另一项决定优化算法向最优值收敛的速度的因素。 如果您想要加快定型速度，可以提高动量。但定型速度加快可能会降低模型的准确率。 更深入来看，动量是一个范围在0～1之间的变量，是矩阵变化速率的导数的因数。它会影响权重随时间变化的速率。 训练网络时，通常先对网络的初始权值按照某种分布进行初始化，如：高斯分布。初始化权值操作对最终网络的性能影响比较大，合适的网络初始权值能够使得损失函数在训练过程中的收敛速度更快，从而获得更好的优化结果。但是按照某类分布随机初始化网络权值时，存在一些不确定因素，并不能保证每一次初始化操作都能使得网络的初始权值处在一个合适的状态。不恰当的初始权值可能使得网络的损失函数在训练过程中陷入局部最小值，达不到全局最优的状态。因此，如何消除这种不确定性，是训练深度网络是必须解决的一个问题。 momentum 动量能够在一定程度上解决这个问题。momentum 动量是依据物理学的势能与动能之间能量转换原理提出来的。当 momentum 动量越大时，其转换为势能的能量也就越大，就越有可能摆脱局部凹域的束缚，进入全局凹域。momentum 动量主要用在权重更新的时候。 一般，神经网络在更新权值时，采用如下公式: w = w - learning_rate * dw,引入momentum后，采用如下公式： v = mu * v - learning_rate * dw w = w + v 其中，v初始化为0，mu是设定的一个超变量，最常见的设定值是0.9。可以这样理解上式：如果上次的momentum(v)与这次的负梯度方向是相同的，那这次下降的幅度就会加大，从而加速收敛。 什么是隐层(hidden layer)隐藏层中的每个节点表示数据集中数据的一项特征。模型的系数按照重要性大小为这些特征赋予权重，随后在每个隐藏层中重新相加，帮助预测。节点的层数更多，网络就能处理更复杂的因素，捕捉更多细节，进而做出更准确的预测。 之所以将中间的层称为“隐藏”层，是因为人们可以看到数据输入神经网络、判定结果输出，但网络内部的数据处理方式和原理并非一目了然。神经网络模型的参数其实就是包含许多数字、计算机可以读取的长向量 如何选择神经网络下表列出了各种不同的问题和每种问题最适用的神经网络： 数据类型 应用案例 输入 变换 神经网络 文本 情感分析 词向量 高斯修正 RNTN或DBN（采用移动窗口） 文本 命名实体识别 词向量 高斯修正 RNTN或DBN（采用移动窗口） 文本 词性标注 词向量 高斯修正 RNTN或DBN（采用移动窗口） 文本 词性标注 词向量 高斯修正 RNTN或DBN（采用移动窗口） 文本 语义角色标记 词向量 高斯修正 RNTN或DBN（采用移动窗口） 文档 主题建模/语义哈希（无监督） 词频概率 可为二进制 深度自动编码器（包装一个DBN或SDA） 文档 文档分类（有监督） TF-IDF（或词频概率） 二进制 深度置信网络、堆叠式降噪自动编码器 图像 图像识别 二进制 二进制（可见及隐藏层） 深度置信网络 图像 图像识别 连续 高斯修正 深度置信网络 图像 多对象识别 N/A 高斯修正 卷积网络、RNTN（图像向量化） 图像 图像搜索/语义哈希 N/A 高斯修正 深度自动编码器（包装一个DBN） 声音 语音识别 N/A 高斯修正 循环网络 声音 语音识别 N/A 高斯修正 移动窗口，DBN或卷积网络 时间序列 预测分析 N/A 高斯修正 循环网络 时间序列 预测分析 N/A 高斯修正 移动窗口，DBN或卷积网络 注：高斯修正 = Gaussian Rectified | 语义哈希 = Semantic Hashing]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[elasticsearch官网文档阅读记录]]></title>
      <url>%2F2017%2F12%2F12%2Felasticsearch-query%2F</url>
      <content type="text"><![CDATA[本文根据官网文档及对公司日志平台es升级调优经验分享，如有错误，欢迎斧正。 主题 环境调优 - 磨刀不误砍柴工 概念普及 - 步调一致 如何合理高效查询 - 查询说明 如果合理高效的写入（另外写） 环境调优是先决条件，应对查询和写入都有帮助。重点分享查询，因为目前业务没有高频写入的场景 环境调优注意：配置只针对centos，其他系统未做测试。 设置elasticsearch的jvm内存编辑jvm.options，添加一下内容： 12-Xms8g -Xmx8g 注意：具体大小应当&lt;=系统内存的一半，建议直接设置为系统内存的一半 禁用swap交换空间 大多数操作系统试图尽可能多地为文件系统缓存使用内存，并急切地交换掉未使用的应用程序内存。这可能会导致JVM堆的部分甚至将其可执行页被交换到磁盘。 交换对于性能、节点稳定性是非常不利的，应该不惜一切代价避免。它可能导致垃圾收集持续数分钟而不是毫秒，并可能导致节点响应缓慢，甚至可能断开与群集的连接。 禁用虚拟内存,并让jvm锁定内存： swapoff -a 编辑文件/etc/fstab，注释掉所有包含swap的行 编辑文件elasticsearch.yml，添加配置bootstrap.memory_lock: true 验证是否锁定内存成功： 1curl -XGET &apos;http://121.41.84.118:9210/_nodes?filter_path=**.mlockall&amp;pretty&apos; 调整文件句柄数量 Lucene 使用了 大量的 文件。 同时，Elasticsearch 在节点和 HTTP 客户端之间进行通信也使用了大量的套接字（注：sockets）。所有这一切都需要足够的文件描述符 先临时设置允许的文件句柄数量： sudo su ulimit -n 65536 su elasticsearch 以上确保在当前session生效，再永久设置： 编辑/etc/security/limits.conf，添加一行，内容为elasticsearch - nofile 65536 验证是否设置成功： 1curl -XGET &apos;http://121.41.84.118:9210/_nodes/stats/process?filter_path=**.max_file_descriptors&amp;pretty&apos; 调整文件映射数量 Elasticsearch 对各种文件混合使用了 NioFs（ 注：非阻塞文件系统）和 MMapFs （ 注：内存映射文件系统）。请确保你配置的最大映射数量，以便有足够的虚拟内存可用于 mmapped 文件 先临时设置： 1sysctl -w vm.max_map_count=262144 再永久修改： 编辑/etc/sysctl.conf，添加vm.max_map_count=262144 调整允许的线程数量1ulimit -u 4096 概念普及index(名词)：索引 ≈ mysql中的库（database）type：类型 ≈ mysql中的表document：文档 ≈ mysql中的一行数据share：分片 ≈ mysql中的数据分表replicas：副本，即数据分片备份 index(动词)：为文档创建索引 分片与副本一个索引应设置几个分片，几个副本才合理？ 副本分片副本用来应对不断攀升的吞吐量以及确保数据的安全性.副本可以动态改变，默认为1份副本，比较合理。 当查询吞吐量跟不上时，可以考虑增加副本数量。 分片分片无法动态指定，只能在创建index的时候指定。（why？）但是默认设置5个分片，这通常来说属于过度分配，这是作者考虑到数据迁移成本的权衡。 原则就是最小分片。多个分片对于查询和写入都有额外消耗。 什么时候该违反这个原则？ 由于单个分片有数量上限（Integer.MAX_VALUE=2147483647） 单机资源限制，如单个分片所占用磁盘过大 为了吞吐量和单机热点，大数量写入被分到不同集群中的不同分片中，避免频繁写入占用过多系统资源，从这点看，也能加快查询吞吐量 所以，根据“经验法则”，小集群时合理的分片数量==节点数量 如何合理高效查询elasticsearch的查询可以在主分片和副本分片查询 查询流程根据_id查询流程图： 以下是从主分片或者副本分片检索文档的步骤顺序： 客户端向Node 1发送获取请求 节点使用文档的 _id 来确定文档属于分片 0 。分片 0 的副本分片存在于所有的三个节点上。 在这种情况下，它将请求转发到Node 2 Node 2将文档返回给Node 1，然后将文档返回给客户端 在处理读取请求时，协调结点在每次请求的时候都会通过轮询所有的副本分片来达到负载均衡 如果查询有全文检索和聚合操作（例如排序），elasticsearch需要每个分片都执行查询，并把结果返回给协调节点，由协调节点进行聚合操作后再返回被客户端。 如何路由一个文档到一个分片根据以下公式： shard = hash(routing) % number_of_primary_shards routing 是一个可变值，默认是文档的 _id ，也可以设置成一个自定义的值。 routing 通过 hash 函数生成一个数字，然后这个数字再除以 number_of_primary_shards （主分片的数量）后得到 余数 这也是为何副本数量能够动态修改，而分片数量需要创建索引时就确定好 – 因为如果分片数量变化了，那么所有之前路由的值都会无效，文档也再也找不到了 查询原理 倒排索引 精确值 &amp; 全文域 query查询 &amp; filter查询 倒排索引 倒排索引为何叫倒排索引？ 一个普通的数据库中，一般是以文档ID作为索引，以文档内容作为记录。而倒排索引指的是将单词或记录作为索引，将文档ID作为记录，这样便可以方便地通过单词或记录查找到其所在的文档。刚好倒过来。 思考：有没有更好快的数据结构？如果有，为何不用？ 精确值 &amp; 全文域elasticsearch中数据类型大致可以分为2类：精确值和全文域 精确值如它们听起来那样精确。例如日期或者用户ID，但字符串也可以表示精确值，例如用户名或邮箱地址。对于精确值来讲，Foo和foo是不同的，2014和2014-09-15也是不同的 精确值很容易查询。结果是明确的：要么匹配查询，要么不匹配 全文通常是指非结构化的数据，但这里有一个误解：自然语言是高度结构化的。问题在于自然语言的规则是复杂的，导致计算机难以正确解析 查询全文数据要微妙的多。我们问的不只是“这个文档匹配查询吗”，而是“该文档匹配查询的程度有多大？”换句话说，该文档与给定查询的相关性如何？ 我们很少对全文类型的域做精确匹配。相反，我们希望在文本类型的域中搜索。不仅如此，我们还希望搜索能够理解我们的意图： 搜索 UK ，会返回包含 United Kindom 的文档。 搜索 jump ，会匹配 jumped ， jumps ， jumping ，甚至是 leap 。 搜索 johnny walker 会匹配 Johnnie Walker ， johnnie depp 应该匹配 Johnny Depp fox news hunting 应该返回福克斯新闻（ Foxs News ）中关于狩猎的故事，同时，fox hunting news 应该返回关于猎狐的故事 举例：西红柿&amp;番茄、芝士 &amp; 奶酪 分页原理Elasticsearch 接受 from 和 size 参数： size显示应该返回的结果数量，默认是 10from显示应该跳过的初始结果数量，默认是 0 考虑到分页过深以及一次请求太多结果的情况，结果集在返回之前先进行排序。 但请记住一个请求经常跨越多个分片，每个分片都产生自己的排序结果，这些结果需要进行集中排序以保证整体顺序是正确的 注意：谨慎使用深度分页 理解为什么深度分页是有问题的，我们可以假设在一个有 5 个主分片的索引中搜索。 当我们请求结果的第一页（结果从 1 到 10 ），每一个分片产生前 10 的结果，并且返回给 协调节点 ，协调节点对 50 个结果排序得到全部结果的前 10 个。 现在假设我们请求第 1000 页–结果从 10001 到 10010 。所有都以相同的方式工作除了每个分片不得不产生前10010个结果以外。 然后协调节点对全部 50050 个结果排序最后丢弃掉这些结果中的 50040 个结果。 可以看到，在分布式系统中，对结果排序的成本随分页的深度成指数上升。这就是 web 搜索引擎对任何查询都不要返回超过 1000 个结果的原因 elasticsearch默认限制最多分页10000条数据，可以用index.max_result_window参数覆盖配置]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[分布式追踪系统x-apm开发经历分享]]></title>
      <url>%2F2017%2F11%2F06%2Fapm-share%2F</url>
      <content type="text"><![CDATA[感谢@dingdang对开发的强力支持。 背景在公司微服务化转型后，系统被拆分为多个由不同开发团队维护的分布式微服务。随着业务的发展，分布式服务越来越多，其关系越来越复杂。我们亟需一个工具能够梳理内部服务之间的关系，感知上下游服务的形态，快速定位冗长服务调用间的问题。 需要解决的核心问题： 一次请求的完整调用链 一次请求出现异常，能快速定位那个节点出现问题 一次请求经历的服务的详细信息 一次请求的瓶颈节点，并对节点资源分配提供数据支持 一次请求中出现异常、超时自动报警 简介为了解决以上问题，自研了一个分布式追踪系统X-APM(APM = Application Performance Management，应用性能管理).其核心就是调用链：通过一个全局的ID将分布在各个服务节点上的同一次请求串联起来，还原原有的调用关系、追踪系统问题、分析调用数据、统计系统指标。在阅读google 《dapper》的思想，open traceing的理念后,实现参考了skywalking 设计目标 低损耗: 对微服务的影响越低越好，包括cpu、内存、tps、响应时间等指标 低侵入: 作为非业务组件，应当尽可能少侵入或者无侵入其他业务系统，对于使用方透明，减少开发人员的负担 低延迟: 从数据的产生和收集，到数据计算和处理，再到最终展现，都要求尽可能快 可配置: 可以通过配置决定所收集数据的范围和粒度 可视化: 能够以图表方式展示调用链路等信息 可预警: 分析跟踪到的调用链数据，当出现调用耗时时间过长、调用异常、重复调用等情况，及时警告 决策支持: 这些数据最好能在决策支持层面发挥作用 架构 各业务系统使用x-apm的agent探针来处理调用链路信息的采集，当采集的信息达到一定量或每隔一段特定的时间时，agent将会把这些信息传送到Flume，通过flume的channel缓冲区流向到指定的sink。目前项目一期已支持将数据保存至ES，并通过UI项目读取ES数据，方便大家在页面上以图表的形式查看各业务系统的调用链路信息。 领域模型对于理解分布式追踪系统的领域模型，我强烈建议先阅读open traceing，能够理解在分布式追踪系统中，Trace、Span、Tag等基本概念。 trace一个trace代表一个潜在的，分布式的，存在并行数据或并行执行轨迹（潜在的分布式、并行）的系统。一个trace可以认为是多个span的有向无环图（DAG）。 span一个span代表系统中具有开始时间和执行时长的逻辑运行单元。span之间通过嵌套或者顺序排列建立逻辑因果关系。 trace与span的关系123456789101112131415161718192021222324252627一个tracer过程中，各span的关系 [Span A] ←←←(the root span) | +------+------+ | | [Span B] [Span C] ←←←(Span C 是 Span A 的孩子节点, ChildOf) | | [Span D] +---+-------+ | | [Span E] [Span F] &gt;&gt;&gt; [Span G] &gt;&gt;&gt; [Span H] ↑ ↑ ↑ (Span G 在 Span F 后被调用, FollowsFrom)上述tracer与span的时间轴关系––|–––––––|–––––––|–––––––|–––––––|–––––––|–––––––|–––––––|–&gt; time [Span A···················································] [Span B··············································] [Span D··········································] [Span C········································] [Span E·······] [Span F··] [Span G··] [Span H··] 核心数据结构 简单解释： TraceSegment: 一次分布式Trace中可能会经历多个微服务系统，每个系统都是一个TraceSegment(追踪链的一部分)，所有经过的微服务TraceSegment组合在一起，才是一次完整的Trace Span: 正如open traceing中的概念，记录调用链中某个功能、某个组件的详细信息 TraceSegmentRef: 各个微服务系统的TraceSegment之间的关系(调用顺序) DistributedTraceIds: 记录各个微服务系统的追踪id DistributedTraceId: 分布式追踪id，全局唯一 原理这里只讲agent端的原理。因为后面的数据收集使用flume，数据存储使用elasticsearch，实时流分析使用spark，就不细说了 数据埋点为了无侵入，数据埋点采用javaagent配合bytebuddy完成。 javaagent: 主要利用instrument agent,其可以在加载class文件之前做拦截，对字节码做修改 bytebuddy: 修改字节码 对所有中间件、框架、类库、本地方法的数据埋点，都采用Plugin的形式实现，做到自动化、可插拔、可配置、低耦合。 延伸：javaagent的what、how、why 数据收集由于埋点是动态织入到字节码的功能增强，如何快速高效的收集而不阻塞正常业务系统的流程是个关键。 具体设计考虑： 如何收集数据: 收集的数据在发送前怎么存，收集的速度大于发送的速度的时候，又该怎么办？ 如何发送数据: 异步发送数据到flume，但又不能开启太多线程，以免抢占业务系统线程资源，这个线程数设定多大合适呢？ 如何保证数据完整性: 高并发，大数据量下，如何保证数据的完整性？ 解决方案方案注意点： 埋点数据无需落盘，直接发送到flume.在业务系统节点落盘追踪数据毫无意义，徒耗节点系统资源 埋点数据不能一收到就发送，得批量发送 最终实现： 以数组为基础，实现一个环形结构的无锁数据缓冲区，批量发送埋点数据。数据结构如下： buffer: 缓存区 bufferSize: 缓存区大小 everySendSize: 每次批量发送的数量 currentIndex: 缓存区当前位置索引 实现细节： 对于追踪系统而言，当收集速度大于发送速度，应该果断丢弃数据。因为埋点的数据是可重复的且不能影响业务系统，而且本身很多追踪系统是有采样率的，即不是每次的埋点数据都会收集。当丢弃数据达到一定程度的时候会输出一条警告日志，spark中的日志实时分析会对该日志预警 对于保证数据的完整性，我们采用宁可丢弃数据，也不能有重复数据。因为重复的数据将对后续调用链分析，预警，数据统计，流量分析造成比较大的影响 如何实现环形的缓存区，只需要让缓存区的位置索引currentIndex始终在1~bufferSize内原子变动即可，请看以下示例代码： 12345678// 利用cas操作，获取buffer位置索引 while (true) &#123; int current = currentIndex.get(); int next = current &gt;= bufferSize ? 1 : current + 1; if (currentIndex.compareAndSet(current, next)) &#123; return next; &#125; &#125; 如何实现无锁，核心还是cas操作，请看以下代码示例： 1234567891011// 只有数组中index位置上为null的才设置新值 if (!casObject(index, null, traceSegment)) &#123; return; &#125; // 判断是否需要发送数据 // a % b == a &amp; (b - 1) if ((nextIndex &amp; (everySendSize - 1)) != 0) &#123; return; &#125; // 收集缓冲区数据发送 collectBufferToSend(index, everySendSize); ps: 这里有个强制约定，bufferSize和everySendSize的大小必须为2^n.因为计算是否需要批量发送的时候要用到%操作，%操作是个相对比较昂贵的操作。所以这里我们有个取巧，当计算a%b,且b=2^n的时候，a%b==a&amp;(b-1),位移操作将高效的多。 方案benchmark为了检验环形数据结构的性能，我们专门写了benchmark，使用openjdk.jmh测试，benchmark代码片段如下： 12345678910@Threads(value = Threads.MAX)@Warmup(iterations = 1, time = 10, timeUnit = TimeUnit.MILLISECONDS)@Measurement(iterations = 1, time = 10, timeUnit = TimeUnit.MILLISECONDS)@Fork(value = 1)@Benchmark@BenchmarkMode(value = Mode.Throughput)@OutputTimeUnit(value = TimeUnit.MILLISECONDS)public void benchMarkCollector() &#123; collector(mockData.getAndIncrement());&#125; 可用性 flume挂了怎么办？ agent出异常了怎么办？ agent如何升级？ 解决方案 flume是个集群，单点故障可以无视，有重试机制。当全部flume都挂了的时候，agent端的数据将全部丢失，并且agent端将进入每隔30s的无限重连flume操作 agent的异常被全局catch，输出到日志，后面spark日志实时流分析预警。 agent的升级比较简单，由于项目使用docker部署，所以升级的时候，只要替换docker仓库中的基础镜像中的agent包即可。 性能测试 cpu额外消耗保持在7%以内，内存基本无变化 tps和响应时间基本无变化]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[如何处理InterruptedException]]></title>
      <url>%2F2017%2F09%2F20%2Fhowto-handle-InterruptedException%2F</url>
      <content type="text"><![CDATA[背景一直对于如何合理的处理InterruptedException不是很清晰. 参考以下链接内容理解：传送门 什么是InterruptedException先来看看InterruptedException的java doc说明： Thrown when a thread is waiting, sleeping, or otherwise occupied, and the thread is interrupted, either before or during the activity. Occasionally a method may wish to test whether the current thread has been interrupted, and if so, to immediately throw this exception. The following code can be used to achieve this effect: if (Thread.interrupted()) // Clears interrupted status! throw new InterruptedException(); 就是说只有在线程处于Object.wait()、Thread.sleep()或者被occupied(应该是指类似LockSupport.park()),并且线程被中断时会抛出InterruptedException异常。 如果有某个方法希望测试当前线程是否被中断，如果中断就抛出异常，有个推荐的用法： 12if (Thread.interrupted()) // Clears interrupted status! throw new InterruptedException(); 阻塞方法当一个方法抛出InterruptedException时，它不仅告诉您它可以抛出一个特定的检查异常，而且还告诉您其他一些事情。例如，它告诉您它是一个阻塞（blocking）方法，如果您响应得当的话，它将尝试消除阻塞并尽早返回。 阻塞方法不同于一般的要运行较长时间的方法。一般方法的完成只取决于它所要做的事情，以及是否有足够多可用的计算资源（CPU周期和内存）。而阻塞方法的完成还取决于一些外部的事件，例如计时器到期，I/O 完成，或者另一个线程的动作（释放一个锁，设置一个标志，或者将一个任务放在一个工作队列中）。一般方法在它们的工作做完后即可结束，而阻塞方法较难于预测，因为它们取决于外部事件。阻塞方法可能影响响应能力，因为难于预测它们何时会结束。 阻塞方法可能因为等不到所等的事件而无法终止，因此令阻塞方法可取消就非常有用（如果长时间运行的非阻塞方法是可取消的，那么通常也非常有用）。可取消操作是指能从外部使之在正常完成之前终止的操作。由Thread提供并受Thread.sleep()和Object.wait()支持的中断机制就是一种取消机制；它允许一个线程请求另一个线程停止它正在做的事情。当一个方法抛出 InterruptedException时，它是在告诉您，如果执行该方法的线程被中断，它将尝试停止它正在做的事情而提前返回，并通过抛出InterruptedException表明它提前返回。 行为良好的阻塞库方法应该能对中断作出响应并抛出InterruptedException，以便能够用于可取消活动中，而不至于影响响应。 线程中断每个线程都有一个与之相关联的 Boolean 属性，用于表示线程的中断状态（interrupted status）。中断状态初始时为 false；当另一个线程通过调用 Thread.interrupt() 中断一个线程时，会出现以下两种情况之一。如果那个线程在执行一个低级可中断阻塞方法，例如 Thread.sleep()、 Thread.join() 或 Object.wait()，那么它将取消阻塞并抛出 InterruptedException。否则， interrupt() 只是设置线程的中断状态。 在被中断线程中运行的代码以后可以轮询中断状态，看看它是否被请求停止正在做的事情。中断状态可以通过 Thread.isInterrupted() 来读取，并且可以通过一个名为 Thread.interrupted() 的操作读取和清除。 中断是一种协作机制。当一个线程中断另一个线程时，被中断的线程不一定要立即停止正在做的事情。相反，中断是礼貌地请求另一个线程在它愿意并且方便的时候停止它正在做的事情。有些方法，例如 Thread.sleep()，很认真地对待这样的请求，但每个方法不是一定要对中断作出响应。对于中断请求，不阻塞但是仍然要花较长时间执行的方法可以轮询中断状态，并在被中断的时候提前返回。 您可以随意忽略中断请求，但是这样做的话会影响响应。 中断的协作特性所带来的一个好处是，它为安全地构造可取消活动提供更大的灵活性。我们很少希望一个活动立即停止；如果活动在正在进行更新的时候被取消，那么程序数据结构可能处于不一致状态。中断允许一个可取消活动来清理正在进行的工作，恢复不变量，通知其他活动它要被取消，然后才终止。 处理InterruptedException如果抛出 InterruptedException 意味着一个方法是阻塞方法，那么调用一个阻塞方法则意味着您的方法也是一个阻塞方法，而且您应该有某种策略来处理 InterruptedException。通常最容易的策略是自己抛出 InterruptedException，如清单 1 中 putTask() 和 getTask() 方法中的代码所示。 这样做可以使方法对中断作出响应，并且只需将 InterruptedException 添加到 throws 子句。 清单 1. 不捕捉 InterruptedException，将它传播给调用者： 1234567891011121314public class TaskQueue &#123; private static final int MAX_TASKS = 1000; private BlockingQueue&lt;Task&gt; queue = new LinkedBlockingQueue&lt;Task&gt;(MAX_TASKS); public void putTask(Task r) throws InterruptedException &#123; queue.put(r); &#125; public Task getTask() throws InterruptedException &#123; return queue.take(); &#125;&#125; 有时候需要在传播异常之前进行一些清理工作。在这种情况下，可以捕捉InterruptedException，执行清理，然后抛出异常。清单 2 演示了这种技术，该代码是用于匹配在线游戏服务中的玩家的一种机制。 matchPlayers() 方法等待两个玩家到来，然后开始一个新游戏。如果在一个玩家已到来，但是另一个玩家仍未到来之际该方法被中断，那么它会将那个玩家放回队列中，然后重新抛出 InterruptedException，这样那个玩家对游戏的请求就不至于丢失。清单 2. 在重新抛出 InterruptedException 之前执行特定于任务的清理工作： 123456789101112131415161718192021222324252627public class PlayerMatcher &#123; private PlayerSource players; public PlayerMatcher(PlayerSource players) &#123; this.players = players; &#125; public void matchPlayers() throws InterruptedException &#123; try &#123; Player playerOne, playerTwo; while (true) &#123; playerOne = playerTwo = null; // Wait for two players to arrive and start a new game playerOne = players.waitForPlayer(); // could throw IE playerTwo = players.waitForPlayer(); // could throw IE startNewGame(playerOne, playerTwo); &#125; &#125; catch (InterruptedException e) &#123; // If we got one player and were interrupted, put that player back if (playerOne != null) players.addFirst(playerOne); // Then propagate the exception throw e; &#125; &#125;&#125; 不要生吞中断有时候抛出 InterruptedException 并不合适，例如当由 Runnable 定义的任务调用一个可中断的方法时，就是如此。在这种情况下，不能重新抛出 InterruptedException，但是您也不想什么都不做。当一个阻塞方法检测到中断并抛出 InterruptedException 时，它清除中断状态。如果捕捉到 InterruptedException 但是不能重新抛出它，那么应该保留中断发生的证据，以便调用栈中更高层的代码能知道中断，并对中断作出响应。该任务可以通过调用 interrupt() 以 “重新中断” 当前线程来完成，如清单 3 所示。至少，每当捕捉到 InterruptedException 并且不重新抛出它时，就在返回之前重新中断当前线程。 清单 3. 捕捉 InterruptedException 后恢复中断状态: 1234567891011121314151617181920public class TaskRunner implements Runnable &#123; private BlockingQueue&lt;Task&gt; queue; public TaskRunner(BlockingQueue&lt;Task&gt; queue) &#123; this.queue = queue; &#125; public void run() &#123; try &#123; while (true) &#123; Task task = queue.take(10, TimeUnit.SECONDS); task.execute(); &#125; &#125; catch (InterruptedException e) &#123; // Restore the interrupted status Thread.currentThread().interrupt(); &#125; &#125;&#125; 处理 InterruptedException 时采取的最糟糕的做法是生吞它 —— 捕捉它，然后既不重新抛出它，也不重新断言线程的中断状态。对于不知如何处理的异常，最标准的处理方法是捕捉它，然后记录下它，但是这种方法仍然无异于生吞中断，因为调用栈中更高层的代码还是无法获得关于该异常的信息。（仅仅记录 InterruptedException 也不是明智的做法，因为等到人来读取日志的时候，再来对它作出处理就为时已晚了。） 清单 4 展示了一种使用得很广泛的模式，这也是生吞中断的一种模式： 清单 4. 生吞中断 —— 不要这么做: 1234567891011121314151617181920// Don't do this public class TaskRunner implements Runnable &#123; private BlockingQueue&lt;Task&gt; queue; public TaskRunner(BlockingQueue&lt;Task&gt; queue) &#123; this.queue = queue; &#125; public void run() &#123; try &#123; while (true) &#123; Task task = queue.take(10, TimeUnit.SECONDS); task.execute(); &#125; &#125; catch (InterruptedException swallowed) &#123; /* DON'T DO THIS - RESTORE THE INTERRUPTED STATUS INSTEAD */ &#125; &#125;&#125; 如果不能重新抛出 InterruptedException，不管您是否计划处理中断请求，仍然需要重新中断当前线程，因为一个中断请求可能有多个 “接收者”。标准线程池 （ThreadPoolExecutor）worker 线程实现负责中断，因此中断一个运行在线程池中的任务可以起到双重效果，一是取消任务，二是通知执行线程线程池正要关闭。如果任务生吞中断请求，则 worker 线程将不知道有一个被请求的中断，从而耽误应用程序或服务的关闭。 实现可取消任务语言规范中并没有为中断提供特定的语义，但是在较大的程序中，难于维护除取消外的任何中断语义。取决于是什么活动，用户可以通过一个 GUI 或通过网络机制，例如 JMX 或 Web 服务来请求取消。程序逻辑也可以请求取消。例如，一个 Web 爬行器（crawler）如果检测到磁盘已满，它会自动关闭自己，否则一个并行算法会启动多个线程来搜索解决方案空间的不同区域，一旦其中一个线程找到一个解决方案，就取消那些线程。 仅仅因为一个任务是可取消的，并不意味着需要立即 对中断请求作出响应。对于执行一个循环中的代码的任务，通常只需为每一个循环迭代检查一次中断。取决于循环执行的时间有多长，任何代码可能要花一些时间才能注意到线程已经被中断（或者是通过调用 Thread.isInterrupted() 方法轮询中断状态，或者是调用一个阻塞方法）。 如果任务需要提高响应能力，那么它可以更频繁地轮询中断状态。阻塞方法通常在入口就立即轮询中断状态，并且，如果它被设置来改善响应能力，那么还会抛出 InterruptedException。 惟一可以生吞中断的时候是您知道线程正要退出。只有当调用可中断方法的类是 Thread 的一部分，而不是 Runnable 或通用库代码的情况下，才会发生这样的场景，清单 5 演示了这种情况。清单 5 创建一个线程，该线程列举素数，直到被中断，这里还允许该线程在被中断时退出。用于搜索素数的循环在两个地方检查是否有中断：一处是在 while 循环的头部轮询 isInterrupted() 方法，另一处是调用阻塞方法 BlockingQueue.put()。 清单 5. 如果知道线程正要退出的话，则可以生吞中断: 12345678910111213141516171819public class PrimeProducer extends Thread &#123; private final BlockingQueue&lt;BigInteger&gt; queue; PrimeProducer(BlockingQueue&lt;BigInteger&gt; queue) &#123; this.queue = queue; &#125; public void run() &#123; try &#123; BigInteger p = BigInteger.ONE; while (!Thread.currentThread().isInterrupted()) queue.put(p = p.nextProbablePrime()); &#125; catch (InterruptedException consumed) &#123; /* Allow thread to exit */ &#125; &#125; public void cancel() &#123; interrupt(); &#125;&#125; 不可中断的阻塞方法并非所有的阻塞方法都抛出 InterruptedException。输入和输出流类会阻塞等待 I/O 完成，但是它们不抛出 InterruptedException，而且在被中断的情况下也不会提前返回。然而，对于套接字 I/O，如果一个线程关闭套接字，则那个套接字上的阻塞 I/O 操作将提前结束，并抛出一个 SocketException。java.nio 中的非阻塞 I/O 类也不支持可中断 I/O，但是同样可以通过关闭通道或者请求 Selector 上的唤醒来取消阻塞操作。类似地，尝试获取一个内部锁的操作（进入一个 synchronized 块）是不能被中断的，但是 ReentrantLock 支持可中断的获取模式。 不可取消的任务有些任务拒绝被中断，这使得它们是不可取消的。但是，即使是不可取消的任务也应该尝试保留中断状态，以防在不可取消的任务结束之后，调用栈上更高层的代码需要对中断进行处理。清单 6 展示了一个方法，该方法等待一个阻塞队列，直到队列中出现一个可用项目，而不管它是否被中断。为了方便他人，它在结束后在一个 finally 块中恢复中断状态，以免剥夺中断请求的调用者的权利。（它不能在更早的时候恢复中断状态，因为那将导致无限循环 —— BlockingQueue.take() 将在入口处立即轮询中断状态，并且，如果发现中断状态集，就会抛出 InterruptedException。） 清单 6. 在返回前恢复中断状态的不可取消任务: 12345678910111213141516public Task getNextTask(BlockingQueue&lt;Task&gt; queue) &#123; boolean interrupted = false; try &#123; while (true) &#123; try &#123; return queue.take(); &#125; catch (InterruptedException e) &#123; interrupted = true; // fall through and retry &#125; &#125; &#125; finally &#123; if (interrupted) Thread.currentThread().interrupt(); &#125;&#125;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[zookeeper迁移(扩容/缩容)实践]]></title>
      <url>%2F2017%2F08%2F29%2Fhowto-zookeeper-move%2F</url>
      <content type="text"><![CDATA[背景由于一些历史原因，目前zookeeper集群（3个节点）和elasticsearch、hadoop部署在一起，导致几个组件相互影响，性能也逐渐下降。甚至出现某个组件异常（例如oom）导致了其他组件不可用。 由于大量项目使用dubbo且依赖zookeeper作为注册中心，zookeeper的不稳定可能是致命的，所以计划先将zookeeper迁出到3台独立的节点，在此记录下迁移方案。 zookeeper选举原理在迁移前有必要了解zookeeper的选举原理，以便更科学的迁移。 快速选举FastLeaderElectionzookeeper默认使用快速选举，在此重点了解快速选举： 向集群中的其他zookeeper建立连接，并且只有myid比对方大的连接才会被接受（也就是每2台只会有1个连接，避免连接浪费） 每台zookeeper默认先投自己，然后向集群广播自己的选票 收到对方的选票时，依次比较epoch（选举轮数）、zxid（事务id）、myid，较大者胜出，更新选票并广播 如果收到的选票中有某个节点超过集群半数，则胜出当选为leader，其他节点为follower 注意事项 zookeeper集群的数量应为奇数： 因为根据paxos理论，只有集群中超过半数的节点还存活才能保证集群的一致性。假如目前集群有5个节点，我们最多允许2个节点不可用，因为3&gt;5\2。当集群扩容到6个节点的时候，我们仍然只能最多允许2个节点不可用，到3个节点不可用时，将不满足paxos理论，因为3&gt;6\2不成立。也就是说当集群节点数n为偶数时，其可用性与n-1是一样的，那我们何必多浪费一台机器呢？ 由于zookeeper只允许mid大的节点连接到mid小的节点，我们启动zookeeper的顺序应该按照myid小的到myid大的，最后再启动leader节点！ 迁移目标迁移过程中要保证原zookeeper集群还是能提供服务，新zookeeper集群同步老集群的数据，将zookeeper url指向新集群的3个节点，停掉老zookeeper集群。 相当于先扩容zookeeper,然后缩容zookeeper… 迁移步骤原有zookeeper集群(server1、server2、server3)zoo.cfg配置如下: 12345# 省略其他配置dataDir=/dataserver.1=node1:3181:4181server.2=node2:3181:4181server.3=node3:3181:4181 使用命令：echo srvr | nc node{?} 2181检查谁是leader({?}依次替换为1、2、3) ps：也可以用echo stat | nc node{?} 2181显示更详细信息 这里假设leader为node2.（按照正常情况，leader也理应是node2） 步骤1：新增节点4 在/data目录创建mid文件，内容为4 配置zoo.cfg,内容如下： 123456# 省略其他配置dataDir=/dataserver.1=node1:3181:4181server.2=node2:3181:4181server.3=node3:3181:4181server.4=node4:3181:4181 启动zookeeper：{zookeeperDir}/bin/zkServer.sh start 检查所有节点是否提供服务，且集群中只有一个leader，例如以下命令: 12345678910$ echo srvr | nc node1 2181Zookeeper version: 3.4.5-cdh5.7.0--1, built on 03/23/2016 18:30 GMTLatency min/avg/max: 0/6/190Received: 16002Sent: 19874Connections: 1Outstanding: 0Zxid: 0x3b00004872Mode: leaderNode count: 334 可以看到Mode表示该节点的角色为leader。依次检查每一个节点,如果没有响应，或者出现多个leader，需要还原整个集群！ 步骤2：新增节点5 在/data目录创建mid文件，内容为5 配置zoo.cfg,内容如下： 1234567# 省略其他配置dataDir=/dataserver.1=node1:3181:4181server.2=node2:3181:4181server.3=node3:3181:4181server.4=node4:3181:4181server.5=node5:3181:4181 启动zookeeper：{zookeeperDir}/bin/zkServer.sh start 检查所有节点是否提供服务，且集群中只有一个leader: 12345678910$ echo srvr | nc node1 2181...$ echo srvr | nc node2 2181...$ echo srvr | nc node3 2181...$ echo srvr | nc node4 2181...$ echo srvr | nc node5 2181... 步骤3：新增节点6 在/data目录创建mid文件，内容为6 配置zoo.cfg,内容如下： 12345678# 省略其他配置dataDir=/dataserver.1=node1:3181:4181server.2=node2:3181:4181server.3=node3:3181:4181server.4=node4:3181:4181server.5=node5:3181:4181server.6=node6:3181:4181 启动zookeeper：{zookeeperDir}/bin/zkServer.sh start 检查所有节点是否提供服务，且集群中只有一个leader: 123456789101112$ echo srvr | nc node1 2181...$ echo srvr | nc node2 2181...$ echo srvr | nc node3 2181...$ echo srvr | nc node4 2181...$ echo srvr | nc node5 2181...$ echo srvr | nc node6 2181... 步骤4：更新节点4 修改节点4的配置如下： 12345678# 省略其他配置dataDir=/dataserver.1=node1:3181:4181server.2=node2:3181:4181server.3=node3:3181:4181server.4=node4:3181:4181server.5=node5:3181:4181server.6=node6:3181:4181 重启节点4的zookeeper：{zookeeperDir}/bin/zkServer.sh restart 检查所有节点是否提供服务，且集群中只有一个leader: 123456789101112$ echo srvr | nc node1 2181...$ echo srvr | nc node2 2181...$ echo srvr | nc node3 2181...$ echo srvr | nc node4 2181...$ echo srvr | nc node5 2181...$ echo srvr | nc node6 2181... 步骤5：更新节点5同步骤4 步骤6：更新老集群节点1 修改节点1的配置如下： 12345678# 省略其他配置dataDir=/dataserver.1=node1:3181:4181server.2=node2:3181:4181server.3=node3:3181:4181server.4=node4:3181:4181server.5=node5:3181:4181server.6=node6:3181:4181 重启节点4的zookeeper：{zookeeperDir}/bin/zkServer.sh restart 检查所有节点是否提供服务，且集群中只有一个leader: 123456789101112$ echo srvr | nc node1 2181...$ echo srvr | nc node2 2181...$ echo srvr | nc node3 2181...$ echo srvr | nc node4 2181...$ echo srvr | nc node5 2181...$ echo srvr | nc node6 2181... 步骤7：更新老集群节点3同步骤6 步骤8：更新老集群节点2最后更新leader节点：node2，同步骤6 ps:这时候如果没有读写zookeeper操作，集群的leader将变为节点6（因为节点6的myid最大） 步骤9：将原有zookeeper的url指向新的节点运维修改nginx配置，zookeeper url（例如pro1.zookeeper.so、pro2.zookeeper.so、pro3.zookeeper.so）指向node4，node5，node6 相关业务系统重启（避免cdh缓存） 步骤10：老zookeeper集群下线这一步需要等待所有的业务系统都重启之后。 这时候还是得一台一台关闭（下线），因为假如同时关闭node1和node2，那当重启node3的时候集群将不可用（没有超过集群半数的节点存活） 步骤10.1：下线zookeeper老集群中的节点1关闭node1: {zookeeperDir}/bin/zkServer.sh stop 依次修改node2，3，4，5，6的配置，并且重启，配置如下： 1234567# 省略其他配置dataDir=/dataserver.2=node2:3181:4181server.3=node3:3181:4181server.4=node4:3181:4181server.5=node5:3181:4181server.6=node6:3181:4181 重启后检查所有节点是否提供服务，且集群中只有一个leader。 ps:这时候如果没有读写zookeeper操作，leader将变成node5，因为node6节点重启的时候，集群重新选举，node5的myid最大 步骤10.2：下线zookeeper老集群中的节点2关闭node2: {zookeeperDir}/bin/zkServer.sh stop 依次修改node3，4，5，6的配置，并且重启，配置如下： 123456# 省略其他配置dataDir=/dataserver.3=node3:3181:4181server.4=node4:3181:4181server.5=node5:3181:4181server.6=node6:3181:4181 重启后检查所有节点是否提供服务，且集群中只有一个leader。 ps:这时候如果没有读写zookeeper操作，leader将重新变成node6 步骤10.3：下线zookeeper老集群中的节点3关闭node3: {zookeeperDir}/bin/zkServer.sh stop 依次修改node4，5，6的配置，并且重启，配置如下： 12345# 省略其他配置dataDir=/dataserver.4=node4:3181:4181server.5=node5:3181:4181server.6=node6:3181:4181 重启后检查所有节点是否提供服务，且集群中只有一个leader。 ps:这时候如果没有读写zookeeper操作，node5将成为最终的leader 结束。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[线上java项目OOM快速定位与解决方法]]></title>
      <url>%2F2017%2F08%2F21%2Fhowto-handle-java-oom%2F</url>
      <content type="text"><![CDATA[背景最近比较多的碰到OOM异常，总结下OOM的异常快速定位和解决的办法。 OOM的常见原因 内存分配确实过小 频繁创建对象，没有及时释放 频繁申请系统资源，导致系统资源耗尽（例如：不断创建线程，不断发起网络连接） 定位与解决方法需要先找到出问题的进程，使用top命令定位： top 输入top命令后，可以按P(shift+p)根据cpu占用排序、按M根据内存占用排序、按T根据运行时间排序。（可以先按c显示具体的command） 这里先按M根据内存排序查找异常的进程：这里假设出现异常的进程pid为2879 注意定位问题前请先尝试输入jps命令，确定是否能够显示出现问题的pid（例如2879）.如果jps没有相应的显示，可能是你当前用户的权限不够，请使用启用相应进程的用户或者拥有更高权限的用户排查问题！不然以下的一些命令（例如jmap）将无法使用. 原理：java程序启动后，默认会在/tmp/hsperfdata_userName目录下以该进程的id为文件名新建文件，并在该文件中存储jvm运行的相关信息，其中的userName为当前的用户名，/tmp/hsperfdata_userName目录会存放该用户所有已经启动的java进程信息.而jps、jconsole等工具的数据来源就是这个文件（/tmp/hsperfdata_userName/pid)。所以当该文件不存在或是无法读取时就会出现jps无法查看该进程号，jconsole无法监控等问题 判断是否是由于“内存分配确实过小”输入以下命令： jmap -heap 2879 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748[root@node182 ~]# jmap -heap 2879Attaching to process ID 2879, please wait...Debugger attached successfully.Server compiler detected.JVM version is 25.73-b02using thread-local object allocation.Parallel GC with 4 thread(s)Heap Configuration: MinHeapFreeRatio = 0 MaxHeapFreeRatio = 100 MaxHeapSize = 2040528896 (1946.0MB) NewSize = 42467328 (40.5MB) MaxNewSize = 680001536 (648.5MB) OldSize = 85458944 (81.5MB) NewRatio = 2 SurvivorRatio = 8 MetaspaceSize = 21807104 (20.796875MB) CompressedClassSpaceSize = 1073741824 (1024.0MB) MaxMetaspaceSize = 17592186044415 MB G1HeapRegionSize = 0 (0.0MB)Heap Usage:PS Young GenerationEden Space: capacity = 28311552 (27.0MB) used = 21982144 (20.96380615234375MB) free = 6329408 (6.03619384765625MB) 77.64372649016204% usedFrom Space: capacity = 1048576 (1.0MB) used = 688128 (0.65625MB) free = 360448 (0.34375MB) 65.625% usedTo Space: capacity = 1048576 (1.0MB) used = 0 (0.0MB) free = 1048576 (1.0MB) 0.0% usedPS Old Generation capacity = 100139008 (95.5MB) used = 90236608 (86.05633544921875MB) free = 9902400 (9.44366455078125MB) 90.11134602012434% used28237 interned Strings occupying 3386232 bytes. 可以看到详细的堆内存使用情况，可以以此判断应用分配的内存是否确实过小。 判断是否是由于“频繁创建对象，没有及时回收”输入以下命令，找出最耗内存的对象： jmap -histo:live 2879 | more 123456789101112131415161718192021222324[root@node182 ~]# jmap -histo:live 2879 | more num #instances #bytes class name---------------------------------------------- 1: 81515 11259264 [C 2: 80010 1920240 java.lang.String 3: 44265 1416480 java.util.concurrent.ConcurrentHashMap$Node 4: 4057 1369872 [B 5: 11200 1241976 java.lang.Class 6: 8977 789976 java.lang.reflect.Method 7: 18801 752040 java.util.LinkedHashMap$Entry 8: 5144 627336 [I 9: 11948 601184 [Ljava.lang.Object; 10: 8275 595352 [Ljava.util.HashMap$Node; 11: 18231 583392 java.lang.ref.WeakReference 12: 9847 551432 java.util.LinkedHashMap 13: 375 544288 [Ljava.util.concurrent.ConcurrentHashMap$Node; 14: 29118 465888 java.lang.Object 15: 13034 417088 java.util.HashMap$Node 16: 8850 354000 java.lang.ref.SoftReference 17: 10490 251760 java.beans.MethodRef 18: 3586 200816 java.beans.MethodDescriptor 19: 6450 195288 [Ljava.lang.String; 输入命令后，会以表格的形式显示存活对象的信息，并按照所占内存大小排序。 instances: 对象实例数量 bytes: 占用内存大小 class name: 类名 可以看到目前最耗内存的对象也才占用内存11m，所以属于正常范畴 如果发现某个对象的占用大量内存（例如：1G以上），就需要review代码，审查下该对象是否没有及时回收 PS：其中输出的奇怪的class name请查看最后的附录。 判断是否是由于“频繁申请系统资源” 查看进程的线程数量： ll /proc/{PID}/task | wc -l 123[root@node182 ~]# ll /proc/2879/task | wc -l101 可以看到，该进程使用了101个线程。 如果看到启用了大量线程，就需要审查代码涉及到线程池的使用部分，是否限定了最大线程数量。 查询进程占用的句柄数量 ll /proc/{PID}/fd | wc -l 123[root@node182 ~]# ll /proc/2879/fd | wc -l38 可以看到，该进程使用了38个文件句柄。 如果占用大量文件句柄，需要审查代码中涉及到文件操作和网络连接操作是否有及时关闭资源链接。 jmap 附加说明jmap -heap输出的非自定义类名说明： BaseType Character Type Interpretation B byte signed byte C char Unicode character D double double-precision floating-point value F float single-precision floating-point value I int integer J long long integer L; reference an instance of class S short signed short Z boolean true or false [ reference one array dimension]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[重构总结之升级log4j为logback]]></title>
      <url>%2F2017%2F07%2F24%2Frestructure-summary-2%2F</url>
      <content type="text"><![CDATA[背景随着业务的复杂度上升，流量增大，各个系统的日志量也急剧上升。个别基础服务日志量达到了2G/天。使用的log4j(1)出现了大量丢日志的情况，且写日志的性能也出现下降。由于使用了slf4j作为日志门面，所以考虑换到业界使用更为广泛的logback。 现状目前系统都以log4j作为日志实现，且有很多第三方包同样也依赖了log4j作为日志输出。如果要使用logback，总不能一个一个的去排除对log4j的依赖吧，不仅工作量大而且容易漏掉。 只能先看下slf4j选择具体日志实现的原理了。。。 slf4j选择日志实现的原理slf4j官网：传送门 SLF4J API is designed to bind with one and only one underlying logging framework at a time. If more than one binding is present on the class path, SLF4J will emit a warning, listing the location of those bindings. When multiple bindings are available on the class path, select one and only one binding you wish to use, and remove the other bindings. For example, if you have both slf4j-simple-1.8.0-alpha2.jar and slf4j-nop-1.8.0-alpha2.jar on the class path and you wish to use the nop (no-operation) binding, then remove slf4j-simple-1.8.0-alpha2.jar from the class path. The list of locations that SLF4J provides in this warning usually provides sufficient information to identify the dependency transitively pulling in an unwanted SLF4J binding into your project. In your project’s pom.xml file, exclude this SLF4J binding when declaring the unscrupulous dependency. For example, cassandra-all version 0.8.1 declares both log4j and slf4j-log4j12 as compile-time dependencies. Thus, when you include cassandra-all as a dependency in your project, the cassandra-all declaration will cause both slf4j-log4j12.jar and log4j.jar to be pulled in as dependencies. In case you do not wish to use log4j as the the SLF4J backend, you can instruct Maven to exclude these two artifacts as shown next: org.apache.cassandra cassandra-all 0.8.1 &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;groupId&gt;log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; Note The warning emitted by SLF4J is just that, a warning. Even when multiple bindings are present, SLF4J will pick one logging framework/implementation and bind with it. The way SLF4J picks a binding is determined by the JVM and for all practical purposes should be considered random. As of version 1.6.6, SLF4J will name the framework/implementation class it is actually bound to. Embedded components such as libraries or frameworks should not declare a dependency on any SLF4J binding but only depend on slf4j-api. When a library declares a compile-time dependency on a SLF4J binding, it imposes that binding on the end-user, thus negating SLF4J’s purpose. When you come across an embedded component declaring a compile-time dependency on any SLF4J binding, please take the time to contact the authors of said component/library and kindly ask them to mend their ways. 意思就是说如果有多个日志组件并存的时候，slf4j的选择方式是随机的… 黑魔法方式最终google发现一种巧妙的方式。请看以下maven pom.xml配置： 1234567891011121314151617181920212223242526272829303132333435363738&lt;!-- 强制去除log4j的依赖,全部 delegate 到 log4j-over-slf4j 上--&gt;&lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt; &lt;version&gt;99.0-does-not-exist&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j&lt;/artifactId&gt; &lt;version&gt;99.0-does-not-exist&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;apache-log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j&lt;/artifactId&gt; &lt;version&gt;99.0-not-exist&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;log4j-over-slf4j&lt;/artifactId&gt; &lt;version&gt;1.7.25&lt;/version&gt;&lt;/dependency&gt;&lt;!-- 明确指定只用logback --&gt;&lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt; &lt;version&gt;1.7.5&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt; &lt;artifactId&gt;logback-classic&lt;/artifactId&gt; &lt;version&gt;1.1.11&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.logback-extensions&lt;/groupId&gt; &lt;artifactId&gt;logback-ext-spring&lt;/artifactId&gt; &lt;version&gt;0.1.4&lt;/version&gt;&lt;/dependency&gt; 原理就是maven对于冲突包的选择方式是就近原则，当项目主动定义了一个并不存在的log4j版本(当然你得打个空jar到你的maven私服或者本地)，maven优先会选择这个不存在的版本，从而使log4j的依赖全部被排除。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[业务重构总结之分解关联查询]]></title>
      <url>%2F2017%2F06%2F20%2Frestructure-summary-1%2F</url>
      <content type="text"><![CDATA[背景经历了一段漫长痛苦的重构期，整体的业务重构基本完成。这里总结下重构中遇到的一些问题和经验。这里主要讲下分解关联查询。 例子例如一个查询标签为‘mysql’的所有文章的关联查询sql： 1234select * from tag join tag_post on tag_post.tag_id = tag.id join post on tag_post.post_id = post.idwhere tag.tag = 'mysql'; 分解成以下多个sql，在应用层做关联： 123select id from tag where tag = 'mysql';select * from tag_post where tag_id=1234;select * from post where post.id in (123,456,...); 分解关联查询的优点缓存的效率更高应用程序可以很方便的缓存单表查询的结果。例如例子中分解后的第1个查询，如果已经在缓存中，这可以跳过第1个查询。 另外对于mysql的query cacha（查询缓存）来说，如果关联查询中的任意表发生了变化，就无法使用缓存，而拆分后，如果其中一个表很少改变，那么该表的缓存命中将很高。 减少数据库锁竞争查询分解后，执行单个查询可以减少锁的竞争，而关联查询将可能锁多个表。 微服务化友好应用层做关联，可以更容易的做数据库拆分，更容易做到高性能和可扩展。对于原本的单体应用做微服务化拆分与改造将非常便捷。 查询效率提升例如例子中的第3个查询，使用了in()代替了关联查询，可以让mysql按照id顺序进行查询，这比随机的关联要更高效。 减少冗余记录的查询在应用层做关联，意味着对某条记录只需查询一次，而在数据库关联查询，则可能需要重复地访问一部分数据。从这点看，这样还能减少网络和内测消耗。 关联更高效在应用层关联，往往比mysql中的嵌套循环关联更高效。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[RocketMQ阅读笔记]]></title>
      <url>%2F2017%2F01%2F03%2Frocketmq-read-note%2F</url>
      <content type="text"><![CDATA[为何选择rocketmq选型时主要对比了kafka和rocketmq。两者还是存在较大差异的，kafka一开始的定位就是日志收集，对于订单、交易等可靠传输场景不能很好满足（消息丢失、消息重复消费等方面）。并且rocketmq是使用java编写的，相对于scala编写的kafka，我们有更大的定制与扩展的空间。 数据可靠性 rocketmq支持异步/同步刷盘,异步/同步复制 kafka异步刷盘，异步/同步复制 刷盘效率上应该是rocketmq更高。因为rocketmq的消息都写到一个文件中，而kafka的每个分区对应一个文件，rocketmq可以充分利用IO组commit机制批量传输数据。 性能对比 kafka单机协议TPS约在100w/s，消息大小为10字节 rocketmq单机写入TPS单实例约为7W/s,单机3个broker，可以跑到12w/s,消息大小为10字节 之所以kafka有如此高的TPS,是由于producer端会将多个小消息合并，批量发送至broker。rocketmq没有这做的原因： 由于使用java语言，如果producer端缓存过多消息，GC是个严重问题 producer端调用发送消息接口，消息为发送到broker就返回，此时producer宕机会导致消息丢失 producer通常为分布式部署，且每台机器都是多线程发送，单个producer产生的消息有限 单机支持的队列/分区数量 Kafka单机超过64个队列/分区，Load会发生明显的飙高现象，队列越多，load越高，发送消息响应时间变长。Kafka分区数无法过多的问题 rocketmq支持单机最高5w个队列，负载不会发送明显变化 队列/分区多的好处： 单机可以创建更多Topic，因为没有Topic都是有一批队列组成 消费者的集群规模和队列数成正比 消息投递实时性 kafka使用短轮询方式，实时性取决于轮询间隔时间，0.8以后支持长轮询 rockmq使用长轮询，同push方式实时性基本一致 消费失败重试 kafka不支持重试 rocketmq消费失败支持定时重试，每次重试间隔时间顺延 重试的场景比较适合依赖第三方的consumer，比较充值，consumer需要调用第三方运营商网关，充值失败可能是对方当前压力过大，稍后调用可能就会成功。 消息顺序 kafka支持消息顺序，但是在一台broker宕机后，就会产生消息乱序 rocketmq支持严格的消息顺序，当一台broker宕机后，发送消息会失败，但不会乱序 定时消息 kafka目前不支持定时消息 rocketmq支持定时消息 目前业务场景暂时用不到。 分布式事务消息 kafka目前不支持 rocketmq暂时没有开源事务消息 消息查询 kafka不支持消息查询 rocketmq支持根据消息表示查询，也可根据消息内容查询（发送消息时指定一个消息密钥，任意字符串，例如指定为订单编号） 这个对于消息定位非常有帮助。 消息回溯 kafka不支持 rocketmq可以按照时间回溯消息，精度毫秒 这个对于对账等功能比较有用 消息过滤 kafka不支持broker端过滤 rocketmq支持根据tag（相当于子主题）过滤 开发语言友好rocketmq使用java，更友好。 开源社区活跃度都比较活跃。 rocketmq消息存储]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[dubbo遇到的坑]]></title>
      <url>%2F2016%2F12%2F12%2Fdubbo-parameter-validate%2F</url>
      <content type="text"><![CDATA[背景目前项目使用dubbo做服务化，同时开启dubbo的consumer端的参数校验。 遇到的坑一第一个遇到的就是参数分组校验的bug了，这个其实网上很多人提过。 具体原因就是内部类使用_连接符代替实际应该使用的$。具体看如下代码(传送门)： 123456789public void validate(String methodName, Class&lt;?&gt;[] parameterTypes, Object[] arguments) throws Exception &#123; String methodClassName = clazz.getName() + "_" + toUpperMethoName(methodName); Class&lt;?&gt; methodClass = null; try &#123; methodClass = Class.forName(methodClassName, false, Thread.currentThread().getContextClassLoader()); &#125; catch (ClassNotFoundException e) &#123; &#125; // 以下代码略 &#125; 这段代码的作用就是加载dubbo service中的分组校验group的内部类，再根据具体的group进行参数校验。但是内部类的连接符却用了_连接。按理说这个问题应该很容易被发现且很容易被测试出来，不应该出现在dubbo身上。 于是抱着怀疑的的心态查看该类的提交记录。果然，作者是故意这么改的(传送门)： JValidator在类名生成的类名有$，有frozen class异常 个人不是很理解这句话。。。且这么改留下了一个明显的bug。可能由于当时dubbo已经不再维护，作者也没有对此修改有进一步的说明。只好将此处的修改还原为使用$连接。实际测试与使用都没有出现异常，就此作罢。 遇到的坑二随着系统的愈加复杂，出现了dubbo调用dubbo的情况。当前端web系统的controller调用dubboService1的时候，会在controller端进行参数校验，这个时候如果校验失败，能正常抛出错误，因为根本都还没有发起RPC调用。但是当dubboService1调用dubboService2的时候，也会在dubboService1端进行参数校验，这个时候如果校验失败，会抛出异常，dubboService1会试图将此异常序列化并传回controller端。如果此异常中包含不可系列化的属性，将会抛出无法序列化异常。这个就是dubbo默认的参数校验会存在的问题。例如以下错误: 12java.lang.RuntimeException: Serialized class com.example.dubboService2_method1 must implement java.io.SerializableJava field: private final java.lang.Object org.hibernate.validator.internal.engine.ConstraintViolationImpl.rootBean 解决办法：dubbo提供了自定义参数校验的扩展点，并且我们只要自定义一个可正常序列化的异常即可。例如以下代码： DubboValidation.java: 12345678910public class DubboValidation extends JValidation &#123; public DubboValidation() &#123; &#125; protected Validator createValidator(URL url) &#123; return new DubboValidator(url); &#125; &#125; DubboValidator.java: 1234567891011121314public class DubboValidator extends JValidator &#123; public DubboValidator(URL url) &#123; super(url); &#125; public void validate(String methodName, Class&lt;?&gt;[] parameterTypes, Object[] arguments) throws Exception &#123; try&#123; super.validate(methodName, parameterTypes, arguments); &#125;catch (Exception e)&#123; throw new MyBusinessException("DUBBO参数校验失败", e.getMessage()); &#125; &#125; &#125; MyBUsinessException.java: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051public class MyBusinessException extends RpcException &#123; public static final String DEFAULT_FAULT_CODE = "X0001"; private String xCode; private String message; public MyBusinessException(String message)&#123; this(DEFAULT_FAULT_CODE, message); &#125; public MyBusinessException(String xCode, String message) &#123; this(xCode, message, new Throwable()); &#125; public MyBusinessException(String xCode, String message, String internalMessage) &#123; this(xCode, message, internalMessage, null); &#125; public MyBusinessException(String code, String message, Throwable throwable) &#123; this(code, message, throwable.getMessage(), throwable); &#125; public MyBusinessException(String xCode, String message, String internalMessage, Throwable throwable) &#123; super(RpcException.BIZ_EXCEPTION, "[" + xCode + "] - " + message + internalMessage, throwable); this.message = message; this.xCode = xCode; &#125; public String getXCode() &#123; return xCode; &#125; public void setXCode(String xCode) &#123; this.xCode = xCode; &#125; public String getMessageWithoutCode()&#123; return message; &#125; @Override public String getMessage() &#123; return "[" + xCode + "]" + " - " + message; &#125; public void setMessage(String message) &#123; this.message = message; &#125; &#125; 同时需要在classpath:META-INF/下新建如下目录：dubbo/,并且新建一个文件com.alibaba.dubbo.validation.Validation,然后写入以下内容： dubboValidation=com.xkeshi.webkits.dubbovalidation.DubboValidation 其实以上就是java spi的类加载方式。 遇到的坑三dubbo provider服务提供者不要有方法重载！不然默认的dubbo协议说使用的Hessian序列化方式将有可能无法正确找到重载的方法！（客户端开启参数校验的时候）]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[线上java项目cpu100%排查步骤]]></title>
      <url>%2F2016%2F12%2F09%2Fhowto-handle-java-cpu100%2F</url>
      <content type="text"><![CDATA[1.利用top命令查找异常进程 top 输入top命令后，可以按P(shift+p)根据cpu占用排序、按M根据内存占用排序、按T根据运行时间排序。 这里先按P根据cpu排序查找异常的线程： 可以看到，有个pid为19132的线程占用cpu400%(这里是因为4核，每个cpu都100%，加起来就是400%) 2.根据记录的pid查找其线程占用情况 top -Hc -p 19132 说明：这里-Hc是指按照cpu占用降序 这里可以看到这个pid为31395的线程cpu占用非常高，且运行时间也非常长，肯定是有问题的。 3.打印出异常进程信息先根据第1步查出的pid，打印出线程堆栈信息到文件： jstack 19321 &gt; stack-19321.log 根据第二步查出的pid，打印出其16进制： printf %x 31395 7aa3 然后去stack-19321.log文件里查找7aa3: vim stack-19321.log /7aa3 即可。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[netty源码解读之时间轮算法实现-HashedWheelTimer]]></title>
      <url>%2F2016%2F12%2F02%2Fnetty-hashedwheeltimer%2F</url>
      <content type="text"><![CDATA[前因由于netty动辄管理100w+的连接，每一个连接都会有很多超时任务。比如发送超时、心跳检测间隔等，如果每一个定时任务都启动一个Timer,不仅低效，而且会消耗大量的资源。 解决方案根据George Varghese 和 Tony Lauck 1996 年的论文：Hashed and Hierarchical Timing Wheels: data structures to efficiently implement a timer facility。提出了一种定时轮的方式来管理和维护大量的Timer调度. 原理时间轮其实就是一种环形的数据结构，可以想象成时钟，分成很多格子，一个格子代码一段时间（这个时间越短，Timer的精度越高）。并用一个链表报错在该格子上的到期任务，同时一个指针随着时间一格一格转动，并执行相应格子中的到期任务。任务通过取摸决定放入那个格子。如下图所示： 以上图为例，假设一个格子是1秒，则整个wheel能表示的时间段为8s，假如当前指针指向2，此时需要调度一个3s后执行的任务，显然应该加入到(2+3=5)的方格中，指针再走3次就可以执行了；如果任务要在10s后执行，应该等指针走完一个round零2格再执行，因此应放入4，同时将round（1）保存到任务中。检查到期任务时应当只执行round为0的，格子上其他任务的round应减1。 是不是很像java中的Hashmap。其实就是HashMap的哈希拉链算法，只不过多了指针转动与一些定时处理的逻辑。所以其相关的操作和HashMap也一致： 添加任务：O(1) 删除/取消任务：O(1) 过期/执行任务：最差情况为O(n)-&gt;也就是当HashMap里面的元素全部hash冲突，退化为一条链表的情况。平均O(1)-&gt;显然，格子越多，每个格子上的链表就越短，这里需要权衡时间与空间。 多层时间轮如果任务的时间跨度很大，数量很大，单层的时间轮会造成任务的round很大，单个格子的链表很长。这时候可以将时间轮分层，类似于时钟的时分秒3层。如下图所示： 但是个人认为，多层的时间轮造成的算法复杂度的进一步提升。单层时间轮只需增加每一轮的格子就能解决链表过长的问题。因此，更倾向使用单层的时间轮，netty4中时间轮的实现也是单层的。 netty时间轮的实现-HashedWheelTimer简单使用示例1.引入netty依赖 &lt;dependency&gt; &lt;groupId&gt;io.netty&lt;/groupId&gt; &lt;artifactId&gt;netty-all&lt;/artifactId&gt; &lt;version&gt;4.1.4.Final&lt;/version&gt; &lt;/dependency&gt; 2.示例代码 示例1： 123456789101112@Testpublic void test1() throws Exception &#123; DateTimeFormatter formatter = DateTimeFormatter.ofPattern("yyyy-MM-dd HH:mm:ss"); HashedWheelTimer hashedWheelTimer = new HashedWheelTimer(100, TimeUnit.MILLISECONDS); System.out.println("start:" + LocalDateTime.now().format(formatter)); hashedWheelTimer.newTimeout(timeout -&gt; &#123; System.out.println("task :" + LocalDateTime.now().format(formatter)); &#125;, 3, TimeUnit.SECONDS); Thread.sleep(5000);&#125; 输出为： start:2016-11-30 05:56:35 task :2016-11-30 05:56:38 示例2： 1234567891011121314151617@Testpublic void test2() throws Exception &#123; DateTimeFormatter formatter = DateTimeFormatter.ofPattern("yyyy-MM-dd HH:mm:ss"); HashedWheelTimer hashedWheelTimer = new HashedWheelTimer(100, TimeUnit.MILLISECONDS); System.out.println("start:" + LocalDateTime.now().format(formatter)); hashedWheelTimer.newTimeout(timeout -&gt; &#123; Thread.sleep(3000); System.out.println("task1:" + LocalDateTime.now().format(formatter)); &#125;, 3, TimeUnit.SECONDS); hashedWheelTimer.newTimeout(timeout -&gt; System.out.println("task2:" + LocalDateTime.now().format( formatter)), 4, TimeUnit.SECONDS); Thread.sleep(10000);&#125; 输出： start:2016-12-01 08:32:37 task1:2016-12-01 08:32:43 task2:2016-12-01 08:32:43 可以看到，当前一个任务执行时间过长的时候，会影响后续任务的到期执行时间的。也就是说其中的任务是串行执行的。所以，要求里面的任务都要短平快。 HashedWheelTimer源码之构造函数123456789101112131415161718192021222324252627282930313233343536373839404142434445 public HashedWheelTimer( ThreadFactory threadFactory, // 用来创建worker线程 long tickDuration, // tick的时长，也就是指针多久转一格 TimeUnit unit, // tickDuration的时间单位 int ticksPerWheel, // 一圈有几格 boolean leakDetection // 是否开启内存泄露检测 ) &#123; // 一些参数校验 if (threadFactory == null) &#123; throw new NullPointerException("threadFactory"); &#125; if (unit == null) &#123; throw new NullPointerException("unit"); &#125; if (tickDuration &lt;= 0) &#123; throw new IllegalArgumentException("tickDuration must be greater than 0: " + tickDuration); &#125; if (ticksPerWheel &lt;= 0) &#123; throw new IllegalArgumentException("ticksPerWheel must be greater than 0: " + ticksPerWheel); &#125; // 创建时间轮基本的数据结构，一个数组。长度为不小于ticksPerWheel的最小2的n次方 wheel = createWheel(ticksPerWheel); // 这是一个标示符，用来快速计算任务应该呆的格子。 // 我们知道，给定一个deadline的定时任务，其应该呆的格子=deadline%wheel.length.但是%操作是个相对耗时的操作，所以使用一种变通的位运算代替： // 因为一圈的长度为2的n次方，mask = 2^n-1后低位将全部是1，然后deadline&amp;mast == deadline%wheel.length // java中的HashMap也是使用这种处理方法 mask = wheel.length - 1; // 转换成纳秒处理 this.tickDuration = unit.toNanos(tickDuration); // 校验是否存在溢出。即指针转动的时间间隔不能太长而导致tickDuration*wheel.length&gt;Long.MAX_VALUE if (this.tickDuration &gt;= Long.MAX_VALUE / wheel.length) &#123; throw new IllegalArgumentException(String.format( "tickDuration: %d (expected: 0 &lt; tickDuration in nanos &lt; %d", tickDuration, Long.MAX_VALUE / wheel.length)); &#125; // 创建worker线程 workerThread = threadFactory.newThread(worker);// 这里默认是启动内存泄露检测：当HashedWheelTimer实例超过当前cpu可用核数*4的时候，将发出警告 leak = leakDetection || !workerThread.isDaemon() ? leakDetector.open(this) : null; &#125; 再来看下createWheel的代码： 1234567891011121314151617181920 private static HashedWheelBucket[] createWheel(int ticksPerWheel) &#123; // 一些参数校验if (ticksPerWheel &lt;= 0) &#123; throw new IllegalArgumentException( "ticksPerWheel must be greater than 0: " + ticksPerWheel); &#125; if (ticksPerWheel &gt; 1073741824) &#123; throw new IllegalArgumentException( "ticksPerWheel may not be greater than 2^30: " + ticksPerWheel); &#125;// 初始化ticksPerWheel的值为不小于ticksPerWheel的最小2的n次方 ticksPerWheel = normalizeTicksPerWheel(ticksPerWheel);// 初始化wheel数组 HashedWheelBucket[] wheel = new HashedWheelBucket[ticksPerWheel]; for (int i = 0; i &lt; wheel.length; i ++) &#123; wheel[i] = new HashedWheelBucket(); &#125; return wheel; &#125; normalizeTicksPerWheel()的代码： 12345678// 初始化ticksPerWheel的值为不小于ticksPerWheel的最小2的n次方 private static int normalizeTicksPerWheel(int ticksPerWheel) &#123; int normalizedTicksPerWheel = 1; while (normalizedTicksPerWheel &lt; ticksPerWheel) &#123; normalizedTicksPerWheel &lt;&lt;= 1; &#125; return normalizedTicksPerWheel; &#125; 这里其实不建议使用这种方式，因为当ticksPerWheel的值很大的时候，这个方法会循环很多次，方法执行时间不稳定，效率也不够。推荐使用java8 HashMap的做法： 1234567891011private int normalizeTicksPerWheel(int ticksPerWheel) &#123; // 这里参考java8 hashmap的算法，使推算的过程固定 int n = ticksPerWheel - 1; n |= n &gt;&gt;&gt; 1; n |= n &gt;&gt;&gt; 2; n |= n &gt;&gt;&gt; 4; n |= n &gt;&gt;&gt; 8; n |= n &gt;&gt;&gt; 16; // 这里1073741824 = 2^30,防止溢出 return (n &lt; 0) ? 1 : (n &gt;= 1073741824) ? 1073741824 : n + 1;&#125; HashedWheelTimer源码之启动、停止与添加任务start()启动时间轮的方法： 12345678910111213141516171819202122232425262728// 启动时间轮。这个方法其实不需要显示的主动调用，因为在添加定时任务（newTimeout()方法）的时候会自动调用此方法。// 这个是合理的设计，因为如果时间轮里根本没有定时任务，启动时间轮也是空耗资源public void start() &#123; // 判断当前时间轮的状态，如果是初始化，则启动worker线程，启动整个时间轮；如果已经启动则略过；如果是已经停止，则报错 // 这里是一个Lock Free的设计。因为可能有多个线程调用启动方法，这里使用AtomicIntegerFieldUpdater原子的更新时间轮的状态 switch (WORKER_STATE_UPDATER.get(this)) &#123; case WORKER_STATE_INIT: if (WORKER_STATE_UPDATER.compareAndSet(this, WORKER_STATE_INIT, WORKER_STATE_STARTED)) &#123; workerThread.start(); &#125; break; case WORKER_STATE_STARTED: break; case WORKER_STATE_SHUTDOWN: throw new IllegalStateException("cannot be started once stopped"); default: throw new Error("Invalid WorkerState"); &#125; // 等待worker线程初始化时间轮的启动时间 while (startTime == 0) &#123; try &#123; startTimeInitialized.await(); &#125; catch (InterruptedException ignore) &#123; // Ignore - it will be ready very soon. &#125; &#125;&#125; AtomicIntegerFieldUpdater是JUC里面的类，原理是利用反射进行原子操作。有比AtomicInteger更好的性能和更低得内存占用。跟踪这个类的github 提交记录，可以看到更详细的原因 stop()停止时间轮的方法： 12345678910111213141516171819202122232425262728293031323334353637383940414243public Set&lt;Timeout&gt; stop() &#123; // worker线程不能停止时间轮，也就是加入的定时任务，不能调用这个方法。 // 不然会有恶意的定时任务调用这个方法而造成大量定时任务失效 if (Thread.currentThread() == workerThread) &#123; throw new IllegalStateException( HashedWheelTimer.class.getSimpleName() + ".stop() cannot be called from " + TimerTask.class.getSimpleName()); &#125; // 尝试CAS替换当前状态为“停止：2”。如果失败，则当前时间轮的状态只能是“初始化：0”或者“停止：2”。直接将当前状态设置为“停止：2“ if (!WORKER_STATE_UPDATER.compareAndSet(this, WORKER_STATE_STARTED, WORKER_STATE_SHUTDOWN)) &#123; // workerState can be 0 or 2 at this moment - let it always be 2. WORKER_STATE_UPDATER.set(this, WORKER_STATE_SHUTDOWN); if (leak != null) &#123; leak.close(); &#125; return Collections.emptySet(); &#125; // 终端worker线程 boolean interrupted = false; while (workerThread.isAlive()) &#123; workerThread.interrupt(); try &#123; workerThread.join(100); &#125; catch (InterruptedException ignored) &#123; interrupted = true; &#125; &#125; // 从中断中恢复 if (interrupted) &#123; Thread.currentThread().interrupt(); &#125; if (leak != null) &#123; leak.close(); &#125; // 返回未处理的任务 return worker.unprocessedTimeouts();&#125; newTimeout()添加定时任务： 1234567891011121314151617181920public Timeout newTimeout(TimerTask task, long delay, TimeUnit unit) &#123; // 参数校验 if (task == null) &#123; throw new NullPointerException("task"); &#125; if (unit == null) &#123; throw new NullPointerException("unit"); &#125; // 如果时间轮没有启动，则启动 start(); // Add the timeout to the timeout queue which will be processed on the next tick. // During processing all the queued HashedWheelTimeouts will be added to the correct HashedWheelBucket. // 计算任务的deadline long deadline = System.nanoTime() + unit.toNanos(delay) - startTime; // 这里定时任务不是直接加到对应的格子中，而是先加入到一个队列里，然后等到下一个tick的时候，会从队列里取出最多100000个任务加入到指定的格子中 HashedWheelTimeout timeout = new HashedWheelTimeout(this, task, deadline); timeouts.add(timeout); return timeout;&#125; 这里使用的Queue不是普通java自带的Queue的实现，而是使用JCTool–一个高性能的的并发Queue实现包。 HashedWheelTimer源码之HashedWheelTimeoutHashedWheelTimeout是一个定时任务的内部包装类，双向链表结构。会保存定时任务到期执行的任务、deadline、round等信息。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107private static final class HashedWheelTimeout implements Timeout &#123; // 定义定时任务的3个状态：初始化、取消、过期 private static final int ST_INIT = 0; private static final int ST_CANCELLED = 1; private static final int ST_EXPIRED = 2; // 用来CAS方式更新定时任务状态 private static final AtomicIntegerFieldUpdater&lt;HashedWheelTimeout&gt; STATE_UPDATER; static &#123; AtomicIntegerFieldUpdater&lt;HashedWheelTimeout&gt; updater = PlatformDependent.newAtomicIntegerFieldUpdater(HashedWheelTimeout.class, "state"); if (updater == null) &#123; updater = AtomicIntegerFieldUpdater.newUpdater(HashedWheelTimeout.class, "state"); &#125; STATE_UPDATER = updater; &#125; // 时间轮引用 private final HashedWheelTimer timer; // 具体到期需要执行的任务 private final TimerTask task; private final long deadline; @SuppressWarnings(&#123;"unused", "FieldMayBeFinal", "RedundantFieldInitialization" &#125;) private volatile int state = ST_INIT; // 离任务执行的轮数，当将次任务加入到格子中是计算该值，每过一轮，该值减一。 long remainingRounds; // 双向链表结构，由于只有worker线程会访问，这里不需要synchronization / volatile HashedWheelTimeout next; HashedWheelTimeout prev; // 定时任务所在的格子 HashedWheelBucket bucket; HashedWheelTimeout(HashedWheelTimer timer, TimerTask task, long deadline) &#123; this.timer = timer; this.task = task; this.deadline = deadline; &#125; @Override public Timer timer() &#123; return timer; &#125; @Override public TimerTask task() &#123; return task; &#125; @Override public boolean cancel() &#123; // 这里只是修改状态为ST_CANCELLED，会在下次tick时，在格子中移除 if (!compareAndSetState(ST_INIT, ST_CANCELLED)) &#123; return false; &#125; // 加入到时间轮的待取消队列，并在每次tick的时候，从相应格子中移除。 timer.cancelledTimeouts.add(this); return true; &#125; // 从格子中移除自身 void remove() &#123; HashedWheelBucket bucket = this.bucket; if (bucket != null) &#123; bucket.remove(this); &#125; &#125; public boolean compareAndSetState(int expected, int state) &#123; return STATE_UPDATER.compareAndSet(this, expected, state); &#125; public int state() &#123; return state; &#125; @Override public boolean isCancelled() &#123; return state() == ST_CANCELLED; &#125; @Override public boolean isExpired() &#123; return state() == ST_EXPIRED; &#125; // 过期并执行任务 public void expire() &#123; if (!compareAndSetState(ST_INIT, ST_EXPIRED)) &#123; return; &#125; try &#123; task.run(this); &#125; catch (Throwable t) &#123; if (logger.isWarnEnabled()) &#123; logger.warn("An exception was thrown by " + TimerTask.class.getSimpleName() + '.', t); &#125; &#125; &#125; // 略过toString()&#125; HashedWheelTimer源码之HashedWheelBucketHashedWheelBucket用来存放HashedWheelTimeout，结构类似于LinkedList。提供了expireTimeouts(long deadline)方法来过期并执行格子中的定时任务 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114private static final class HashedWheelBucket &#123; // 指向格子中任务的首尾 private HashedWheelTimeout head; private HashedWheelTimeout tail; // 基础的链表添加操作 public void addTimeout(HashedWheelTimeout timeout) &#123; assert timeout.bucket == null; timeout.bucket = this; if (head == null) &#123; head = tail = timeout; &#125; else &#123; tail.next = timeout; timeout.prev = tail; tail = timeout; &#125; &#125; // 过期并执行格子中的到期任务，tick到该格子的时候，worker线程会调用这个方法，根据deadline和remainingRounds判断任务是否过期 public void expireTimeouts(long deadline) &#123; HashedWheelTimeout timeout = head; // 遍历格子中的所有定时任务 while (timeout != null) &#123; boolean remove = false; if (timeout.remainingRounds &lt;= 0) &#123; // 定时任务到期 if (timeout.deadline &lt;= deadline) &#123; timeout.expire(); &#125; else &#123; // 如果round数已经为0，deadline却&gt;当前格子的deadline，说放错格子了，这种情况应该不会出现 throw new IllegalStateException(String.format( "timeout.deadline (%d) &gt; deadline (%d)", timeout.deadline, deadline)); &#125; remove = true; &#125; else if (timeout.isCancelled()) &#123; remove = true; &#125; else &#123; //没有到期，轮数-1 timeout.remainingRounds --; &#125; // 先保存next，因为移除后next将被设置为null HashedWheelTimeout next = timeout.next; if (remove) &#123; remove(timeout); &#125; timeout = next; &#125; &#125; // 基础的链表移除node操作 public void remove(HashedWheelTimeout timeout) &#123; HashedWheelTimeout next = timeout.next; // remove timeout that was either processed or cancelled by updating the linked-list if (timeout.prev != null) &#123; timeout.prev.next = next; &#125; if (timeout.next != null) &#123; timeout.next.prev = timeout.prev; &#125; if (timeout == head) &#123; // if timeout is also the tail we need to adjust the entry too if (timeout == tail) &#123; tail = null; head = null; &#125; else &#123; head = next; &#125; &#125; else if (timeout == tail) &#123; // if the timeout is the tail modify the tail to be the prev node. tail = timeout.prev; &#125; // null out prev, next and bucket to allow for GC. timeout.prev = null; timeout.next = null; timeout.bucket = null; &#125; /** * Clear this bucket and return all not expired / cancelled &#123;@link Timeout&#125;s. */ public void clearTimeouts(Set&lt;Timeout&gt; set) &#123; for (;;) &#123; HashedWheelTimeout timeout = pollTimeout(); if (timeout == null) &#123; return; &#125; if (timeout.isExpired() || timeout.isCancelled()) &#123; continue; &#125; set.add(timeout); &#125; &#125; // 链表的poll操作 private HashedWheelTimeout pollTimeout() &#123; HashedWheelTimeout head = this.head; if (head == null) &#123; return null; &#125; HashedWheelTimeout next = head.next; if (next == null) &#123; tail = this.head = null; &#125; else &#123; this.head = next; next.prev = null; &#125; // null out prev and next to allow for GC. head.next = null; head.prev = null; head.bucket = null; return head; &#125;&#125; HashedWheelTimer源码之WorkerWorker是时间轮的核心线程类。tick的转动，过期任务的处理都是在这个线程中处理的。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154private final class Worker implements Runnable &#123; private final Set&lt;Timeout&gt; unprocessedTimeouts = new HashSet&lt;Timeout&gt;(); private long tick; @Override public void run() &#123; // 初始化startTime.只有所有任务的的deadline都是想对于这个时间点 startTime = System.nanoTime(); // 由于System.nanoTime()可能返回0，甚至负数。并且0是一个标示符，用来判断startTime是否被初始化，所以当startTime=0的时候，重新赋值为1 if (startTime == 0) &#123; startTime = 1; &#125; // 唤醒阻塞在start()的线程 startTimeInitialized.countDown(); // 只要时间轮的状态为WORKER_STATE_STARTED，就循环的“转动”tick，循环判断响应格子中的到期任务 do &#123; // waitForNextTick方法主要是计算下次tick的时间, 然后sleep到下次tick // 返回值就是System.nanoTime() - startTime, 也就是Timer启动后到这次tick, 所过去的时间 final long deadline = waitForNextTick(); if (deadline &gt; 0) &#123; // 可能溢出或者被中断的时候会返回负数, 所以小于等于0不管 // 获取tick对应的格子索引 int idx = (int) (tick &amp; mask); // 移除被取消的任务 processCancelledTasks(); HashedWheelBucket bucket = wheel[idx]; // 从任务队列中取出任务加入到对应的格子中 transferTimeoutsToBuckets(); // 过期执行格子中的任务 bucket.expireTimeouts(deadline); tick++; &#125; &#125; while (WORKER_STATE_UPDATER.get(HashedWheelTimer.this) == WORKER_STATE_STARTED); // 这里应该是时间轮停止了，清除所有格子中的任务，并加入到未处理任务列表，以供stop()方法返回 for (HashedWheelBucket bucket: wheel) &#123; bucket.clearTimeouts(unprocessedTimeouts); &#125; // 将还没有加入到格子中的待处理定时任务队列中的任务取出，如果是未取消的任务，则加入到未处理任务队列中，以供stop()方法返回 for (;;) &#123; HashedWheelTimeout timeout = timeouts.poll(); if (timeout == null) &#123; break; &#125; if (!timeout.isCancelled()) &#123; unprocessedTimeouts.add(timeout); &#125; &#125; // 处理取消的任务 processCancelledTasks(); &#125; // 将newTimeout()方法中加入到待处理定时任务队列中的任务加入到指定的格子中 private void transferTimeoutsToBuckets() &#123; // 每次tick只处理10w个任务，以免阻塞worker线程 for (int i = 0; i &lt; 100000; i++) &#123; HashedWheelTimeout timeout = timeouts.poll(); // 如果没有任务了，直接跳出循环 if (timeout == null) &#123; break; &#125; // 还没有放入到格子中就取消了，直接略过 if (timeout.state() == HashedWheelTimeout.ST_CANCELLED) &#123; continue; &#125; // 计算任务需要经过多少个tick long calculated = timeout.deadline / tickDuration; // 计算任务的轮数 timeout.remainingRounds = (calculated - tick) / wheel.length; //如果任务在timeouts队列里面放久了, 以至于已经过了执行时间, 这个时候就使用当前tick, 也就是放到当前bucket, 此方法调用完后就会被执行. final long ticks = Math.max(calculated, tick); // Ensure we don't schedule for past. int stopIndex = (int) (ticks &amp; mask); // 将任务加入到响应的格子中 HashedWheelBucket bucket = wheel[stopIndex]; bucket.addTimeout(timeout); &#125; &#125; // 将取消的任务取出，并从格子中移除 private void processCancelledTasks() &#123; for (;;) &#123; HashedWheelTimeout timeout = cancelledTimeouts.poll(); if (timeout == null) &#123; // all processed break; &#125; try &#123; timeout.remove(); &#125; catch (Throwable t) &#123; if (logger.isWarnEnabled()) &#123; logger.warn("An exception was thrown while process a cancellation task", t); &#125; &#125; &#125; &#125; /** * calculate goal nanoTime from startTime and current tick number, * then wait until that goal has been reached. * @return Long.MIN_VALUE if received a shutdown request, * current time otherwise (with Long.MIN_VALUE changed by +1) */ //sleep, 直到下次tick到来, 然后返回该次tick和启动时间之间的时长 private long waitForNextTick() &#123; //下次tick的时间点, 用于计算需要sleep的时间 long deadline = tickDuration * (tick + 1); for (;;) &#123; // 计算需要sleep的时间, 之所以加999999后再除10000000, 是为了保证足够的sleep时间 // 例如：当deadline - currentTime=2000002的时候，如果不加999999，则只睡了2ms， // 而2ms其实是未到达deadline这个时间点的，所有为了使上述情况能sleep足够的时间，加上999999后，会多睡1ms final long currentTime = System.nanoTime() - startTime; long sleepTimeMs = (deadline - currentTime + 999999) / 1000000; if (sleepTimeMs &lt;= 0) &#123; // 以下为个人理解：（如有错误，欢迎大家指正） // 这里的意思应该是从时间轮启动到现在经过太长的时间(跨度大于292年...)，以至于让long装不下，都溢出了...对于netty的严谨，我服！ if (currentTime == Long.MIN_VALUE) &#123; return -Long.MAX_VALUE; &#125; else &#123; return currentTime; &#125; &#125; // Check if we run on windows, as if thats the case we will need // to round the sleepTime as workaround for a bug that only affect // the JVM if it runs on windows. // // See https://github.com/netty/netty/issues/356 if (PlatformDependent.isWindows()) &#123; // 这里是因为windows平台的定时调度最小单位为10ms，如果不是10ms的倍数，可能会引起sleep时间不准确 sleepTimeMs = sleepTimeMs / 10 * 10; &#125; try &#123; Thread.sleep(sleepTimeMs); &#125; catch (InterruptedException ignored) &#123; // 调用HashedWheelTimer.stop()时优雅退出 if (WORKER_STATE_UPDATER.get(HashedWheelTimer.this) == WORKER_STATE_SHUTDOWN) &#123; return Long.MIN_VALUE; &#125; &#125; &#125; &#125; public Set&lt;Timeout&gt; unprocessedTimeouts() &#123; return Collections.unmodifiableSet(unprocessedTimeouts); &#125;&#125; 总结通过阅读源码，学到了很多之前不知道的知识点和注意事项。比如： 操作数字型要考虑溢出问题 System.nanoTime(）返回值 Atomic*FieldUpdater类的运用 一些代码设计方式 不断优化性能，Lock Less代替Lock；Lock Free代替Lock Less JCTool高性能队列的使用]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[spring3的@Async异步执行失效]]></title>
      <url>%2F2016%2F09%2F11%2Fspring3-async%2F</url>
      <content type="text"><![CDATA[背景最近有个项目的spring的@Async的异步执行突然失效了。生产环境异步执行正常，那肯定是开发改了某个地方而导致的。 排查查看最近提交代码记录。与@Async有相关的改动只有一个spring.xml的改动。初步推断是这个改动引起的。回滚这部分代码，跑测试类，果然异步执行生效了。 原因在stackoverflow中找到了答案： In short, the context loaded by the ContextLoaderListener (generally from applicationContext.xml) is the parent of the context loaded by the DispatcherServlet (generally from -servlet.xml). If you have the bean with the @Async method declared/component-scanned in both contexts, the version from the child context (DispatcherServlet) will override the one in the parent context (ContextLoaderListener). I verified this by excluding that component from component scanning in the -servlet.xml – it now works as expected. 意思是说：如果项目中存在多个配置文件（例如：applicationContext.xml、applicationContext-servlet.xml）并且这两个文件中配置的扫描包（即配置的：context:component-scan）都包含了配置过@Async的bean，那么后者就会覆盖前者。 例如以下xml配置: applicationContext.xml: &lt;context:component-scan base-package=&quot;com.demo&quot; /&gt; &lt;task:annotation-driven/&gt; &lt;task:executor id=&quot;executor&quot; pool-size=&quot;5-10&quot; queue-capacity=&quot;100&quot; rejection-policy=&quot;CALLER_RUNS&quot;/&gt; applicationContext-servlet.xml: &lt;context:component-scan base-package=&quot;com.demo&quot; /&gt; 并且在web.xml中配置的加载顺序为：applicationContext.xml &gt; applicationContext-servlet.xml，那么后者的component-scan就会覆盖前者的，同时前者配置的task也会被覆盖掉不起作用！]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[mac中jdk的路径]]></title>
      <url>%2F2016%2F09%2F08%2Fmac-jdk-dir%2F</url>
      <content type="text"><![CDATA[mac中如何查询jdk安装路径可以使用工具命令/usr/libexec/java_home. 例如以下所示： 还可以加-V选项列出所有的java home. 例如以下所示:]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Hash碰撞]]></title>
      <url>%2F2016%2F08%2F29%2Fhash-collision%2F</url>
      <content type="text"><![CDATA[Hash定义摘自百度百科： Hash，一般翻译做“散列”，也有直接音译为“哈希”的，就是把任意长度的输入（又叫做预映射， pre-image），通过散列算法，变换成固定长度的输出，该输出就是散列值。这种转换是一种压缩映射，也就是，散列值的空间通常远小于输入的空间，不同的输入可能会散列成相同的输出，所以不可能从散列值来唯一的确定输入值。简单的说就是一种将任意长度的消息压缩到某一固定长度的消息摘要的函数。 为什么会产生Hash碰撞 …通过散列算法，变换成固定长度的输出，该输出就是散列值… 既然是根据输入值，变换成固定长度的输出，那就必然会存在不同的输入产生相同的输出。 如何解决Hash碰撞开放地址法这种方法就是在计算一个key的哈希的时候，发现目标地址已经有值了，即发生冲突了，这个时候通过相应的函数在此地址后面的地址去找，直到没有冲突为止。这个方法常用的有线性探测，二次探测，再哈希。这种解决方法有个不好的地方就是，当发生冲突之后，会在之后的地址空间中找一个放进去，这样就有可能后来出现一个key哈希出来的结果也正好是它放进去的这个地址空间，这样就会出现非同义词的两个key发生冲突。 拉链法拉链法是通过数组+链表的形式组合而成的。当发送碰撞后，只需将其追加到对应的链表中即可。如下图所示： java中的HashMap也是采用这种方法解决Hash冲突的。 与开放地址法相比，拉链法有如下优点： 拉链法处理冲突简单，且无堆积现象，即非同义词决不会发生冲突，因此平均查找长度较短 由于链接法中各链表上的结点空间是动态申请的，故它更适合于造表前无法确定表长的情况 开放定址法为减少冲突，要求装填因子α较小，故当结点规模较大时会浪费很多空间。而链接法中可取α≥1，且结点较大时，拉链法中增加的指针域可忽略不计，因此节省空间 用链接法构造的散列表中，删除结点的操作易于实现。只要简单地删去链表上相应的结点即可。而对开放地址法构造的散列表，删除结点不能简单地将被删结点的空间置为空，否则将截断在它之后填入散列表的同义词结点的查找路径。这是因为各种开放地址法中，空地址单元(即开放地址)都是查找失败的条件。因此在 用开放地址法处理冲突的散列表上执行删除操作，只能在被删结点上做删除标记，而不能真正删除结点 拉链法的缺点： 链表指针需要额外空间 以HashMap为例，如果每次插入都产生碰撞，HashMap将退化为一个链表而导致查询的时间复杂度从O(1)变成了O(n)。我们称之为HashMap退化。 P.S. 这里说明下，在jdk8下，HashMap有个改进。当链表的长度大于8时，将转化为一棵红黑树存储。这样即使在最差情况下，查找速度也将在O(lgn) Hash碰撞攻击由于存在Hash碰撞，攻击者只要制造大量碰撞的Hash输入。将会造成大量Hash堆积，轻则查询速度缓慢，拖累网站服务。重则内存溢出，网站服务崩溃。 如何进行Hash碰撞攻击Hash碰撞攻击其实就是寻找Hash碰撞的过程。 目前寻找Hash碰撞的方式有以下4中： 相等子串法：针对某些Hash函数具有相同的字符串组合在上下文中相同位置的Hash值都相同的特性来构造碰撞的。比如f（“string1”）=f（“string2”），那么字符串“aaastring1bbb”与字符串“aaastring2bbb”中，“string1”与“string2”具有相同的Hash值。针对这个特性我们可以构造任意多的碰撞，比如“Ly”和“nz”的Hash值相同，那么“LyLy”、“nznz”、“Lynz”、“nzLy”的Hash值都相同。 生日攻击法：生日攻击方法没有利用Hash函数的结构和任何代数弱性质，它只依赖于消息摘要的长度，即Hash值的长度。这种攻击对Hash函数提出了一个必要的安全条件，即消息摘要必须足够长。生日攻击(传送门)这个术语来自于所谓的生日悖论（传送门）：在一个教室中最少应有多少学生才使得至少有两个学生的生日在同一天的概率不小于1/2？这个问题的答案为23。 中间相遇法：生日攻击的一种变形，它不比较Hash值，而是比较链中的中间变量。这种攻击主要适用于攻击具有分组链结构的Hash方案。中间相遇攻击的基本原理为：将消息分成两部分，对伪造消息的第一部分从初试值开始逐步向中间阶段产生r1个变量；对伪造消息的第二部分从Hash结果开始逐步退回中间阶段产生r2个变量。在中间阶段有一个匹配的概率与生日攻击成功的概率一样。 模差分法：比较高效。应该是目前效率最好的一种方法。传送门 如何抵御Hash碰撞攻击这时候就需要一个算法良好的Hash函数，使最终的Hash值尽量的分布均匀。 目前主流的是time33算法及其变种。 time33算法代码示例： 12345678public int time33(char[] str) &#123; int hash = 0; for (char c : str) &#123; hash = hash * 33 + c; &#125; return hash;&#125; 为什么要用33这个倍数因子呢？ 因为1到256之间的所有奇数，都能达到一个可接受的哈希分布，平均分布大概是86%。而其中33，17，31，63，127，129这几个数在面对大量的哈希运算时有一个更大的优势，就是这些数字能将乘法用位运算配合加减法替换，这样运算速度会更高。并不是所有基于time33的算法都使用33作为倍数，如Ngix使用的是time31，Tokyo Cabinet使用的是time37。 P.S. jdk的String.hashCode使用的是time31.而common-lang3中的HashCodeBuilder默认使用的是time37. String.hashCode代码如下： 1234567891011121314151617181920212223242526/** * Returns a hash code for this string. The hash code for a * &#123;@code String&#125; object is computed as * &lt;blockquote&gt;&lt;pre&gt; * s[0]*31^(n-1) + s[1]*31^(n-2) + ... + s[n-1] * &lt;/pre&gt;&lt;/blockquote&gt; * using &#123;@code int&#125; arithmetic, where &#123;@code s[i]&#125; is the * &lt;i&gt;i&lt;/i&gt;th character of the string, &#123;@code n&#125; is the length of * the string, and &#123;@code ^&#125; indicates exponentiation. * (The hash value of the empty string is zero.) * * @return a hash code value for this object. */public int hashCode() &#123; int h = hash; if (h == 0 &amp;&amp; value.length &gt; 0) &#123; char val[] = value; for (int i = 0; i &lt; value.length; i++) &#123; h = 31 * h + val[i]; &#125; hash = h; &#125; return h;&#125;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[红黑树&TreeMap的实现原理]]></title>
      <url>%2F2016%2F08%2F26%2FtreeMap-theory%2F</url>
      <content type="text"><![CDATA[前言由于TreeMap的实现原理就是以红黑树为基础数据结构的，所以基本也是红黑树的原理解读。 红黑树红黑树是一种自平衡的二叉查找树。是一种复杂但高效的数据结构，它可以在O(log n)时间内做查找，插入和删除。 红黑树的规定： 1.一个节点只能是红色或者黑色2.根节点是黑色3.每个叶节点（null节点/空节点）为黑色4.如果一个节点为红色，则他们的2个子节点都为黑色5.从任意节点到其每个叶节点 红黑树结构java代码示例：（TreeMap中的内部类Entry） 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071/** * 红黑树节点结构 */ static final class Entry&lt;K, V&gt; implements Map.Entry&lt;K, V&gt; &#123; K key; // 红黑树的排序字段 V value; // 节点存储的值 Entry&lt;K, V&gt; left; // 左子树节点 Entry&lt;K, V&gt; right; // 右子树节点 Entry&lt;K, V&gt; parent; // 父节点 boolean color = BLACK; // 节点颜色，默认为黑 /** * Make a new cell with given key, value, and parent, and with * &#123;@code null&#125; child links, and BLACK color. */ Entry(K key, V value, Entry&lt;K, V&gt; parent) &#123; this.key = key; this.value = value; this.parent = parent; &#125; /** * Returns the key. * * @return the key */ public K getKey() &#123; return key; &#125; /** * Returns the value associated with the key. * * @return the value associated with the key */ public V getValue() &#123; return value; &#125; /** * Replaces the value currently associated with the key with the given * value. * * @return the value associated with the key before this method was * called */ public V setValue(V value) &#123; V oldValue = this.value; this.value = value; return oldValue; &#125; public boolean equals(Object o) &#123; if (!(o instanceof Map.Entry)) return false; Map.Entry&lt;?, ?&gt; e = (Map.Entry&lt;?, ?&gt;) o; return valEquals(key, e.getKey()) &amp;&amp; valEquals(value, e.getValue()); &#125; public int hashCode() &#123; int keyHash = (key == null ? 0 : key.hashCode()); int valueHash = (value == null ? 0 : value.hashCode()); return keyHash ^ valueHash; &#125; public String toString() &#123; return key + "=" + value; &#125; &#125; 红黑树的平衡在介绍红黑树的插入前，先弄清楚红黑树如何保持平衡。因为一般在对红黑树插入后，需要对红黑树做平衡化处理。 红黑树的左旋红黑树的左旋操作如下图： 代码如下所示：(TreeMap.rotateLeft) 123456789101112131415161718192021222324252627282930/** * 红黑树左旋 */private void rotateLeft(Entry&lt;K, V&gt; p) &#123; if (p != null) &#123; // 获取p(对应动图中的E节点)的右子节点定义为r(对应为动图中的S) Entry&lt;K, V&gt; r = p.right; // 将p的右子节点设置为r的左子节点 p.right = r.left; // 如果r的左子节点不为空,则设置r的左子节点的父节点为p if (r.left != null) r.left.parent = p; // 将r的父节点设置为p的父节点 r.parent = p.parent; // 如果p没有父节点,则将r设置为根节点 if (p.parent == null) root = r; // 如果p为p父节点的左子节点,则将p的父节点的左子节点设置为r else if (p.parent.left == p) p.parent.left = r; // 反之将p的父节点的右子结点设置为r else p.parent.right = r; // 将r的左子节点设置为p r.left = p; // 将p的父节点设置为r p.parent = r; &#125;&#125; 红黑树的右旋红黑树的右旋操作如下图： 代码如下所示：（TreeMap.rotateRight） 12345678910111213141516171819202122232425262728/** * 红黑树右旋 */private void rotateRight(Entry&lt;K, V&gt; p) &#123; if (p != null) &#123; // 将p的左子节点定义为l Entry&lt;K, V&gt; l = p.left; // 将p的左子节点设置为l的右子节点 p.left = l.right; // 如果l的右子节点不为空,则将l的右子节点的父节点设置为p if (l.right != null) l.right.parent = p; // 将l的父节点设置为p的父节点 l.parent = p.parent; // 如果p的父节点为空,则将l设置为根节点 if (p.parent == null) root = l; // 如果p为p的父节点的右子节点,则将p的父节点的右子节点设置为l else if (p.parent.right == p) p.parent.right = l; // 反之将p的父节点的左子节点设置为l else p.parent.left = l; // 将l的右子节点设置为p l.right = p; // 将p的父节点设置为l p.parent = l; &#125;&#125; 红黑树插入首先红黑树是一棵二叉查找树，所以新增一个节点，首先根据二叉树的性质找到相应的节点位置。然后根据红黑树的特点进行调整和平衡。 红黑树新增节点需要注意以下三点： 1.新增节点默认为红色。2.如果新增的节点的父节点为黑色，那么能维持红黑树的性质。3.如果新增的节点的父节点为红色，那么会破坏红黑树的性质。需要通过重新着色、旋转等手段来维持红黑树的性质。 红黑树的节点新增有以下5种情况：(以下约定,新增节点为N,父节点为P,叔父节点为U,祖父节点为G) 1.新增节点没有父节点，即为跟节点，直接设置为黑色。2.新增节点的父节点为黑色，则直接插入。3.新增节点(N)的父节点(P)和叔父节点(U)都为红色-&gt;将父节点(P)和叔父节点(U)设置为黑，祖父节点(G)设置为红。这时候，由于经由父节点(P)和叔父节点(U)的路径必经过祖父节点(G)，所以这些路径上的黑色节点数目还是相同的。但是祖父节点(G)变为红色之后，祖父节点(G)的父节点可能也是红色，这时候就要将祖父节点(G)当做新增节点递归处理。如下图所示： 4.新增节点(N)的父节点(P)为红色，父节点(P)为祖父节点(G)的左子节点，叔父节点(U)都为黑色或者缺少，且新增节点(N)为父节点(P)的右子节点-&gt;将节点N,P左旋（如下图所所示）。这里注意，如果父节点(P)为祖父节点(G)的右子节点时是要进行右旋。然后产生的结果其实还没有完成，以为违反了规则4，将P节点作为新增节点进行情况5的操作。 5.新增节点(N)的父节点(P)为红色，父节点(P)为祖父节点(G)的左子节点，叔父节点(U)都为黑色或者缺少，且新增节点(N)为父节点(P)的左子节点-&gt;将祖父节(G)与父节点(P)进行右旋（如果父节点(P)为祖父节点(G)的右子节点，进行左旋），然而还没有完成，因为节点P,N都为红色，违反了规则4。将P,G的颜色进行交换。如下图所示： TreeMap中元素的插入TreeMap的put()方法其实只是找到新增节点插入的位置，而插入之后的红黑树平黑调整调用了fixAfterInsertion()方法进行。put()方法代码如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091/** * Associates the specified value with the specified key in this map. * If the map previously contained a mapping for the key, the old * value is replaced. * * @param key key with which the specified value is to be associated * @param value value to be associated with the specified key * @return the previous value associated with &#123;@code key&#125;, or * &#123;@code null&#125; if there was no mapping for &#123;@code key&#125;. * (A &#123;@code null&#125; return can also indicate that the map * previously associated &#123;@code null&#125; with &#123;@code key&#125;.) * @throws ClassCastException if the specified key cannot be compared * with the keys currently in the map * @throws NullPointerException if the specified key is null * and this map uses natural ordering, or its comparator * does not permit null keys */public V put(K key, V value) &#123; // 用t表示当前root节点(也就是整棵数) Entry&lt;K, V&gt; t = root; // 当t为null时,说明是空树,treeMap中没有元素,直接插入 if (t == null) &#123; /* 这里key自我比较很奇怪。 其实是为了key的null校验和k类型检查。 校验key是否可比较的. 这里其实可以用类泛型限定,如TreeMap&lt;key extends Comparable&gt;,之所以没有这么做应该是jdk版本兼容性的考虑 */ compare(key, key); // type (and possibly null) check // 根据key-value,生成节点赋值为root root = new Entry&lt;&gt;(key, value, null); // 容器的元素数量赋值为1 size = 1; // 修改次数+1 modCount++; return null; &#125; int cmp;// key排序比较的结果 Entry&lt;K, V&gt; parent;// 父节点 // split comparator and comparable paths Comparator&lt;? super K&gt; cpr = comparator; // 如果指定的比较器不为空,使用指定的比较器进行比较 if (cpr != null) &#123; do &#123; parent = t;//parent赋值为上次循环后的t // 比较key和当前节点的key cmp = cpr.compare(key, t.key); // key小于当前节点的key,则t指向t的左子节点 if (cmp &lt; 0) t = t.left; // key大于当前节点的key,则t指向t的右子节点 else if (cmp &gt; 0) t = t.right; // key等于当前节点的key,直接在当前节点设置新值并返回 else return t.setValue(value); &#125; while (t != null);//递归的进行上述操作,直到t==null &#125; else &#123; // 如果没有知道比较器,则按照默认的比较方式(即自然顺序) // 如果key==null抛出空指针异常 if (key == null) throw new NullPointerException(); // 以下处理过程和上面的一样 @SuppressWarnings("unchecked") Comparable&lt;? super K&gt; k = (Comparable&lt;? super K&gt;) key; do &#123; parent = t; cmp = k.compareTo(t.key); if (cmp &lt; 0) t = t.left; else if (cmp &gt; 0) t = t.right; else return t.setValue(value); &#125; while (t != null); &#125; // 将新增的节点当做parent的子节点 Entry&lt;K, V&gt; e = new Entry&lt;&gt;(key, value, parent); // 新增节点key小于parent的key,则作为左子节点 if (cmp &lt; 0) parent.left = e; // 新增节点key大于parent的key,则作为右子节点 else parent.right = e; // 新增节点已经在合适的位置了,然后进行红黑树的平衡调整 fixAfterInsertion(e); size++; modCount++; return null;&#125; 再来看看fixAfterInsertion()如何进行红黑树的平衡的，代码如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576/** * 红黑树平衡 */private void fixAfterInsertion(Entry&lt;K, V&gt; x) &#123; x.color = RED; // 新增节点的颜色设置为红色 // 循环直到x为null或者x是根节点或者x的父节点为黑色 while (x != null &amp;&amp; x != root &amp;&amp; x.parent.color == RED) &#123; // 如果x的父节点为x的祖父节点的左节点 if (parentOf(x) == leftOf(parentOf(parentOf(x)))) &#123; // 获取x的叔父节点定义为y Entry&lt;K, V&gt; y = rightOf(parentOf(parentOf(x))); // 如果叔父节点的颜色为红色(情况3) if (colorOf(y) == RED) &#123; // 设置父节点的颜色为黑色 setColor(parentOf(x), BLACK); // 设置叔父节点的颜色为黑色 setColor(y, BLACK); // 设置祖父节点的颜色为红色 setColor(parentOf(parentOf(x)), RED); // x赋值为祖父节点,递归判断 x = parentOf(parentOf(x)); &#125; // 如果叔父节点的颜色为黑色 else &#123; // 如果x为其父节点的右节点(情况4) if (x == rightOf(parentOf(x))) &#123; // x赋值为其父节点 x = parentOf(x); // 根据x的父节点进行左旋 rotateLeft(x); &#125; // 情况5 // 设置x的父节点为黑色 setColor(parentOf(x), BLACK); // 设置x的祖父节点为红色 setColor(parentOf(parentOf(x)), RED); // 根据x的祖父节点右旋 rotateRight(parentOf(parentOf(x))); &#125; &#125; // 如果x的父节点为x的祖父节点的右节点 else &#123; // 定义x的叔父节点为y Entry&lt;K, V&gt; y = leftOf(parentOf(parentOf(x))); // 如果叔父节点的颜色为红色(情况3) if (colorOf(y) == RED) &#123; setColor(parentOf(x), BLACK); setColor(y, BLACK); setColor(parentOf(parentOf(x)), RED); x = parentOf(parentOf(x)); &#125; // 如果叔父节点的颜色为黑色 else &#123; // 如果x为其父节点的左子节点(情况4) if (x == leftOf(parentOf(x))) &#123; // x赋值为其父节点 x = parentOf(x); // 针对x父节点右旋 rotateRight(x); &#125; // 情况5 // 设置x的父节点颜色为黑色 setColor(parentOf(x), BLACK); // 设置祖父节点颜色为红色 setColor(parentOf(parentOf(x)), RED); // 根据祖父节点进行左旋 rotateLeft(parentOf(parentOf(x))); &#125; &#125; &#125; // 设置根节点颜色为黑色 root.color = BLACK;&#125; 红黑树的删除相比较红黑树的插入，红黑树的删除更加复杂。删除一个节点，一般要寻找一个真正的删除点,替代删除点，然后根据删除点做红黑树的平衡。 如何寻找到真正的删除点呢？其实就是寻找待删除点的中序遍历(LDR)的前继节点或者后继节点。即待删除点的最左父树的右父节点或者右子树的最左节点。 所以可以推断出，真正的删除点必定是一个只有一个孩子或者没有孩子的节点，而根据红黑树的性质，可以得出以下2个结论： 真正的删除点必定只有一个红色孩子节点或者没有孩子节点 如果真正的删除点是一个红色节点，那它必定是个叶子节点 所以，红黑树的删除步骤如下： 1.寻找真正的删除点，将真正删除点的元素赋值为待删除点2.删除真正的删除点，如果删除点有子节点，以子节点代替其位置3.以删除点开始判定红黑树的平衡性质4.如有必要做相应的平衡操作 以下开始讨论红黑树删除的几种情况。我们约定，真正的删除点使用“旧”标记，旧点所在位置将被他的子节点取代（最多只会有一个子节点），我们使用“新”标记旧点的孩子节点。删除操作会有以下集中情况： 1.旧点为红色节点 若旧点为红色节点，则它必定为叶子节点，直接删除即可。 2.一黑一红 当旧点为黑色结点，新点为红色结点时，将新点取代旧点位置后，将新点染成黑色即可（如下图所示）。这里需要注意：旧点为红色，新点为黑色的情况不可能存在。 3.双黑 当旧点和新点都为黑色是（新点为空节点也属于这种情况），情况比较复杂，需要根据旧点兄弟结点的颜色来决定进行什么样的操作。我们使用“兄”来表示旧点的兄弟结点。 3.1 红兄 由于兄弟结点为红色，所以父结点必定为黑色，而旧点被删除后，新点取代了它的位置。下图演示了两种可能的情况： 红兄的情况需要进行RR或LL型旋转，然后将父结点染成红色，兄结点染成黑色。然后重新以新点为判定点进行平衡操作。我们可以观察到，旋转操作完成后，判定点没有向上回溯，而是降低了一层，此时变成了黑兄的情况（可能会是3.2.1、3.2.2、3.2.3）。 3.2 黑兄 黑兄的情况最为复杂，需要根据黑兄孩子结点（这里用“侄”表示）和父亲结点的颜色来决定做什么样的操作。 3.2.1 黑兄二黑侄 这种情况比较简单，只需将兄结点变为红色即可，然后根据父节点继续平衡。（其实这时候如果父节点为红色，将父节点设置为黑色，删除操作就结束了）如下图所示： 3.2.2 黑兄右黑侄 黑兄，左侄红色，右侄黑色这种情况需要区分新点是起父节点的左子节点还是右子节点。 3.2.2-1 新点是其父的左子节点 将左侄设置为黑，兄节点设置为红色，然后以兄节点右旋（将情况转为了3.2.3-1）。如下图所示： 3.2.2-2 新点为其父节点的右子节点 将兄节点的颜色设置为父节点颜色，父节点和左侄节点设置为黑色，然后根据父节点右旋。删除操作结束。如下图所示： 3.2.3 黑兄左黑侄 黑兄，左黑侄，右红侄的情况也是需要区分新点是起父节点的左子节点还是右子节点. 3.2.3-1 新点是左子节点 将兄节点的颜色设置为父节点的颜色，父节点和右侄节点设置为黑色,然后根据父节点左旋。删除结束。如下图所示： 3.2.3-2 新点是右子节点 将右侄设置为黑色，兄节点设置为红色，然后以兄节点左旋（将情况转为3.2.2-2）。如下图说示： TreeMap删除代码TreeMap.remove代码如下： 12345678910111213public V remove(Object key) &#123; // 根据key查找出节点p Entry&lt;K, V&gt; p = getEntry(key); // 如果p不存在,直接返回null if (p == null) return null; V oldValue = p.value; // 根据节点p删除节点 deleteEntry(p); return oldValue;&#125; remove其实只是根据key找出对应的节点。真正的删除在deleteEntry方法中,代码如下所示: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566/** * 删除节点p,然后平衡红黑树. */private void deleteEntry(Entry&lt;K, V&gt; p) &#123; modCount++; size--; // If strictly internal, copy successor's element to p and then make p // point to successor. // 如果节点p存在左右子节点,则寻找其真正的删除点(其实是中序遍历的后继节点) if (p.left != null &amp;&amp; p.right != null) &#123; // 寻找中序遍历的后继节点 Entry&lt;K, V&gt; s = successor(p); // 将后继节点的元素值赋给节点p p.key = s.key; p.value = s.value; // 将真正删除点赋值为节点p p = s; &#125; // p has 2 children // Start fixup at replacement node, if it exists. // 定义真正删除点的替代节点 Entry&lt;K, V&gt; replacement = (p.left != null ? p.left : p.right); // 如果存在替代节点 if (replacement != null) &#123; // Link replacement to parent // 将替代节点代替真正删除点的位置 replacement.parent = p.parent; if (p.parent == null) root = replacement; else if (p == p.parent.left) p.parent.left = replacement; else p.parent.right = replacement; // Null out links so they are OK to use by fixAfterDeletion. // 删除真正删除节点 p.left = p.right = p.parent = null; // Fix replacement // 如果真正删除点为黑色,需要进行删除后的平衡操作 if (p.color == BLACK) fixAfterDeletion(replacement); &#125; // 如果真正删除点的父节点为空,那其实treeMap中只有一个元素,直接删除 else if (p.parent == null) &#123; // return if we are the only node. root = null; &#125; // 如果真正删除点p没有子节点,这里有2中情况,如果p为红色即为情况1,直接删除。反之需要树的平衡 else &#123; // No children. Use self as phantom replacement and unlink. // 如果p节点为黑色,则需要平衡树操作 if (p.color == BLACK) fixAfterDeletion(p); // 删除节点p if (p.parent != null) &#123; if (p == p.parent.left) p.parent.left = null; else if (p == p.parent.right) p.parent.right = null; p.parent = null; &#125; &#125;&#125; 在删除节点后，可能需要调用fixAfterDeletion方法来平衡红黑树。fixAfterDeletion方法代码如下所示： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108/** * 红黑树节点删除后平衡操作 */private void fixAfterDeletion(Entry&lt;K, V&gt; x) &#123; // 循环平衡红黑树直到根节点或者节点的颜色为红色 while (x != root &amp;&amp; colorOf(x) == BLACK) &#123; // 当节点x为其父节点的左子节点时 if (x == leftOf(parentOf(x))) &#123; // 将x的兄节点定义为sib Entry&lt;K, V&gt; sib = rightOf(parentOf(x)); // 当兄节点为红色时,情况3.1 if (colorOf(sib) == RED) &#123; // 将兄节点设置为黑色 setColor(sib, BLACK); // 将父节点设置为黑色 setColor(parentOf(x), RED); // 以父节点左旋 rotateLeft(parentOf(x)); sib = rightOf(parentOf(x)); &#125; // 如果兄节点的左右子节点都为黑色,情况3.2.1 if (colorOf(leftOf(sib)) == BLACK &amp;&amp; colorOf(rightOf(sib)) == BLACK) &#123; // 将兄节点设置为红色 setColor(sib, RED); // 以x的父节点在递归平衡 x = parentOf(x); &#125; // 如果兄节点左右子节点的颜色不一致 else &#123; // 如果只有右侄节点为黑色,情况3.2.2-1 if (colorOf(rightOf(sib)) == BLACK) &#123; // 将左侄设置为黑色 setColor(leftOf(sib), BLACK); // 将兄节点设置为红色 setColor(sib, RED); // 以兄节点右旋 rotateRight(sib); sib = rightOf(parentOf(x)); &#125; // 情况3.2.3-1 // 将兄节点的颜色设置为父节点的颜色 setColor(sib, colorOf(parentOf(x))); // 将父节点设置为黑色 setColor(parentOf(x), BLACK); // 将右侄节点设置为黑色 setColor(rightOf(sib), BLACK); // 根据父节点左旋 rotateLeft(parentOf(x)); x = root; &#125; &#125; // 当节点x为其父节点的右子节点 else &#123; // symmetric // 定义其兄节点为sib Entry&lt;K, V&gt; sib = leftOf(parentOf(x)); // 当兄节点为红色,情况3.1 if (colorOf(sib) == RED) &#123; // 将兄节点颜色设置为黑色 setColor(sib, BLACK); // 将父节点颜色设置为红色 setColor(parentOf(x), RED); // 以父节点右旋 rotateRight(parentOf(x)); sib = leftOf(parentOf(x)); &#125; // 如果2个侄子节点都是黑色,情况3.2.1 if (colorOf(rightOf(sib)) == BLACK &amp;&amp; colorOf(leftOf(sib)) == BLACK) &#123; // 将兄节点设置为红色 setColor(sib, RED); // 以父节点递归平衡 x = parentOf(x); &#125; // 如果2个侄子节点的颜色不一致 else &#123; // 如果左侄节点颜色为黑色,情况3.2.3-2 if (colorOf(leftOf(sib)) == BLACK) &#123; // 将右侄节点颜色设置为黑色 setColor(rightOf(sib), BLACK); // 将兄节点颜色设置为红色 setColor(sib, RED); // 以兄节点左旋 rotateLeft(sib); sib = leftOf(parentOf(x)); &#125; // 情况3.2.2-2 // 将兄节点颜色设置为父节点颜色 setColor(sib, colorOf(parentOf(x))); // 将父节点颜色设置为黑色 setColor(parentOf(x), BLACK); // 将左侄节点颜色设置为黑色 setColor(leftOf(sib), BLACK); // 以父节点右旋 rotateRight(parentOf(x)); x = root; &#125; &#125; &#125; // 将x节点设置为黑色 setColor(x, BLACK);&#125; 后记这篇笔记写了4天时间。参考了大量大牛的文章，遇到不太懂的时候就拿viso自己画图帮助理解。这次的学习过程收获良多，让我不得不再次感叹数据结构的精妙与算法的魅力。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[chmod777原理]]></title>
      <url>%2F2016%2F08%2F19%2Fwhy-chmod777%2F</url>
      <content type="text"><![CDATA[背景很多Linux新手发现某个文件没有相关权限，一言不合就是chmod 777。首先说一句，chmod 777应该杜绝使用，尤其生产环境。 那chmod 777的背后原理到底是什么呢？ Unix权限设计首先Unix系统的权限分为三种，分别为拥有者(owner)、用户组(group)、其他用户(other)。用ll命令可以查看具体的权限设置，如下图所示： 每个项目前面那一串字母和横杠就是权限。第一位指的是文件类型：-代表普通文件，d代表文件夹。后面9位分为三组，每组代表了对应用户的权限： r=4:读 w=2:写 x=1:执行 回过头来看上图的soft目录，他的权限是drwxr-xr-x就可以解读为： d:这是个目录 rwx:拥有者(onwer)有读、写和执行权限 r-x:用户组（group）有读和执行权限，没有写权限 r-x:其他用户(other)，和用户组的权限一样 读、写、执行的权限值为何是4、2、1?这是因为1、2、4的二进制为： 1:001 2:010 4:100 这么做主要有2个好处：节省空间和提升运算效率。 Unix是上个世纪60年代的产物，当时的硬件资源非常宝贵。所以只用3bit来保存权限。并且二进制的位运算效率特别高，如下例子： 12345678910111213public static final int READ = 4；int auth = 5;//101，拥有读和执行权限/** * 101 (5) * &amp; 100 (4) * = 100 (4) * */ if(auth &amp; READ)&#123; doRead();//有读权限，执行读操作&#125; 这个权限的判断效率不仅简洁而且高效。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Docker学习系列七：构建jetty镜像]]></title>
      <url>%2F2016%2F08%2F12%2Fdocker-7-jetty%2F</url>
      <content type="text"><![CDATA[前言Docker hub官方已经维护了一套比较完善的jetty镜像，但是依赖的是openjdk。所以这里只是把jdk换成之前学习系列中构建过的oracle-jdk8。 Dockerfile描述12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364FROM oraclejdk8 MAINTAINER zacard &lt;mmaxiaolei@gmail.com&gt; # add our user and group first to make sure their IDs get assigned consistently, regardless of whatever dependencies get added RUN addgroup -S jetty &amp;&amp; adduser -D -S -H -G jetty jetty &amp;&amp; rm -rf /etc/group- /etc/passwd- /etc/shadow- ENV JETTY_HOME /usr/local/jetty ENV PATH $JETTY_HOME/bin:$PATH RUN mkdir -p "$JETTY_HOME" WORKDIR $JETTY_HOME ENV JETTY_BASE /var/lib/jetty RUN mkdir -p "$JETTY_BASE" ENV JETTY_VERSION 9.3.10.v20160621 ENV JETTY_TGZ_URL https://repo1.maven.org/maven2/org/eclipse/jetty/jetty-distribution/$JETTY_VERSION/jetty-distribution-$JETTY_VERSION.tar.gz # GPG Keys are personal keys of Jetty committers (see https://dev.eclipse.org/mhonarc/lists/jetty-users/msg05220.html) ENV JETTY_GPG_KEYS \ # 1024D/8FB67BAC 2006-12-10 Joakim Erdfelt &lt;joakime@apache.org&gt; B59B67FD7904984367F931800818D9D68FB67BAC \ # 1024D/D7C58886 2010-03-09 Jesse McConnell (signing key) &lt;jesse.mcconnell@gmail.com&gt; 5DE533CB43DAF8BC3E372283E7AE839CD7C58886 RUN set -xe \ # Install required packages for build time. Will be removed when build finishes. &amp;&amp; apk add --no-cache --virtual .build-deps gnupg coreutils curl \ &amp;&amp; curl -SL "$JETTY_TGZ_URL" -o jetty.tar.gz \ &amp;&amp; curl -SL "$JETTY_TGZ_URL.asc" -o jetty.tar.gz.asc \ &amp;&amp; export GNUPGHOME="$(mktemp -d)" \ &amp;&amp; for key in $JETTY_GPG_KEYS; do \ gpg --keyserver ha.pool.sks-keyservers.net --recv-keys "$key"; done \ &amp;&amp; gpg --batch --verify jetty.tar.gz.asc jetty.tar.gz \ &amp;&amp; rm -r "$GNUPGHOME" \ &amp;&amp; tar -xvzf jetty.tar.gz \ &amp;&amp; mv jetty-distribution-$JETTY_VERSION/* ./ \ &amp;&amp; sed -i '/jetty-logging/d' etc/jetty.conf \ &amp;&amp; rm -fr demo-base javadoc \ &amp;&amp; rm jetty.tar.gz* \ &amp;&amp; rm -fr jetty-distribution-$JETTY_VERSION/ \ # Get the list of modules in the default start.ini and build new base with those modules, then add setuid &amp;&amp; cd $JETTY_BASE \ &amp;&amp; modules="$(grep -- ^--module= "$JETTY_HOME/start.ini" | cut -d= -f2 | paste -d, -s)" \ &amp;&amp; java -jar "$JETTY_HOME/start.jar" --add-to-startd="$modules,setuid" \ # Remove installed packages and various cleanup &amp;&amp; apk del .build-deps \ &amp;&amp; rm -fr .build-deps \ &amp;&amp; rm -rf /tmp/hsperfdata_root WORKDIR $JETTY_BASE ENV TMPDIR /tmp/jetty RUN set -xe \ &amp;&amp; mkdir -p "$TMPDIR" \ &amp;&amp; chown -R jetty:jetty "$TMPDIR" "$JETTY_BASE" COPY docker-entrypoint.sh / EXPOSE 8080 ENTRYPOINT ["/docker-entrypoint.sh"] CMD ["java","-jar","/usr/local/jetty/start.jar"] 说明这里的Dockerfile是根据官方的jetty9-alpine改写。其实也仅仅是把依赖镜像改成了自己构建的oracle-jdk8而已。 这里还依赖了一个sh文件，具体内容如下： docker-entrypoint.sh： 1234567891011121314151617181920212223242526272829303132333435363738394041#!/bin/sh set -e if [ "$1" = jetty.sh ]; then if ! command -v bash &gt;/dev/null 2&gt;&amp;1 ; then cat &gt;&amp;2 &lt;&lt;- 'EOWARN' ******************************************************************** ERROR: bash not found. Use of jetty.sh requires bash. ******************************************************************** EOWARN exit 1 fi cat &gt;&amp;2 &lt;&lt;- 'EOWARN' ******************************************************************** WARNING: Use of jetty.sh from this image is deprecated and may be removed at some point in the future. See the documentation for guidance on extending this image: https://github.com/docker-library/docs/tree/master/jetty ******************************************************************** EOWARN fi if ! command -v -- "$1" &gt;/dev/null 2&gt;&amp;1 ; then set -- java -jar "$JETTY_HOME/start.jar" "$@" fi if [ -n "$TMPDIR" ] ; then case "$JAVA_OPTIONS" in *-Djava.io.tmpdir=*) ;; *) JAVA_OPTIONS="-Djava.io.tmpdir=$TMPDIR $JAVA_OPTIONS" ;; esac fi if [ "$1" = "java" -a -n "$JAVA_OPTIONS" ] ; then shift set -- java $JAVA_OPTIONS "$@" fi exec "$@" 注意：docker-entrypoint.sh要和Dockerfile同一目录，且需要设置可执行权限。 build镜像 docker buile -t jetty:9-oraclejdk8 . 测试镜像 docker run –rm jetty:9-oraclejdk8 –list-config 启动镜像具体如何启动部署镜像，请参考官方说明文档。传送门 保存镜像 docker save -o jetty.tar jetty:9-oraclejdk8 加载镜像 docker -i jetty.tar]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[java是值传递还是引用传递]]></title>
      <url>%2F2016%2F08%2F09%2Fjava-pass-by-value-or-reference%2F</url>
      <content type="text"><![CDATA[java到底是值传递还是引用传递 “Java manipulates objects ‘by reference,’ but it passes object references to methods ‘by value.’” –David Flanagan 大神解释了：java操作对象都是通过引用传递，而给方法传参都是通过值传递 首先，操作对象通过引用传递这个大家应该没有什么争议。但是方法传参都是通过值传递，估计大家还有些疑虑。 代码验证我们知道，如果是值传递，那么实际上传的是一份拷贝。引用传递的话一般传递的是内存地址（看具体的jvm实现）。所以，值传递是无法修改原值的，而引用传递是可以修改原值。 请看以下代码例子: 123456789101112131415161718@Testpublic void testPassedByValueOrReference() &#123; char[] c1 = &#123;'a','b'&#125;; change1(c1); System.out.println("c1 after change1:" + Arrays.toString(c1)); change2(c1); System.out.println("c1 after change2:" + Arrays.toString(c1));&#125;private void change1(char[] c1) &#123; char[] c2 = &#123;'e','f'&#125;; c1 = c2;&#125;private void change2(char[] c1) &#123; char[] c2 = &#123;'e','f'&#125;; c1[0] = c2[0];&#125; 输出： c1 after change1:[a, b] c1 after change2:[e, b] 我们知道，数组是个对象。传递给2个不同的方法，确出现了不一致的行为，既有点像值传递，有好像是引用传递。我们来看看这2个方法在内存中到底做了什么： change1()方法在内存中的执行过程: change2()方法在内存中的执行过程: 所以很清楚了，首先，对于方法的传参确实都是值传递，传递的总是拷贝（对象传递的是引用的拷贝，基础类型为原值的拷贝）。当方法中试图改变这个应用所指向的对象时，其实改变的仅仅是这个引用的拷贝，原引用（引用指向的对象）没有任何变化。而当方法改变的是这个引用拷贝所指向的对象内容（假设对象是可变的）时，原引用由于指向的是同一个对象，所以也会受影响。这其实就是java方法有“副作用”的原因。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[docker学习系列六：构建zookeeper镜像]]></title>
      <url>%2F2016%2F07%2F15%2Fdocker-six-zookeeper%2F</url>
      <content type="text"><![CDATA[什么是zookeeperzookeeper 是一个分布式的，开源的协调服务框架，服务于分布式应用程序。 为什么要zookeeper可以将分布式应用从处理协调服务的泥潭中解救出来。且性能优越，设计简洁优雅。 顺序一致性: 来自客户端的更新操作将会按照顺序被作用 原子性操作: 更新要么全部成功,要么全部失败,没有部分的结果 统一的系统镜像: 无论客户端链接的是哪台服务器,都能获得同样的服务视图,也就是说他是无状态的 可靠性保证: 一旦写入操作被执行(作用到服务器),这个状态将会被持久化,直到其他客户端的修改生效 时间线特性: 客户端访问服务器系统镜像能在一个特定时间访问内保证当前系统是实时更新的 Dockfile123456789101112131415161718192021222324252627282930313233343536373839404142434445464748FROM oraclejdk8 MAINTAINER zacard &lt;mmaxiaolei@gmail.com&gt; # Install required packages RUN apk add --no-cache \ bash \ su-exec ENV ZOO_USER zookeeper ENV ZOO_CONF_DIR /conf ENV ZOO_DATA_DIR /data ENV ZOO_DATA_LOG_DIR /datalog # Add a user and make dirs RUN set -x \ &amp;&amp; adduser -D "$ZOO_USER" \ &amp;&amp; mkdir -p "$ZOO_DATA_LOG_DIR" "$ZOO_DATA_DIR" "$ZOO_CONF_DIR" \ &amp;&amp; chown "$ZOO_USER:$ZOO_USER" "$ZOO_DATA_LOG_DIR" "$ZOO_DATA_DIR" "$ZOO_CONF_DIR" ARG GPG_KEY=C823E3E5B12AF29C67F81976F5CECB3CB5E9BD2D ARG DISTRO_NAME=zookeeper-3.4.9 # Download Apache Zookeeper, verify its PGP signature, untar and clean up RUN set -x \ &amp;&amp; apk add --no-cache --virtual .build-deps \ gnupg \ &amp;&amp; wget -q "http://www.apache.org/dist/zookeeper/$DISTRO_NAME/$DISTRO_NAME.tar.gz" \ &amp;&amp; wget -q "http://www.apache.org/dist/zookeeper/$DISTRO_NAME/$DISTRO_NAME.tar.gz.asc" \ &amp;&amp; export GNUPGHOME="$(mktemp -d)" \ &amp;&amp; gpg --keyserver ha.pool.sks-keyservers.net --recv-key "$GPG_KEY" \ &amp;&amp; gpg --batch --verify "$DISTRO_NAME.tar.gz.asc" "$DISTRO_NAME.tar.gz" \ &amp;&amp; tar -xzf "$DISTRO_NAME.tar.gz" \ &amp;&amp; mv "$DISTRO_NAME/conf/"* "$ZOO_CONF_DIR" \ &amp;&amp; rm -r "$GNUPGHOME" "$DISTRO_NAME.tar.gz" "$DISTRO_NAME.tar.gz.asc" \ &amp;&amp; apk del .build-deps WORKDIR $DISTRO_NAME VOLUME ["$ZOO_DATA_DIR", "$ZOO_DATA_LOG_DIR"] ENV ZOO_PORT 2181 EXPOSE $ZOO_PORT ENV PATH $PATH:/$DISTRO_NAME/bin ENV ZOOCFGDIR $ZOO_CONF_DIR COPY docker-entrypoint.sh / ENTRYPOINT ["/docker-entrypoint.sh"] CMD ["zkServer.sh", "start-foreground"] 注意：这里依赖的镜像oraclejdk8请查看之前的文章“Docker学习系列五：构建oracle-jdk8镜像” 依赖的docker-entrypoint.sh1234567891011121314151617181920212223242526272829303132#!/bin/bash set -e # Allow the container to be started with `--user` if [ "$1" = 'zkServer.sh' -a "$(id -u)" = '0' ]; then exec su-exec "$ZOO_USER" "$0" "$@" fi # Generate the config only if it doesn't exist if [ ! -f "$ZOO_CONF_DIR/zoo.cfg" ]; then CONFIG="$ZOO_CONF_DIR/zoo.cfg" echo "clientPort=$ZOO_PORT" &gt;&gt; "$CONFIG" echo "dataDir=$ZOO_DATA_DIR" &gt;&gt; "$CONFIG" echo "dataLogDir=$ZOO_DATA_LOG_DIR" &gt;&gt; "$CONFIG" echo 'tickTime=2000' &gt;&gt; "$CONFIG" echo 'initLimit=5' &gt;&gt; "$CONFIG" echo 'syncLimit=2' &gt;&gt; "$CONFIG" for server in $ZOO_SERVERS; do echo "$server" &gt;&gt; "$CONFIG" done fi # Write myid only if it doesn't exist if [ ! -f "$ZOO_DATA_DIR/myid" ]; then echo "$&#123;ZOO_MY_ID:-1&#125;" &gt; "$ZOO_DATA_DIR/myid" fi exec "$@" 设置docker-entrypoint.sh权限： chmod 755 docker-entrypoint.sh build镜像docker build -t zookeeper:3.4.9 . 测试镜像启动镜像docker run --name zookeeper --restart always -d zookeeper:3.4.9 This image includes EXPOSE 2181 (the zookeeper port), so standard container linking will make it automatically available to the linked containers. Since the Zookeeper “fails fast” it’s better to always restart it. 这个镜像内部开放了2181端口(zookeeper默认端口)，所有标准的容器链接会使之自动可用。然后因为Zookeeper是fail fast，所以最好总是能自动重启。 从另一个应用容器链接到zookeeper容器docker run --name some-app --link some-zookeeper:zookeeper -d application-that-uses-zookeeper 从zookeeper命令行客户端链接到zookeeper容器docker run -it --rm --link some-zookeeper:zookeeper zookeeper zkCli.sh -server zookeeper 集群模式启动zookeeperdocker-compose.yml: 12345678910111213141516171819202122232425262728version: '2' services: zoo1: image: zookeeper:3.4.9 restart: always ports: - 2181 environment: ZOO_MY_ID: 1 ZOO_SERVERS: server.1=zoo1:2888:3888 server.2=zoo2:2888:3888 server.3=zoo3:2888:3888 zoo2: image: zookeeper:3.4.9 restart: always ports: - 2181 environment: ZOO_MY_ID: 2 ZOO_SERVERS: server.1=zoo1:2888:3888 server.2=zoo2:2888:3888 server.3=zoo3:2888:3888 zoo3: image: zookeeper:3.4.9 restart: always ports: - 2181 environment: ZOO_MY_ID: 3 ZOO_SERVERS: server.1=zoo1:2888:3888 server.2=zoo2:2888:3888 server.3=zoo3:2888:3888 启动集群： docker-compose up 查看集群状态（端口）： docker-compose ps 这里需要注意：这里是伪集群。因为所有容器都启动在同一个物理主机中。实际应该是在不同的主机中启动zookeeper容器。 配置zookeeper的配置在/conf目录下。如果需要修改配置，可以挂载本地配置文件。例如以下所示： docker run --name some-zookeeper --restart always -d -v $(pwd)/zoo.cfg:/conf/zoo.cfg zookeeper]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[创造Lambda风格的mybatis批量操作]]></title>
      <url>%2F2016%2F05%2F31%2Fmybatis-batch-java8%2F</url>
      <content type="text"><![CDATA[mybatis批量操作mybatis如何批量插入呢？常用的做法如下代码所示： 1234567891011121314// UserDao.java/** * 批量插入 */ int batchInsert(@Param("users") List&lt;User&gt; users); // UserDao.xml &lt;insert id="batchInsert"&gt; INSERT INTO user (name,password) VALUES &lt;foreach collection="users" item="user" index="index" separator=","&gt; (#&#123;user.name&#125;,#&#123;user.password&#125;) &lt;/foreach&gt; &lt;/insert&gt; 但是，这样有个影藏的bug：当user集合超过一定数量，会导致动态拼接的sql过长而导致执行报错。并且，批量更新就不能使用这种形式了。 使用mybatis批量提交方式是否有一种通用的写法实现批量操作呢？查看github中mybatis的官方wiki，里面有批量操作的示例（传送门）: 12345678910111213141516171819202122// Mapper.xml&lt;insert id="insertName"&gt; insert into names (name) values (#&#123;value&#125;)&lt;/insert&gt;// java codeList&lt;String&gt; names = new ArrayList&lt;String&gt;();names.add("Fred");names.add("Barney");names.add("Betty");names.add("Wilma");SqlSession sqlSession = sqlSessionFactory.openSession(ExecutorType.BATCH);try &#123; NameMapper mapper = sqlSession.getMapper(NameMapper.class); for (String name : names) &#123; mapper.insertName(name); &#125; sqlSession.commit();&#125; finally &#123; sqlSession.close();&#125; 这种java代码形式的批量操作更加通用且直观。但是需要自己管理sqlsession，这部分自我管理sqlsession的代码不但容易忘记（特别是finally中的sqlsession.close）,而且违反了DRY原则，代码也显得冗长。 使用java8 lambda改造首先对于sqlsession的资源管理可以使用java7的特性，try-with-resources管理。例如以下代码： 123456789101112131415List&lt;String&gt; names = new ArrayList&lt;String&gt;();names.add("Fred");names.add("Barney");names.add("Betty");names.add("Wilma"); try (SqlSession sqlSession = sqlSessionFactory.openSession(ExecutorType.BATCH)) &#123; NameMapper mapper = sqlSession.getMapper(NameMapper.class); for (String name : names) &#123; mapper.insertName(name); &#125; sqlSession.commit(); &#125; catch (Exception e) &#123; logger.error("批量操作失败", e); &#125; 然而，获取sqlsession和sql.commit等部分仍然是重复代码。调用者可能并不关心这些实现细节。 将批量操作独立为一个工具类，并使用java8 lambda改造： 1234567891011121314151617181920212223242526272829/** * MyBatis 批量操作 * * @author zacard * @since 2016-05-31 09:17 */ @Component public class MyBatisBatch &#123; private static final Logger logger = LoggerFactory.getLogger(MyBatisBatch.class); @Autowired private SqlSessionFactory xSqlSessionFactory; public &lt;T&gt; void doBatch(Class&lt;T&gt; daoClass, Consumer&lt;T&gt; consumer)&#123; Objects.requireNonNull(consumer); if (xSqlSessionFactory == null) &#123; logger.error("无法获取mybatis sqlSessionFactory,请检查mybatis配置"); throw XExceptionFactory.create("mybatis配置错误")); &#125; try (SqlSession sqlSession = xSqlSessionFactory.openSession(ExecutorType.BATCH)) &#123; T mapper = sqlSession.getMapper(daoClass); consumer.accept(mapper); sqlSession.commit(); &#125; catch (Exception e) &#123; logger.error("批量操作失败", e); throw XExceptionFactory.create("批量操作失败"); &#125; &#125; 客户端使用示例： 12345678 List&lt;Long&gt; userIds = new ArrayList&lt;&gt;(); userIds.add(1L); userIds.add(2L); userIds.add(3L);myBatisBatch.doBatch(UserDao.class, userDao -&gt; userIds.forEach(userId -&gt; userDao.insert(userId)) );]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[ThreadLocal的作用与原理]]></title>
      <url>%2F2016%2F05%2F23%2Fjava-threadlocal%2F</url>
      <content type="text"><![CDATA[背景spring默认bean的注册形式是单例模式。那spring是如何解决并发安全问题的呢？就是通过ThreadLocal。到底ThreadLocal有和“魔力”能让普通类变成线程安全的类呢？ 原理先来看看ThreadLocal.java的源码注释： This class provides thread-local variables. These variables differ from their normal counterparts in that each thread that accesses one (via its {@code get} or {@code set} method) has its own, independently initialized copy of the variable. {@code ThreadLocal} instances are typically private static fields in classes that wish to associate state with a thread (e.g.,a user ID or Transaction ID). 大致意思： 这个类提供线程局部变量。这种在多线程环境下访问（通过get或set方法）时，能保证各个线程里的变量相对独立于其他线程内的变量。ThreadLocal实例通常是private static类型的，用于管理线程上下文。 也就是说，Threadlocal提供了作用范围为线程的局部变量，这种变量只在线程生命周期内起作用。减少了线程内多个方法之间公共变量传递的复杂度。 这里关于线程安全的类有一个普遍适用的原则：如果一个类没有实例私有属性，或者实例私有属性也是无状态的类，那么这个类就是无状态的类。而一个无状态的类肯定是线程安全的类。 而用ThreadLocal包装类的所有实例私有属性后，这个类就没有实例私有属性了，那么这个类就是一个无状态类，因此也是一个线程安全的类。这也是spring使用ThreeadLocal处理bean的默认方式。 ThreadLocal基本使用先来看看ThreadLocal几个常用方法。 构造函数123456/** * Creates a thread local variable. * @see #withInitial(java.util.function.Supplier) */public ThreadLocal() &#123;&#125; 内部没有任何实现。 initialValue方法123protected T initialValue() &#123; return null;&#125; initialValue()用来设置ThreadLocal的初始值。方法是protected的，建议在子类中被重载，以指定初始值。通常使用匿名内部类的形式。例如以下代码所示： 1234567891011121314151617/** * ThreadLocal测试类 * * @author zacard * @since 2016-05-23 16:36 */ public class ThreadLocalTest &#123; private static final AtomicInteger nextId = new AtomicInteger(0); ThreadLocal&lt;Integer&gt; threadLocal = new ThreadLocal&lt;Integer&gt;() &#123; @Override protected Integer initialValue() &#123; return nextId.getAndIncrement(); &#125; &#125;; &#125; withInitialwithInitial（）也是用来初始化的，但是是lamda风格的初始化方法。构造方法中也是推荐使用此方法。例如以下代码所示： 123456789101112/** * ThreadLocal测试类 * * @author zacard * @since 2016-05-23 16:36 */public class ThreadLocalTest &#123; private static final AtomicInteger nextId = new AtomicInteger(0); ThreadLocal&lt;Integer&gt; threadLocal = ThreadLocal.withInitial(nextId::getAndIncrement);&#125; 使用测试代码12345678910111213141516171819202122232425/** * ThreadLocal测试类 * * @author zacard * @since 2016-05-23 16:36 */public class ThreadLocalTest &#123; private static final AtomicInteger nextId = new AtomicInteger(0); private static final ThreadLocal&lt;Integer&gt; threadLocal = ThreadLocal.withInitial(nextId::getAndIncrement); public static void main(String[] args) &#123; for (int i = 0; i &lt; 3; i++) &#123; new Thread(new Runnable() &#123; @Override public void run() &#123; System.out.println("线程&#123;" + Thread.currentThread().getId() + "&#125;的初始值为:" + threadLocal.get()); threadLocal.set(threadLocal.get() + 100); System.out.println("线程&#123;" + Thread.currentThread().getId() + "&#125;的累加值为:" + threadLocal.get()); &#125; &#125;).start(); &#125; &#125;&#125; 线程{10}的初始值为:0线程{12}的初始值为:2线程{11}的初始值为:1线程{11}的累加值为:101线程{12}的累加值为:102线程{10}的累加值为:100 由此可以看到，各个线程的threadlocal值是独立的。本线程对threadlocal中值的改动并没有影响到其他线程。 ThreadLocal的实现原理先查看ThreadLocal的get()方法源码： 12345678910111213public T get() &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) &#123; ThreadLocalMap.Entry e = map.getEntry(this); if (e != null) &#123; @SuppressWarnings("unchecked") T result = (T)e.value; return result; &#125; &#125; return setInitialValue();&#125; 其中getMap的源码： 123ThreadLocalMap getMap(Thread t) &#123; return t.threadLocals;&#125; setInitialValue的源码： 12345678910private T setInitialValue() &#123; T value = initialValue(); Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value); return value;&#125; createMap的源码： 123void createMap(Thread t, T firstValue) &#123; t.threadLocals = new ThreadLocalMap(this, firstValue);&#125; 查看以上源码后，我们可以了解get方法的流程： 1.首先获取当前线程 2.获取当前线程中的一个类型为ThreadLocalMap（这个类后面会讲到）的成员变量：threadLocals 3.如果threadLocalMap不为null，这通过当前ThreadLocal的引用作为key获取对应的value e。同时如果e不为null，返回e.value 4.如果threadLocalMap为null或者e为null，通过``setInitialValue``方法返回初始值。并且使用当前ThreadLocal的引用和value作为初始key与value创建一个新的threadLocalMap 总体设计思路：Thread维护了一个Map，key为ThreadLocal实例本身，value为真正需要存储的Object。 这样设计的好处：Map的Entry数量变小，性能提升。并且会随Thread一起销毁。 ThreadLocalMap解析先查看源码： 123456789101112131415161718192021222324252627282930/** * ThreadLocalMap is a customized hash map suitable only for * maintaining thread local values. No operations are exported * outside of the ThreadLocal class. The class is package private to * allow declaration of fields in class Thread. To help deal with * very large and long-lived usages, the hash table entries use * WeakReferences for keys. However, since reference queues are not * used, stale entries are guaranteed to be removed only when * the table starts running out of space. */static class ThreadLocalMap &#123; /** * The entries in this hash map extend WeakReference, using * its main ref field as the key (which is always a * ThreadLocal object). Note that null keys (i.e. entry.get() * == null) mean that the key is no longer referenced, so the * entry can be expunged from table. Such entries are referred to * as "stale entries" in the code that follows. */ static class Entry extends WeakReference&lt;ThreadLocal&lt;?&gt;&gt; &#123; /** The value associated with this ThreadLocal. */ Object value; Entry(ThreadLocal&lt;?&gt; k, Object v) &#123; super(k); value = v; &#125; &#125;&#125; ThreadLocalMap是ThreadLocal的一个静态内部类。类上注释也解释了其基本实现方式： ThreadLocalMap是一个自定义的hash map，只适合用来维护现场局部变量。并且是包级私有。hash表中的key是一个ThreadLocal的弱引用。当没有对ThreadLocal的强引用，并且发生GC时，该Entry必然会被回收。 这里的弱引用也保证了不会因为线程迟迟没有结束，而ThreadLocal的强引用不存在了，保存在ThreadLocalMap中的Entry却还依然存在。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Docker学习系列五：构建oracle-jdk8镜像]]></title>
      <url>%2F2016%2F05%2F17%2Fdocker-five-oraclejdk8%2F</url>
      <content type="text"><![CDATA[前言由于docker官方的jdk镜像都是openjdk，与我们实际开发上线的jdk环境不符。因此需要构建一个oracle-jdk8的基础镜像。 参考的是dockerhub中一个oracle-jdk高star的配置：传送门 Dockerfile描述# AlpineLinux with a glibc-2.21 and Oracle Java 8 FROM alpine:3.3 MAINTAINER zacard &lt;mmaxiaolei@gmail.com&gt; # Java Version and other ENV ENV JAVA_VERSION_MAJOR=8 \ JAVA_VERSION_MINOR=92 \ JAVA_VERSION_BUILD=14 \ JAVA_PACKAGE=jdk \ JAVA_HOME=/opt/jdk \ PATH=${PATH}:/opt/jdk/bin \ LANG=C.UTF-8 # do all in one step RUN apk upgrade --update &amp;&amp; \ apk add --update curl ca-certificates bash &amp;&amp; \ for pkg in glibc-2.23-r1 glibc-bin-2.23-r1 glibc-i18n-2.23-r1; do curl -sSL https://github.com/andyshinn/alpine-pkg-glibc/releases/download/2.23-r1/${pkg}.apk -o /tmp/${pkg}.apk; done &amp;&amp; \ apk add --allow-untrusted /tmp/*.apk &amp;&amp; \ rm -v /tmp/*.apk &amp;&amp; \ ( /usr/glibc-compat/bin/localedef --force --inputfile POSIX --charmap UTF-8 C.UTF-8 || true ) &amp;&amp; \ echo &quot;export LANG=C.UTF-8&quot; &gt; /etc/profile.d/locale.sh &amp;&amp; \ /usr/glibc-compat/sbin/ldconfig /lib /usr/glibc-compat/lib &amp;&amp; \ mkdir /opt &amp;&amp; curl -jksSLH &quot;Cookie: oraclelicense=accept-securebackup-cookie&quot; -o /tmp/java.tar.gz \ http://download.oracle.com/otn-pub/java/jdk/${JAVA_VERSION_MAJOR}u${JAVA_VERSION_MINOR}-b${JAVA_VERSION_BUILD}/${JAVA_PACKAGE}-${JAVA_VERSION_MAJOR}u${JAVA_VERSION_MINOR}-linux-x64.tar.gz &amp;&amp; \ gunzip /tmp/java.tar.gz &amp;&amp; \ tar -C /opt -xf /tmp/java.tar &amp;&amp; \ apk del curl glibc-i18n &amp;&amp; \ ln -s /opt/jdk1.${JAVA_VERSION_MAJOR}.0_${JAVA_VERSION_MINOR} /opt/jdk &amp;&amp; \ rm -rf /opt/jdk/*src.zip \ /opt/jdk/lib/missioncontrol \ /opt/jdk/lib/visualvm \ /opt/jdk/lib/*javafx* \ /opt/jdk/jre/plugin \ /opt/jdk/jre/bin/javaws \ /opt/jdk/jre/bin/jjs \ /opt/jdk/jre/bin/keytool \ /opt/jdk/jre/bin/orbd \ /opt/jdk/jre/bin/pack200 \ /opt/jdk/jre/bin/policytool \ /opt/jdk/jre/bin/rmid \ /opt/jdk/jre/bin/rmiregistry \ /opt/jdk/jre/bin/servertool \ /opt/jdk/jre/bin/tnameserv \ /opt/jdk/jre/bin/unpack200 \ /opt/jdk/jre/lib/javaws.jar \ /opt/jdk/jre/lib/deploy* \ /opt/jdk/jre/lib/desktop \ /opt/jdk/jre/lib/*javafx* \ /opt/jdk/jre/lib/*jfx* \ /opt/jdk/jre/lib/amd64/libdecora_sse.so \ /opt/jdk/jre/lib/amd64/libprism_*.so \ /opt/jdk/jre/lib/amd64/libfxplugins.so \ /opt/jdk/jre/lib/amd64/libglass.so \ /opt/jdk/jre/lib/amd64/libgstreamer-lite.so \ /opt/jdk/jre/lib/amd64/libjavafx*.so \ /opt/jdk/jre/lib/amd64/libjfx*.so \ /opt/jdk/jre/lib/ext/jfxrt.jar \ /opt/jdk/jre/lib/ext/nashorn.jar \ /opt/jdk/jre/lib/oblique-fonts \ /opt/jdk/jre/lib/plugin.jar \ /tmp/* /var/cache/apk/* &amp;&amp; \ echo &apos;hosts: files mdns4_minimal [NOTFOUND=return] dns mdns4&apos; &gt;&gt; /etc/nsswitch.conf # EOF 说明为什么要基于alpine:3.3看考官方java镜像中有关java:alpine的说明：传送门 摘录其中一段： This variant is highly recommended when final image size being as small as possible is desired 官方推荐使用基于alpine制作的镜像。 build镜像docker build -t oraclejdk8 . p.s:由于此镜像需要下载一些基础包和jdk，可能需要比较长的build时间，同时可能需要翻墙~ 测试镜像docker run -ti --rm oraclejdk8 java -version 保存镜像docker save -o jdk8.tar oraclejdk8 加载镜像docker load -i jdk8.tar]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Docker学习系列四：Docker Compose]]></title>
      <url>%2F2016%2F05%2F13%2Fdocker-forth-docker-compose%2F</url>
      <content type="text"><![CDATA[什么是Docker ComposeDocker Compose是一个用来定义和运行docker应用服务（一个或者多个dacker容器应用）的工具。使用Compose file来配置管理docker应用服务。 为什么要用Docker Compose先来看下一下例子: docker run --name jetty -p 8881:8080 -p 22 -d jetty; docker run --name jenkins -p 8882:8080 --link -d jetty:jetty jenkins; 这段运行的命令是要先运行一个jetty容器，然后启用一个jenkins容器，同时链接到之前启动的jetty容器。命令显的冗长且极容易敲错或者漏敲。而且不容易记忆，迁移复杂。 如果使用Docker Compose的形式，只需配置一个docker-compose.yml文件即可。如下所示： services: jetty: images:jetty container_name:jetty ports: - &quot;8881:8080&quot; - &quot;22&quot; jenkins： imagesLjenkins container_name:jenkins ports: - &quot;8882:8080&quot; links: jetty 然后运行命令： docker-compose up -d 即可做到和之前的命令一样的效果。 如同Dockerfile之于镜像构建，Compose file使从Docker image运行Docker contain的过程结构化、透明化。并使之保留运行的记录。 Dokcer Compose安装安装使用如下命令： curl -L https://github.com/docker/compose/releases/download/1.7.0/docker-compose-`uname -s`-`uname -m` &gt; /usr/local/bin/docker-compose chmod +x /usr/local/bin/docker-compose 同时推荐安装zsh的命令行补全： mkdir -p ~/.zsh/completion curl -L https://raw.githubusercontent.com/docker/compose/$(docker-compose version --short)/contrib/completion/zsh/_docker-compose &gt; ~/.zsh/completion/_docker-compose 测试是否安装成功： docker-compose --version Compose file语法具体请参考：官方说明 在此只摘录几个常用的。 buildbuild配置项有2种形式。String形式表示镜像build所需的DOckerfile路径；对象形式表示镜像build所需的的dockerfile和参数。例如以下命令： buile: ./dir build: context: ./dir dockerfile: Dockerfile-redis args: buildno: 1 container_name指定一个自定义的容器名称来代替默认生成的名称。 environment增加一个环境变量。有2种形式。数组形式和字典形式。例如以下所示： environment: RACK_ENV: development SHOW: &apos;true&apos; SESSION_SECRET: environment: - RACK_ENV=development - SHOW=true - SESSION_SECRET image指定容器启动的镜像。可以是镜像名称或者是镜像id。例如以下所示： image: redis image: ubuntu:14.04 image: tutum/influxdb image: example-registry.com:4000/mysql image: a4bc65fd 如果镜像不存在，会自动pull下来。 links链接容器和其他服务。可以指定服务名称和服务的别名。例如以下所示： web: links: - db - db:mysql - redis ports开发端口。例如以下所示： ports: - &quot;3000&quot; - &quot;3000-3005&quot; - &quot;8000:8000&quot; - &quot;9090-9091:8080-8081&quot; - &quot;49100:22&quot; - &quot;127.0.0.1:8001:8001&quot; - &quot;127.0.0.1:5000-5010:5000-5010&quot; volumes挂载主机路径到容器内。例如以下所示： volumes: - /var/lib/mysql - /opt/data:/var/lib/mysql 根据Compose file启动服务docker-compose up docker-compose up -d 具体更多命令，请 docker-compose --help docker-compose [command] --help]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Docker学习系列三：Registry]]></title>
      <url>%2F2016%2F05%2F13%2Fdocker-third-registry%2F</url>
      <content type="text"><![CDATA[什么是registryDocker Registry是一个docker仓库，用来存储和分享docker镜像。类似于Github。 为什么需要docker registry这里应该说为什么需要配置一个私有的docker registry。我们知道，已经有dockerhub了，而且官方也提供私有仓库的功能。 因为访问官方的dockerhub，是要良好的网络。而且当我们部署发布的时候，肯定不希望dockeruhb在维护或者故障。而我们配置私有的docker registry可以很好的避免此类问题。 部署私有的docker registrypull官方的registrydocker pull registry:2.4 运行registry命令： docker run -d -p 5000:5000 --restart=always --name registry -v /data/registry:/var/lib/registry registry:2.4 使用Compose file编排(创建docker-compose.yml)： registry: restart: always image: registry:2.4 container_name: registry ports: - 5000:5000 volumes: - /data/registry:/var/lib/registry 然后使用命令： docker-compose up -d 配置授权用户的registry删除启动的registry:docker stop registry&amp;docker rm registry 或者： docker-compose stop registry&amp;docker-compose rm registry 创建授权用户目录并且创建一个授权用户mkdir auth docker run --rm --entrypoint htpasswd registry：2.4 -Bbn testuser testpasswd &gt; auth/htpasswd 以授权用户的方式启动reigstry命令： docker run -d -p 5000:5000 --restart=always --name registry -v /data/registry:/var/lib/registry -v `pwd`/auth:/auth -e &quot;REGISTRY_AUTH=htpasswd&quot; -e &quot;REGISTRY_AUTH_HTPASSWD_REALM=Registry Realm&quot; -e &quot;REGISTRY_AUTH_HTPASSWD_PATH=/auth/htpasswd&quot; registry:2.4 Compose file编排方式： registry: restart: always image: registry:2.4 container_name: registry ports: - 5000:5000 volumes: - /data/registry:/var/lib/registry - /data/auth:/auth environment: REGISTRY_AUTH: htpasswd REGISTRY_AUTH_HTPASSWD_REALM: Registry Realm REGISTRY_AUTH_HTPASSWD_PATH: /auth/htpasswd 然后使用命令： docker-compose up -d 查看log是否启动成功： docker logs registry 登录到私服： docker login localhost:5000 输入用户名、密码等信息。然后上传镜像测试： docker pull busybox docker tab busybox localhost:5000/busybox docker push localhost:5000/busybox 使用证书（CA）认证的域名方式启动私服参考：官方说明 如要使用自签名证书方式启动，参考：官方说明]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Docker学习系列二：Dockerfile]]></title>
      <url>%2F2016%2F05%2F11%2Fdocker-second-dockerfile%2F</url>
      <content type="text"><![CDATA[前言构建或者修改Docker image建议都使用Dockerfile。因为通过Dockerfile构建image或者修改image是透明的、可记录的，且无需重复的镜像和容器的创建过程。甚至可以使用版本控制（如：git）来保存Dockerfile的修改记录，以保留docker image完整的生命周期。 参考：官方Dockerfile说明 Dockerfile基本语法Dockerfile支持的语法命令如下： INSTRUCTION argument 指令不区分大小写。但是，命名约定全部为大写。 所有Dockerfile都必须以FROM命令开始。FROM命令会指定基于哪个基础镜像创建，接下来的命令也会基于这个基础镜像。FROM命令可以多次使用，表示会创建多个镜像。集体突发如下： FROM &lt;IMAGE NAME&gt; 例如： FROM ubuntu 上面的指定告诉我们，新的镜像将基于Ubuntu的镜像来构建。 继FROM命令，Dockerfile还提供了一些其他的命令以实现自动化。这些命令的顺序就是他们的执行顺序。 MAINTAINERMAINTAINER命令用来设置改镜像的作者。语法如下： MAINTAINER &lt;author name&gt; 例如： MAINTAINER zacard RUNRUN有2种形式，shell和exec。shell形式的语法如下： RUN &lt;command&gt; exec形式的语法如下： RUN [&quot;executable&quot;,&quot;param1&quot;,&quot;param2&quot;] ADDADD复制文件的命令。它有2个参数和。source可以是url或者是启动配置上下文中的一个文件。destination是容器内的路径。语法如下： ADD &lt;source&gt; &lt;destination&gt; CMDCMD提供了容器默认的执行命令。Dockerfile只允许使用一次CMD命令。使用多个CMD会抵消之前所有的命令，只有最后一个命令生效。CMD命令有3种形式： // exec形式，推荐的使用形式 CMD [&quot;executable&quot;,&quot;param1&quot;,&quot;param2&quot;] // 默认ENTRYPOINT的param形式 CMD [&quot;param1&quot;,&quot;param2&quot;] // shell形式 CMD command param1 param2 ENTRYPOINTENTRYPOINT命令配置给容器一个可执行的命令，使镜像创建容器时默认运行一个可执行文件。且和CMD类似，Dockerfile也只允许一个ENTRYPOINT命令，多个ENTRYPOINT只会执行最后一个命令。语法如下： // exec形式，推荐的使用形式 ENTRYPOINT [&quot;executable&quot;,&quot;param1&quot;,&quot;param2&quot;] // shell形式 ENTRYPOINT command param1 param2 CMD和ENTRYPOINT如何相互影响2个命令相互间的影响如下表格所示： No ENTRYPOINT ENTRYPOINT exec_entry p1_entry ENTRYPOINT [“exec_entry”,”p1_entry”] No CMD error,not allowrd /bin/sh -c exec_entry p1_entry exec_entry p1_entry CMD [“exec_cmd”,”p1_cmd”] exec_cmd p1_cmd /bin/sh -c exec_entry p1_entry exec_cmd p1_cmd exec_entry p1_entry exec_cmd p1_cmd CMD [“p1_cmd”,”p2_cmd”] p1_cmd p2_cmd /bin/sh -c exec_entry p1_entry p1_cmd p2_cmd exec_entry p1_entry p1_cmd p2_cmd CMD exec_cmd p1_cmd /bin/sh -c exec_cmd p1_cmd /bin/sh -c exec_entry p1_entry /bin/sh -c exec_cmd p1_cmd exec_entry p1_entry /bin/sh -c exec_cmd p1_cmd 另外，docker run命令中的参数会传递给ENTRYPOINT命令，而不用担心被覆盖（CMD与之相反）。所以ENTRYPOINT与CMD结合使用效果会更好。 EXPOSEEXPOSE命令指定容器在运行时监听的端口。语法如下： EXPOSE &lt;port&gt; [&lt;port&gt;...] 例如： // 映射容器私有端口80到共有端口8080 EXPOSE 80:8080 // 开放私有端口80 EXPOSE 80 注意，永远不要使用Dockerfile映射公有端口。不然你将可能只能运行一个容器化应用程序的实例。 WORKDIRWORKDIR命令指定了RUN、CDM和ENTRYPOINT命令的工作目录。语法如下： WORKDIR /path/to/workdir ENVENV命令设置环境变量。使用键值对的方式，增加了运行程序的灵活性。语法如下： // 推荐 ENV &lt;key&gt;=&lt;value&gt; ENV &lt;key&gt; &lt;value&gt; USER给镜像运行时设置一个UID。语法如下： USER &lt;uid&gt; VOLUME授权访问从容器内到宿主主机上的目录。语法如下： VOLUME [&quot;/data&quot;] Dockerfile的一些建议 不要开机初始化 不要在构建中升级版本 使用小型基础镜像，建议FROM alpine:3.3 尽量使用格式一致的Dockerfile，这样能使用缓存 不要在构建中升级版本，如在容器中apt-get upgrade 使用特点的标签。如FROM debian:jeesie,而不是FROM debian 常见的命令组合。如：apt-get update与atp-get install组合。此外使用\格式化成多行命令。这样能够最大程度的应该缓存。 使用自己的基础镜像]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Docker学习系列一：为何要用Docker]]></title>
      <url>%2F2016%2F05%2F11%2Fdocker-one-why%2F</url>
      <content type="text"><![CDATA[前言强烈建议先看下官方的文档：传送门 同时建议看下Flux7的Dock入门教程：传送门 本系列需要了解Docker的一些基本命令为前提。 什么是DockerDocker是一个开源的应用容器引擎。基于Namspaces、Control Groups和UnionFS，保证容器了的轻巧、隔离和易移植。 为何要用Docker build once, configure once and run anywhere 速度飞快 优雅的隔离架构 cpu/内存消耗低 快速启动/关闭/销毁 开源 种种优点契合了目前主流的一些需求： 简化了大规模的集群部署步骤 方便的持续集成和持续部署 微服务架构 一次性的/定时的任务 快速部署 一致的开发测试环境 演示、使用环境 解决设备成本，充分利用资源 技术方案快速验证 更多…]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[JSqlParser使用示例]]></title>
      <url>%2F2016%2F05%2F10%2FJSqlParser-examples%2F</url>
      <content type="text"><![CDATA[背景由于业务需要，需要编写一个mybatis插件来统一处理一类sql，并且需要对sql动态处理。然而解析sql成为一件繁琐的工作，果断github上查找是否有sql解析的项目。一个300多star的sql解析构建项目：JSqlParser。 由于JSqlParser的github主页的使用说明略简单，查看测试类，也没有覆盖常用的使用需求。于是，这里整理了一些个人实际使用的一些方法。 使用示例查询返回增加一列代码如下： /** * 测试查询返回增加一列 */ @Test public void testAddSelectColumn() throws Exception { Select select = (Select) CCJSqlParserUtil.parse(&quot;select name from user where id = 1&quot;); SelectUtils.addExpression(select, new Column(&quot;mail&quot;)); Assert.assertEquals(select.toString(), &quot;SELECT name, mail FROM user WHERE id = 1&quot;); } 查询语句增加where条件代码如下： /** * 测试查询语句增加where条件 */ @Test public void testAddWhereCondition() throws Exception { Select select = (Select) CCJSqlParserUtil.parse(&quot;select name from user&quot;); PlainSelect plainSelect = (PlainSelect) select.getSelectBody(); if (plainSelect.getWhere() == null) { EqualsTo equalsTo = new EqualsTo(); equalsTo.setLeftExpression(new Column(&quot;id&quot;)); equalsTo.setRightExpression(new LongValue(1000L)); plainSelect.setWhere(equalsTo); } Assert.assertEquals(select.toString(), &quot;SELECT name FROM user WHERE id = 1000&quot;); } 增加where查询条件代码如下： /** * 测试增加where查询条件 */ @Test public void testAddCondition() throws Exception { Select select = (Select) CCJSqlParserUtil.parse(&quot;select name from user where id = 1000&quot;); PlainSelect plainSelect = (PlainSelect) select.getSelectBody(); // 原where表达式 Expression where = plainSelect.getWhere(); // 新增的查询条件表达式 EqualsTo equalsTo = new EqualsTo(); equalsTo.setLeftExpression(new Column(&quot;name&quot;)); equalsTo.setRightExpression(new StringValue(&quot;&apos;张三&apos;&quot;)); // 用and链接条件 AndExpression and = new AndExpression(where, equalsTo); // 设置新的where条件 plainSelect.setWhere(and); Assert.assertEquals(select.toString(), &quot;SELECT name FROM user WHERE id = 1000 AND name = &apos;张三&apos;&quot;); } 增加null查询条件代码如下： /** * 测试null条件 */ @Test public void testNullCondition() throws Exception { Select select = (Select) CCJSqlParserUtil.parse(&quot;select name from user where id = 1000&quot;); PlainSelect plainSelect = (PlainSelect) select.getSelectBody(); // 原where表达式 Expression where = plainSelect.getWhere(); // 新增的null判断条件 IsNullExpression isNullExpression = new IsNullExpression(); isNullExpression.setLeftExpression(new Column(&quot;name&quot;)); isNullExpression.setNot(true); // 用and链接条件 AndExpression and = new AndExpression(where, isNullExpression); // 设置新的where条件 plainSelect.setWhere(and); Assert.assertEquals(select.toString(), &quot;SELECT name FROM user WHERE id = 1000 AND name IS NOT NULL&quot;); } 总结JSqlParser的代码结构和使用逻辑总体上算上简单易懂，基本看下项目的包结构以及类注释就能明白大致的用法。其中不乏一些join、group等高阶sql操作。如有sql解析，动态处理方面的需求，JSqlParser还是一个很好的选择。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[testng期望异常和期望异常信息的使用]]></title>
      <url>%2F2016%2F04%2F22%2Ftestng-exceptexception-message%2F</url>
      <content type="text"><![CDATA[背景当我们编写单元测试的时候，经常会使用到expectedExceptions来测试程序的报错是否达到预期。但是，一般的系统设计中，异常都是统一处理成一个自定义的异常，用不同的错误code和错误message来区分不同的错误信息。这就需要用到testng的expectedExceptionsMessageRegExp来匹配抛出的异常message是否是预期的。 使用代码如下： public class MyTest { @Test(expectedExceptions = MyException.class, expectedExceptionsMessageRegExp = &quot;.*error-code-1001.*&quot;) public void testcaseOne() { System.out.println(&quot;test expectedExceptionsMessageRegExp.&quot;); throw new MyException(“error-code-1001”，“系统错误”); } } 这个测试方法会被判定通过。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[idea设置google code style]]></title>
      <url>%2F2016%2F04%2F11%2Fidea-google-code-style%2F</url>
      <content type="text"><![CDATA[背景idea支持自定义的code style，并且google code style也提供了正对idea的xml配置，直接导入就可以在idea中使用google提倡的code style了。 操作 从github上clone google code style 复制对应的xml配置（如intellij-java-google-style.xml）到“~/Library/Preferences/IDEA/codestyles/”下 重启idea在Prefrence-&gt;Editor—&gt;Code Stytle-&gt;Java,选择GoogleStyle即可]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[ideaVim使用记录(持续更新)]]></title>
      <url>%2F2016%2F03%2F23%2FideaVim-use-record%2F</url>
      <content type="text"><![CDATA[背景一直想脱离触摸板（鼠标已经脱离），纯键盘开发。vim肯定是首选，于是idea上的vim插件ideaVim进入熟悉阶段。由于vim的操作也不熟悉，所以在此记录本人开发中用到的一些快捷键操作。 keymap 记录 跳转到指定行：{行数}g 标签特切换：gt或者gT,前者顺序切换，后者逆向切换 单词移动：w/W，移动到下个单词开头；b/B,倒退到上个单词开头。大写的会忽略标点。命令前加数字表示执行次数，如2W 删除当前单词并进入插入模式：cw 撤销：u;恢复被撤销的操作：ctrl+r 复制单词，替换复制内容：yiw-&gt;viwp]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[使用java8将list转为map]]></title>
      <url>%2F2016%2F03%2F17%2Fjava8-list-to-map%2F</url>
      <content type="text"><![CDATA[常用方式代码如下： public Map&lt;Long, String&gt; getIdNameMap(List&lt;Account&gt; accounts) { return accounts.stream().collect(Collectors.toMap(Account::getId, Account::getUsername)); } 收集成实体本身map代码如下： public Map&lt;Long, Account&gt; getIdAccountMap(List&lt;Account&gt; accounts) { return accounts.stream().collect(Collectors.toMap(Account::getId, account -&gt; account)); } account -&gt; account是一个返回本身的lambda表达式，其实还可以使用Function接口中的一个默认方法代替，使整个方法更简洁优雅： public Map&lt;Long, Account&gt; getIdAccountMap(List&lt;Account&gt; accounts) { return accounts.stream().collect(Collectors.toMap(Account::getId, Function.identity())); } 重复key的情况代码如下： public Map&lt;String, Account&gt; getNameAccountMap(List&lt;Account&gt; accounts) { return accounts.stream().collect(Collectors.toMap(Account::getUsername, Function.identity())); } 这个方法可能报错（java.lang.IllegalStateException: Duplicate key），因为name是有可能重复的。toMap有个重载方法，可以传入一个合并的函数来解决key冲突问题： public Map&lt;String, Account&gt; getNameAccountMap(List&lt;Account&gt; accounts) { return accounts.stream().collect(Collectors.toMap(Account::getUsername, Function.identity(), (key1, key2) -&gt; key2)); } 这里只是简单的使用后者覆盖前者来解决key重复问题。 指定具体收集的maptoMap还有另一个重载方法，可以指定一个Map的具体实现，来收集数据： public Map&lt;String, Account&gt; getNameAccountMap(List&lt;Account&gt; accounts) { return accounts.stream().collect(Collectors.toMap(Account::getUsername, Function.identity(), (key1, key2) -&gt; key2, LinkedHashMap::new)); }]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[http压力测试小工具]]></title>
      <url>%2F2016%2F03%2F15%2Fstress-test-tool%2F</url>
      <content type="text"><![CDATA[背景最近在寻找一款小而美的http压力测试工具，以方便本机快速测试。果断github里搜索。不负众望啊，一款4000多star的http压力测试小工具。果断试用。（ps：感谢开源，拥抱开源） 安装工具叫做boom(传送门)。 go get github.com/rakyll/boom 这里要注意，这个工具是用go语言写的，所以你要先有go语言环境，并且是要配置GOPATH。 使用boom -n 100 -c 10 http://www.baidu.com -n：请求连接数-c：请求并发数其他参数参考官方github。 ps：boom命令在${GOPATH}/bin/下]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[关于java的一些冷知识]]></title>
      <url>%2F2016%2F02%2F29%2Fjava-cold-one%2F</url>
      <content type="text"><![CDATA[背景最近开始重新翻阅了《Think in Java》这本书。果然，温故而知新，发现了一些冷知识。 java中的gotogoto是java中的保留字，但是却不是java中的关键字，你并不能在代码中使用goto。但是java能够使用break/continue和标签达到goto的效果。然而，需要注意的是，java里唯一需要用到这种效果的理由就是因为循环嵌套的存在，并且想从循环嵌套中break/continue。 到目前为止，本人阅读过的开源源码中且有记忆的，有使用过类似这种goto效果的，只有Google的Gson。 以返回值区分重载方法在我们学习重载的时候就知道，只能以方法和方法的形参列表作为标准。那为何不能以方法的返回值来区分呢？ 如以下2个方法： void f(){} int void f(){return 1;} 编译器可以通过int x=f()这里的语义来区分需要调用的方法。但是，有时候你并不关心方法的返回值，你想要的是方法调用的其他效果（这通常称为“为了副作用而调用”）。所以，像f()这种调用方法，编译器就无法区分了。 this关键字为何我们能在一个类的方法（非静态方法）中使用this关键字，即当前对象呢？是因为在调用该实例对象的方法的时候，编译器“偷偷”的帮我们把当前实例对象的传进来了。 逗号操作符这里说的不是逗号分隔符，逗号用作分隔符时用来函数的不同参数。java中唯一用到逗号操作符的地方就是for循环的控制表达式。在控制表达式的初始化和步进控制部分，可以使用一系列由逗号分隔的语句，而且那些语句俊辉独立执行。例如一下代码： for(int i = 1, j = i + 10; i&lt;5; i++, j = i * 2){ } else if在java中else if不是关键字。由于java是自由格式语言。else if其实相当于： if(a==1){ }else{ if(a==2){ } } 大家都知道，if和else的大括号是可以省略的。于是就成了else if。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[关于mybatis3.3.1批量插入回写id的实践]]></title>
      <url>%2F2016%2F02%2F18%2Fmybatis3-multiple-rows-write-bace-id%2F</url>
      <content type="text"><![CDATA[背景今日，注意到mybatis3.3.1正式发布，果断查看了更新内容（传送门）。大致浏览了下，其中有一项喜人的改进： Support insert multiple rows and write-back id 批量插入支持id回写了！我们知道，以往如果批量插入，需要获取插入后的ids，是需要根据特定条件反查的。但是，有了这个特性了，完全省去了这一多余查询过程。 实践迫不及待的试了一把。代码如下： pom依赖： 12345678910&lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis&lt;/artifactId&gt; &lt;version&gt;3.3.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring&lt;/artifactId&gt; &lt;version&gt;1.2.4&lt;/version&gt; &lt;/dependency&gt; mapper interface: 1234567891011public interface AccountDAO &#123; /** * 批量插入账户 * * @param accounts 账户集合 * @return 成功插入数量 */ int batchInsert(List&lt;Account&gt; accounts); &#125; mapper xml: 12345678910111213 &lt;?xml version="1.0" encoding="UTF-8" ?&gt; &lt;!DOCTYPE mapper PUBLIC "-//mybatis.org//DTD Mapper 3.0//EN" "http://mybatis.org/dtd/mybatis-3-mapper.dtd" &gt; &lt;mapper namespace="com.xkeshi.shop.dao.AccountDAO"&gt; &lt;insert id="batchInsert" useGeneratedKeys="true" keyProperty="id"&gt; INSERT INTO account (username, password) VALUES &lt;foreach collection="accounts" item="account" index="index" separator="," &gt; (#&#123;account.username&#125;,#&#123;account.password&#125;) &lt;/foreach&gt; &lt;/insert&gt; &lt;/mapper&gt; 测试类： 123456789101112131415161718192021222324@ContextConfiguration(locations = &#123;"classpath*:spring-test.xml" &#125;)@Transactionalpublic class AccountDAOTest extends AbstractTestNGSpringContextTests &#123; @Autowired private AccountDAO accountDAO; public void testBatchInsert() &#123; List&lt;Account&gt; accounts = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; 3; i++) &#123; Account account = new Account(); account.setUsername("测试" + i); account.setPassword("888"); accounts.add(account); &#125; int result = accountDAO.batchInsert(accounts); Assert.assertEquals(3, result); for (Account account : accounts) &#123; Assert.assertNotNull(account.getId()); &#125; &#125; &#125; 然而，测试类结果直接报错： 1org.mybatis.spring.MyBatisSystemException: nested exception is org.apache.ibatis.executor.ExecutorException: Error getting generated key or setting result to parameter object. Cause: org.apache.ibatis.binding.BindingException: Parameter 'id' not found. Available parameters are [accounts, param1] 跟踪这项修改的提交记录（传送门）发现src/main/java/org/apache/ibatis/executor/keygen/Jdbc3KeyGenerator.java的修改记录： 1234567891011121314151617181920212223private Collection&lt;Object&gt; getParameters(Object parameter) &#123; Collection&lt;Object&gt; parameters = null; if (parameter instanceof Collection) &#123; parameters = (Collection) parameter; &#125; else if (parameter instanceof Map) &#123; Map parameterMap = (Map) parameter; // when you insert a List(or Array). // If you want retrieve the auto-increment value or default value. // You should not to use @Param annotations, You must use a single parameter(List or Array). if (parameterMap.containsKey("collection")) &#123; parameters = (Collection) parameterMap.get("collection"); &#125; else if (parameterMap.containsKey("list")) &#123; parameters = (List) parameterMap.get("list"); &#125; else if (parameterMap.containsKey("array")) &#123; parameters = Arrays.asList((Object[]) parameterMap.get("array")); &#125; &#125; if (parameters == null) &#123; parameters = new ArrayList&lt;Object&gt;(); parameters.add(parameter); &#125; return parameters;&#125; 也就是说入参的集合名称必须叫“collection”、“list”、“array”才会生效哦！ 修改代码，mapper interface： 1234567891011public interface AccountDAO &#123; /** * 批量插入账户 * * @param accounts 账户集合 * @return 成功插入数量 */ int batchInsert(List&lt;Account&gt; list); &#125; mapper xml: 12345678910111213 &lt;?xml version="1.0" encoding="UTF-8" ?&gt; &lt;!DOCTYPE mapper PUBLIC "-//mybatis.org//DTD Mapper 3.0//EN" "http://mybatis.org/dtd/mybatis-3-mapper.dtd" &gt; &lt;mapper namespace="com.xkeshi.shop.dao.AccountDAO"&gt; &lt;insert id="batchInsert" useGeneratedKeys="true" keyProperty="id"&gt; INSERT INTO account (username, password) VALUES &lt;foreach collection="list" item="account" index="index" separator="," &gt; (#&#123;account.username&#125;,#&#123;account.password&#125;) &lt;/foreach&gt; &lt;/insert&gt; &lt;/mapper&gt; 重新运行测试类，成功！ 思考mybatis这项修改的原理就是，当集合或者数组的parameter名称为“collection”、“list”、“array”，同时设置了useGeneratedKeys=”true” ，就会把生成的id值回写到对应集合或者数组中的实体中。 但是通过parameter名称区别是否回写总是不太优雅，个人感觉应该新增一个注解，添加在相应的集合或者数组上，标示这是一个批量插入的实体，是需要回写id到这里的。 总而言之，这是一个方便大家的改动，enjoy吧~]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Mac osx推荐2款键盘党软件]]></title>
      <url>%2F2016%2F02%2F03%2Fmac-kill-mouse%2F</url>
      <content type="text"><![CDATA[背景由于平时键盘操作大于触摸板（无鼠标操作），然后前段时间整了个机械键盘，连触摸板都不想用了。于是去网上找了几款键盘党神器级软件，基本能解放触摸板了~ shortcat Shortcat lets you keep your hands on the keyboard and boost your productivity! Shortcat is a keyboard tool for OS X that lets you “click” buttons and control your apps with a few keystrokes. Think of it as Spotlight for the user interface Shortcat 是一款OS X上的键盘工具，能够让你的双手在键盘上操作代替鼠标或者触摸板的操作，提高生产力。可以把他想象成用户界面上的Spotlight 效果如下: karabiner A powerful and stable keyboard customizer for OS X karabiner是OS X上的一个功能强大的键盘映射工具 个人主要用来修改机械键盘中的一些pc专用的按键和一些Right按键 具体修改方法参考：传送门键盘对应的keycode参考：传送门 后感使用这2款工具后，95%的操作是键盘完成的。非常方便实用。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[使用java8编写整洁的逻辑判断]]></title>
      <url>%2F2016%2F02%2F01%2Fjava8-new-one%2F</url>
      <content type="text"><![CDATA[背景 IN-LINE PREDICATES CAN CREATE A MAINTENANCE NIGHTMARE 代码内部的逻辑判断将会成为代码可维护性的恶梦。 使用lambda表达式和steam接口对集合进行常见的操作是非常畅快的。例如如下代码： public List&lt;Person&gt; getAdultMales (List&lt;Person&gt; persons) { return persons.stream().filter(p -&gt; p.getAge() &gt; ADULT &amp;&amp; p.getSex() == SexEnum.MALE ).collect(Collectors.&lt;Person&gt;toList()); } 这很简便！但是这么写却会导致高昂的维护成本。在一个企业级的应用程序中，您的开发团队肯定会有编写重复的业务逻辑判断的代码，这肯定不是你想要看到的项目。因为对于一个易维护，可扩展的企业应用来说，它违反了以下3个重要的原则： DRY(don`t repeat yourself，不要重复代码)：重复一次的代码对于一个“懒惰”的开发者来说就是不好的；同时这也使得您的代码难以维护，因为当业务逻辑改变时，你很难保持业务规则的一致性。 Readability（可读性）：根据整洁代码的最佳实践，您编写的80%的代码应该是调用已经存在的代码。相对于简单的一行调用方法来说，lambda表达式仍然是有点难以阅读。 Testability（易测性）：您的业务代码需要良好的测试。并且非常建议对复杂的逻辑判断做单元测试。而当你把逻辑判断那部分分离出来后，测试将会异常的简单。 从我个人的角度看，这样的方法仍然包含太多的模板代码。 优化幸运的是，在单元测试的世界中，有一个非常好的建议能够改变这一问题。 请看如下代码: import static com.xkeshi.shop.imp.PersonPredicate.*; /** * Predicate测试类 * * @author zacard * @since 2016-02-01 16:11 */ public class PredicateTest { public List&lt;Person&gt; getAdultMales(List&lt;Person&gt; persons) { return persons.stream().filter(isAdultMale()).collect(Collectors.&lt;Person&gt;toList()); } } 我们做了什么： 创建了一个PersonPredicate类 定义了一个lambda形式的断言静态工厂方法 静态导入这个工厂方法 PersonPredicate类的定义如下： /** * @author zacard * @since 2016-02-01 17:41 */ public class PersonPredicate { public static final int ADULT = 18; public static Predicate&lt;Person&gt; isAdultMale() { return p -&gt; p.getAge() &gt; ADULT &amp;&amp; p.getSex() == SexEnum.MALE; } } 等等，我们为什么不直接在Person类中创建一个叫做“isAdultMale”的boolean函数？这确实是一种选择。。。但是随着时间的推移，项目变的庞大，并且加载越来越多的功能和数据是，你仍然会打破代码整洁的原则： 类的功能和条件变得臃肿 类和单元测试变得巨大，难以处理和修改 添加默认方法根据面向对象的思想，我们可以想象，一些操作会经常的在对象上被执行（比如过滤操作）。考虑到这点，我们可以让对象服务实现一个接口来定义一个对象的行为，并提供一些默认的方法（java8中允许接口有默认方法的实现），是很有意义的。 例如以下代码： public interface PersonOperations { default List&lt;Person&gt; filter(List&lt;Person&gt; persons, Predicate&lt;Person&gt; predicate) { return persons.stream().filter(predicate).collect(Collectors.toList()); } } 当我们的person服务实现了这个接口，我们可以让代码更简洁： import java.util.List; import static com.xkeshi.shop.imp.predicate.PersonPredicate.isAdultMale; public class PersonService implements PersonOperations { public List&lt;Person&gt; getAdultMales(List&lt;Person&gt; persons) { return filter(persons, isAdultMale()); } } 结论从长远发展来看，将业务逻辑判断移到一个逻辑判断的辅助类中，将提供以下几个优点： 你的逻辑判断很容易修改和测试 你的对象服务类将保持整洁，让你集中在业务流程而不是业务逻辑判断 提高了代码的重用性，减少了代码的维护成本 进一步分离出了业务的操作关系 以上从这里（传送门）翻译整理。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[dubbo service单元测试参数校验的问题]]></title>
      <url>%2F2016%2F01%2F29%2Fdubbo-bean-validation%2F</url>
      <content type="text"><![CDATA[背景当我们编写dubbo service端的单元测试的时候，并且设置了dubbo的validation是在客户端（服务消费端）校验的话，那么测试类中的基于注解的参数校验将不会生效。 解决办法最简单的办法就是直接编写一个aop类，在方法调用前先做参数校验，代码如下： /** * 参数校验aop切面 * 在dubbo service test类中,使参数校验生效 * * @author zacard * @since 2016-01-29 13:56 */ @Component @Aspect public class ValidatorAspect { private static final Logger logger = LoggerFactory.getLogger(ValidatorAspect.class); /** * 参数校验类 */ private static Validator validator; /** * 内部类连接符 */ public static final String INNERCLASSSTR = &quot;$&quot;; // 定义切入点:dubbo service @Pointcut(value = &quot;execution(public * com.zacard.*.apis.*.*(..))&quot;) private void dubboServicePointcut() { } // 前置aop @Before(value = &quot;dubboServicePointcut()&quot;) public void beforeAdvice(JoinPoint pj) throws Throwable { // 1.校验方法入参 validateMethodParams(pj); // 2.校验入参内的属性 validateParamsProperty(pj); } /** * 校验方法入参 * * @param pj aop切面入参 */ private void validateMethodParams(JoinPoint pj) throws Exception { MethodSignature signature = (MethodSignature) pj.getSignature(); // 代理的方法 Method method = signature.getMethod(); // 是否需要校验方法入参 if (isNeedValidateMethod(method)) { // 代理类 Class aopClass = pj.getTarget().getClass(); // 方法参数列表 Object[] parms = pj.getArgs(); Set&lt;ConstraintViolation&lt;Object&gt;&gt; violations = thegetValidateResultForMethod(aopClass.newInstance(), method, parms); if (!CollectionUtils.isEmpty(violations)) { throw new ValidateException(&quot;TEST_ERROR_001&quot;, &quot;参数校验未通过=&gt;{&quot; + getErrorMsg(violations) + &quot;}&quot;); } } } /** * 校验入参属性 * * @param pj aop切面入参 */ private void validateParamsProperty(JoinPoint pj) { // 方法参数列表 Object[] params = pj.getArgs(); if (params == null || params.length &lt; 1) { return; } // 分组校验注解类 Class methodAnnotation = getMethodGroupAnnotation(pj.getTarget().getClass(), pj.getSignature().getName()); for (Object param : params) { if (param == null) { continue; } Set&lt;ConstraintViolation&lt;Object&gt;&gt; violations = getValidateResultForParam(param, methodAnnotation); if (!CollectionUtils.isEmpty(violations)) { throw new ValidateException(&quot;TEST_ERROR_001&quot;, &quot;参数校验未通过=&gt;{&quot; + getErrorMsg(violations) + &quot;}&quot;); } } } /** * 判断是否需要先验证方法中的入参 * * @param method aop方法类 */ private boolean isNeedValidateMethod(Method method) { for (Annotation[] annotations : method.getParameterAnnotations()) { if (annotations.length &gt; 0) { return true; } } return false; } /** * 获取aop方法对应的分组校验注解类 * * @param aopClass aop类 * @param methodName aop方法名称 * @return 分组校验注解类 */ private Class getMethodGroupAnnotation(Class aopClass, String methodName) { Class[] interfaces = aopClass.getInterfaces(); if (interfaces.length &gt; 0) { String interfaceName = interfaces[0].getName(); if (logger.isInfoEnabled()) { logger.info(&quot;aop method=&gt;{&quot; + aopClass.getName() + &quot;.&quot; + methodName + &quot;()}&quot;); } // 判断是否有对应方法的分组校验注解 try { String annotationName = interfaceName + INNERCLASSSTR + getDubboTypeAnnonName(methodName); return Class.forName(annotationName); } catch (ClassNotFoundException e) { // 不存在这个注解 } } return null; } /** * 获取dubbo验证规则下的分组校验的注解名称 * * @param methodName aop的方法名称 * @return 注解名称 */ private String getDubboTypeAnnonName(String methodName) { return methodName.substring(0, 1).toUpperCase() + methodName.substring(1); } /** * 校验方法中的入参,并返回验证结果 * * @param classInstance 方法所在类的实例 * @param method 方法类 * @param params 方法值数组 * @return 校验结果 */ private Set&lt;ConstraintViolation&lt;Object&gt;&gt; getValidateResultForMethod(Object classInstance, Method method, Object[] params) { return getValidator().forExecutables().validateParameters(classInstance, method, params); } /** * 校验入参 * * @param param 入参 * @param methodAnnotation 分组注解类 * @return 校验结果 */ private Set&lt;ConstraintViolation&lt;Object&gt;&gt; getValidateResultForParam(Object param, Class methodAnnotation) { if (methodAnnotation == null) { return getValidator().validate(param); } return getValidator().validate(param, methodAnnotation); } /** * 从校验结果中格式化出错误信息 * * @param violations 参数校验结果 * @return 错误信息集合, 格式:[a:reason] */ private List&lt;String&gt; getErrorMsg(Set&lt;ConstraintViolation&lt;Object&gt;&gt; violations) { List&lt;String&gt; result = new ArrayList&lt;&gt;(); if (violations == null || violations.isEmpty()) { return result; } return violations.stream() .map(violation -&gt; violation.getPropertyPath() + &quot;:&quot; + violation.getMessage()) .collect(Collectors.toList()); } /** * 获取validator * * @return 参数校验类 */ private Validator getValidator() { if (validator == null) { ValidatorFactory factory = Validation.buildDefaultValidatorFactory(); validator = factory.getValidator(); } return validator; } xml需要开启aop注解支持： &lt;!--开启aop注解支持--&gt; &lt;aop:aspectj-autoproxy /&gt; 同时需要扫描ValidatorAspect类所在的包，例如： &lt;context:component-scan base-package=&quot;com.zacard.core.test&quot; /&gt; 依赖的jar包,pom.xml配置： &lt;!--AspectJ--&gt; &lt;dependency&gt; &lt;groupId&gt;org.aspectj&lt;/groupId&gt; &lt;artifactId&gt;aspectjrt&lt;/artifactId&gt; &lt;version&gt;1.6.10&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.aspectj&lt;/groupId&gt; &lt;artifactId&gt;aspectjweaver&lt;/artifactId&gt; &lt;version&gt;1.6.10&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;aopalliance&lt;/groupId&gt; &lt;artifactId&gt;aopalliance&lt;/artifactId&gt; &lt;version&gt;1.0&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; 需要注意的一个地方如果在单元测试类中，同时使用了Mock一类的包(例如：mockito)，可能会使Mock失效。 失效原因由于测试类是被aop代理的类,使用mock注入的一些bean或者属性会注入到代理类中,所以会失败. 解决办法编写一个工具类，将mock对象注入到真实的类中，代码如下： /** * Mock注入工具类 * * @author zacard * @since 2016-01-29 14:26 */ public class MockWithAopUtils { private static final Logger logger = LoggerFactory.getLogger(MockWithAopUtils.class); /** * 注入mock对象到被aop代理的原bean中 * * @param target 真实的bean * @param propertyName 被mock属性名称 * @param mock mock对象 */ public static void setMocks(Object target, String propertyName, Object mock) { // 1.获取被aop代理的原始bean Object realBean = target; try { realBean = unwrapProxy(target); } catch (Exception e) { logger.error(&quot;获取被aop代理的原始bean失败!&quot;, e); } // 2.注入mock对象 ReflectionTestUtils.setField(realBean, propertyName, mock); } /** * 获取真实的被代理类 * * @param bean 代理类 * @return 真实bean * @throws Exception */ private static Object unwrapProxy(Object bean) throws Exception { if (AopUtils.isAopProxy(bean) &amp;&amp; bean instanceof Advised) { Advised advised = (Advised) bean; bean = advised.getTargetSource().getTarget(); } return bean; } }]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Ubuntu中添加zsh(oh-my-zsh)的环境变量]]></title>
      <url>%2F2016%2F01%2F23%2Flinux-zsh-env%2F</url>
      <content type="text"><![CDATA[背景听说有个shell叫zsh和oh-my-zsh完爆Ubuntu默认的bash，果断安装试用。 命令： apt-get install -y zsh wget https://github.com/robbyrussell/oh-my-zsh/raw/master/tools/install.sh -O - | sh 安装完成后体验了下被网友力推的几个功能和插件（详情可以见：传送门），确实方便好用。 但是碰到个问题：无法读取到配置在~/.bashrc中的环境变量，这也是摆明的问题，你shell都换了，zsh这么可能读到bash的配置文件中的环境变量。 解决方法只需要复制~/.basrc中的环境变量的配置到~/.zshrc中，然后 source ~/.zshrc 即可生效。 大家快去体验zsh(oh-my-zsh)带来的便利吧~]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[IntelliJ IDEA内存优化]]></title>
      <url>%2F2016%2F01%2F21%2Fidea-vmoptions-setting%2F</url>
      <content type="text"><![CDATA[背景经常有人抱怨说idea反应慢，吃内存。于是google到了一篇老外对idea内存配置优化方案的比较和测试，传送门 引用 Don’t be a Scrooge and give your IDE some more memory 不要做守财奴，给IDE多分配点内存吧。 哈哈！老外已经说了，idea慢的原因，基本是内存给的不够。 结论这里直接拿老外的测试结论来提供一份idea.vmoptions的配置： -Xms2g -Xmx2g -XX:ReservedCodeCacheSize=1024m -XX:+UseCompressedOops 就是这样了。。。 至于idea.vmoptions怎么用，请看传送门 have fun~]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[关于使用maven jetty插件启动慢的解决方法]]></title>
      <url>%2F2016%2F01%2F19%2Fmaven-jetty-slow%2F</url>
      <content type="text"><![CDATA[背景使用maven的jetty插件启动web（spring）项目时，可能会遇到项目启动很慢，甚至可能直接timeout或者报一些其他错误。我们可以根据错误来优化maven中jetty的启动速度。 常见错误一当遇到类似如下错误： java.lang.ArrayIndexOutOfBoundsException: 51889 或者： java.lang.Exception: Timeout scanning annotations 解决办法在web.xml中的web-app标签设置属性metadata-complete=”true” &lt;web-app xmlns=&quot;http://java.sun.com/xml/ns/javaee&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://java.sun.com/xml/ns/javaee http://java.sun.com/xml/ns/javaee/web-app_3_0.xsd&quot; version=&quot;3.0&quot; metadata-complete=&quot;true&quot;&gt; 产生原因官方原因解释如下： One important thing to be aware of is that the 2.5 Servlet Specification has introduced a new attribute into the element, the metadata-complete attribute. If true, then the web container will NOT search the webapp for source code annotations, and your web.xml file must contain all resources required. If false or not specified, then jetty is required to examine all servlets, filters and listeners in the webapp for annotations. Therefore, you can save startup time by using this attribute correctly - if you don’t want to use annotations then ensure you mark metadata-complete=”true”, otherwise you will pay the penalty of the code examination. 也就是说如果不设置metadata-complete=”true”，那么jetty会检查程序中所有的annotations，而程序中spring和其他的annotations是不需要jetty来检查的。 常见错误二出现如下提示信息： [INFO] No Transaction manager found - if your webapp requires one, please configure one. 解决办法首先修改pom.xml中jetty插件的配置： &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.eclipse.jetty&lt;/groupId&gt; &lt;artifactId&gt;jetty-maven-plugin&lt;/artifactId&gt; &lt;version&gt;9.3.0.M1&lt;/version&gt; &lt;configuration&gt; &lt;httpConnector&gt; &lt;port&gt;8888&lt;/port&gt; &lt;/httpConnector&gt; &lt;!-- 本地装载contextXml，来解决未配置事务或数据库造成启动时等待时间过长 --&gt; &lt;contextXml&gt;src/main/resources/jetty-deploy.xml&lt;/contextXml&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; 关键是新增了contextXml项的配置，jetty-deploy.xml具体内容如下： &lt;?xml version=&quot;1.0&quot;?&gt; &lt;!DOCTYPE Configure PUBLIC &quot;-//Jetty//Configure//EN&quot; &quot;http://www.eclipse.org/jetty/configure.dtd&quot;&gt; &lt;!-- =============================================================== --&gt; &lt;!-- Add a ContextProvider to the deployment manager --&gt; &lt;!-- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - --&gt; &lt;!-- This scans the webapps directory for war files and directories --&gt; &lt;!-- to deploy. --&gt; &lt;!-- This configuration must be used with jetty-deploy.xml, which --&gt; &lt;!-- creates the deployment manager instance --&gt; &lt;!-- =============================================================== --&gt; &lt;Configure id=&quot;Server&quot; class=&quot;org.eclipse.jetty.webapp.WebAppContext&quot;&gt; &lt;Call name=&quot;setAttribute&quot;&gt; &lt;Arg&gt;org.eclipse.jetty.server.webapp.WebInfIncludeJarPattern&lt;/Arg&gt; &lt;Arg&gt;.*/mwa-web-.*\.jar$&lt;/Arg&gt; &lt;!--&lt;Arg&gt;.*/.*jsp-api-[^/]\.jar$|./.*jsp-[^/]\.jar$|./.*taglibs[^/]*\.jar$&lt;/Arg&gt;--&gt; &lt;/Call&gt; &lt;/Configure&gt; 产生原因项目中未配置事务或数据库造成启动时等待时间过长。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[java锁的种类及研究]]></title>
      <url>%2F2016%2F01%2F13%2Fjava-lock-research%2F</url>
      <content type="text"><![CDATA[背景锁作为并发共享数据，保证一致性的工具，在JAVA平台有多种实现(如 synchronized 和 ReentrantLock等等 ) 。这些已经写好提供的锁为我们开发提供了便利，但是锁的具体性质以及类型却很少被提及。 自旋锁自旋锁是采用让当前线程不停地的在循环体内执行实现的，当循环的条件被当前线程改变时其他前程才能进入临界区。 自旋锁流程：获取自旋锁时，如果没有任何线程保持该锁，那么将立即得到锁；如果在获取自旋锁时锁已经有保持者，那么获取锁操作将自旋在那里，直到该自旋锁的保持者释放了锁。 简单实现原理的代码如下： /** * 自旋锁原理简单示例 * * @author zacard * @since 2016-01-13 21:40 */ public class SpinLock { private AtomicReference&lt;Thread&gt; sign = new AtomicReference&lt;&gt;(); // 获取锁 public void lock() { Thread current = Thread.currentThread(); while (!sign.compareAndSet(null, current)) { } } // 释放锁 public void unlock() { Thread current = Thread.currentThread(); sign.compareAndSet(current, null); } } 要理解以上代码，我们要先弄清楚AtomicReference的作用。 AtomicReference：位于java.util.concurrent.atomic包下。从包名就可知道它的大致作用：在并发环境中保证引用对象的原子操作。 查看AtomicReference源码： package java.util.concurrent.atomic; import java.util.function.UnaryOperator; import java.util.function.BinaryOperator; import sun.misc.Unsafe; /** * An object reference that may be updated atomically. See the {@link * java.util.concurrent.atomic} package specification for description * of the properties of atomic variables. * @since 1.5 * @author Doug Lea * @param &lt;V&gt; The type of object referred to by this reference */ public class AtomicReference&lt;V&gt; implements java.io.Serializable { private static final long serialVersionUID = -1848883965231344442L; private static final Unsafe unsafe = Unsafe.getUnsafe(); private static final long valueOffset; static { try { valueOffset = unsafe.objectFieldOffset (AtomicReference.class.getDeclaredField(&quot;value&quot;)); } catch (Exception ex) { throw new Error(ex); } } private volatile V value; ...(省略) /** * Atomically sets the value to the given updated value * if the current value {@code ==} the expected value. * @param expect the expected value * @param update the new value * @return {@code true} if successful. False return indicates that * the actual value was not equal to the expected value. */ public final boolean compareAndSet(V expect, V update) { return unsafe.compareAndSwapObject(this, valueOffset, expect, update); } ...(省略) 发现AtomicReference实现的基本原理是使用volatile关键字和Unsafe类来保证其可见性和原子性。（PS:在此暂不作扩展阅读Unsafe类） 我们重点关注AtomicReference.compareAndSet()这个自旋锁用到的方法。从方法注释和方式实现，可以理解：这个方法的意思就是当当前的值==（注意是双等号）期望的值（即传入的第一个参数）时，把当前值更新为新值（即传入的第二个参数），并且返回true，否则返回false。 再回过头，看之前自旋锁的代码，就很好理解了。一开始AtomicReference中的值为null，当有线程获得锁后，将值更新为该线程。当其他线程进入被锁的方法时，由于sign.compareAndSet(null, current)始终返回的是false，导致while循环体一直在运行，知道获得锁的线程调用unlock方法，将当前持有线程重新设置为null：sign.compareAndSet(current, null)其他线程才可获得锁。 阻塞锁阻塞锁，与自旋锁不同，改变了线程的运行状态。阻塞锁，可以说是让线程进入阻塞状态进行等待，当获得相应的信号（唤醒，时间） 时，才可以进入线程的准备就绪状态，准备就绪状态的所有线程，通过竞争，进入运行状态。 阻塞锁和自旋锁最大的区别就在于，当获取锁是，如果锁有持有者，当前线程是进入阻塞状态，等待当前线程结束而被唤醒的。 简单实现原理的代码如下： /** * 阻塞锁原理简单示例 * * @author zacard * @since 2016-01-13 22:02 */ public class BlockLock { private AtomicReference&lt;Thread&gt; sign = new AtomicReference&lt;&gt;(); // 获取锁 public void lock() { Thread current = Thread.currentThread(); if (!sign.compareAndSet(null, current)) { LockSupport.park(); } } // 释放锁 public void unlock() { Thread current = Thread.currentThread(); sign.compareAndSet(null, current); LockSupport.unpark(current); } } 要理解以上代码，我们要先弄清楚LockSupport的作用。 LockSupport：位于java.util.concurrent.locks包下（又是j.u.c）。同样，从包名和类名即可知道其作用：提供并发编程中的锁支持。 还是先查看下LockSupport的源码: public class LockSupport { private LockSupport() {} // Cannot be instantiated. private static void setBlocker(Thread t, Object arg) { // Even though volatile, hotspot doesn&apos;t need a write barrier here. UNSAFE.putObject(t, parkBlockerOffset, arg); } ...(省略) 又是sun.misc.Unsafe这个类，在此我们不得不先扩展研究下这个Unsafe类的作用和原理了。 sun.misc.Unsafe：有个称号叫做魔术类。因为他能直接操作内存等一些复杂操作。包括直接修改内存值，绕过构造器，直接调用类方法等。当然，他主要提供了CAS（compareAndSwap）原子操作而被我们熟知。 查看Unsafe类源码: public final class Unsafe { private static final Unsafe theUnsafe; ...(省略) private Unsafe() { } @CallerSensitive public static Unsafe getUnsafe() { Class var0 = Reflection.getCallerClass(); if(!VM.isSystemDomainLoader(var0.getClassLoader())) { throw new SecurityException(&quot;Unsafe&quot;); } else { return theUnsafe; } } ...(省略) 根据代码可知：Unsafe是final类，意味着我们不能通过继承来使用或改变这个类的方法。然后构造器是私有的，也不能实例化。但是他自己保存了一个静态私有不可改变的实例“theUnsafe”，并且只提供了一个静态方法getUnsafe()来获取这个类的实例。 但是这个getUnsafe方法确有个限制：注意if语句里的判断，他表示如果不是受信任的类调用，会直接抛出异常。显然，我们平常编写的类都是不受信任的！ 但是，我们有反射！既然他已经持有了一个实例，就能通过反射强行窃取这个私有的实例。 代码如下: public void getUnsafe() { try { Field field = Unsafe.class.getDeclaredField(&quot;theUnsafe&quot;); field.setAccessible(true); Unsafe unsafe = (Unsafe) field.get(null); } catch (NoSuchFieldException | IllegalAccessException e) { e.printStackTrace(); } } Unsafe类的方法基本都是native关键字修饰的，也就是说这些方法都是原生态方法，方法对应的实现不是在当前文件，而是在用其他语言（如C和C++）实现的文件中。这也就是为什么Unsafe能够直接操作内存等一些特权功能的原因。 回过头看下LockSupport中park()和uppark()这2个方法的作用。 LockSupport.unpark(): /** * Makes available the permit for the given thread, if it * was not already available. If the thread was blocked on * {@code park} then it will unblock. Otherwise, its next call * to {@code park} is guaranteed not to block. This operation * is not guaranteed to have any effect at all if the given * thread has not been started. * * @param thread the thread to unpark, or {@code null}, in which case * this operation has no effect */ public static void unpark(Thread thread) { if (thread != null) UNSAFE.unpark(thread); } 根据方法注释：对于给定线程，将许可证设置为可用状态。如果这个线程是因为调用park()而处于阻塞状态，则清除阻塞状态。反之，这个线程在下次调用park()时，将保证不被阻塞。 LockSupport.park()： /** * Disables the current thread for thread scheduling purposes unless the * permit is available. * * &lt;p&gt;If the permit is available then it is consumed and the call returns * immediately; otherwise * the current thread becomes disabled for thread scheduling * purposes and lies dormant until one of three things happens: * * &lt;ul&gt; * &lt;li&gt;Some other thread invokes {@link #unpark unpark} with the * current thread as the target; or * * &lt;li&gt;Some other thread {@linkplain Thread#interrupt interrupts} * the current thread; or * * &lt;li&gt;The call spuriously (that is, for no reason) returns. * &lt;/ul&gt; * * &lt;p&gt;This method does &lt;em&gt;not&lt;/em&gt; report which of these caused the * method to return. Callers should re-check the conditions which caused * the thread to park in the first place. Callers may also determine, * for example, the interrupt status of the thread upon return. * * @param blocker the synchronization object responsible for this * thread parking * @since 1.6 */ public static void park(Object blocker) { Thread t = Thread.currentThread(); setBlocker(t, blocker); UNSAFE.park(false, 0L); setBlocker(t, null); } 根据注释：除非许可证是可用的，不然将当前线程的调度设置为不可用。当许可是可用时，方法会立即返回，不会阻塞，反之就会阻塞当前线程直到下面3件事发生: 其他线程调用了unpark(此线程) 其他线程interrupts（终止）了此线程 调用时发生未知原因的返回 重入锁重入锁，也叫做递归锁，指的是同一线程外层函数获得锁之后 ，内层递归函数仍然有获取该锁的代码，但不受影响。在JAVA环境下ReentrantLock和synchronized都是重入锁。 测试代码如下: /** * 测试ReentrantLock和synchronized */ @Test public void testReentrantLock() { // ReentrantLock test for (int i = 0; i &lt; 3; i++) { new Thread(new Runnable() { ReentrantLock lock = new ReentrantLock(); public void get() { lock.lock(); System.out.println(&quot;ReentrantLock:&quot; + Thread.currentThread().getId()); set(); lock.unlock(); } public void set() { lock.lock(); System.out.println(&quot;ReentrantLock:&quot; + Thread.currentThread().getId()); lock.unlock(); } @Override public void run() { get(); } }).start(); } // synchronized test for (int i = 0; i &lt; 3; i++) { new Thread(new Runnable() { public synchronized void get() { System.out.println(&quot;synchronized:&quot; + Thread.currentThread().getId()); set(); } public synchronized void set() { System.out.println(&quot;synchronized:&quot; + Thread.currentThread().getId()); } @Override public void run() { get(); } }).start(); } } 2段代码的输出一致：都会重复输出当前线程id2次。 可重入锁最大的作用是避免死锁。以自旋锁作为例子： /** * 自旋锁原理简单示例 * * @author zacard * @since 2016-01-13 21:40 */ public class SpinLock { private AtomicReference&lt;Thread&gt; sign = new AtomicReference&lt;&gt;(); // 获取锁 public void lock() { Thread current = Thread.currentThread(); while (!sign.compareAndSet(null, current)) { } } // 释放锁 public void unlock() { Thread current = Thread.currentThread(); sign.compareAndSet(current, null); } } 若有同一线程两调用lock()，会导致第二次调用lock位置进行自旋，产生了死锁说明这个锁并不是可重入的。（在lock函数内，应验证线程是否为已经获得锁的线程） 若1问题已经解决，当unlock（）第一次调用时，就已经将锁释放了。实际上不应释放锁 自旋锁避免死锁的方法（采用计数次统计）： /** * 自旋锁改进 * * @author Guoqw * @since 2016-01-14 14:11 */ public class SpinLockImprove { private AtomicReference&lt;Thread&gt; owner = new AtomicReference&lt;&gt;(); private int count = 0; /** * 获取锁 */ public void lock() { Thread current = Thread.currentThread(); if (current == owner.get()) { count++; return; } while (!owner.compareAndSet(null, current)) { } } /** * 释放锁 */ public void unlock() { Thread current = Thread.currentThread(); if (current == owner.get()) { if (count != 0) { count--; } else { owner.compareAndSet(current, null); } } } } 改进后自旋锁即为重入锁的简单实现。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[单元测试中涉及到mybatis plugin时需要注意的地方]]></title>
      <url>%2F2016%2F01%2F11%2Ftestcase-with-mybatis-plugin%2F</url>
      <content type="text"><![CDATA[背景当编写test case的时候，如果测试内容中又涉及到mybatis plugin（interceptor）的时候，可能会出现奇怪的问题。比如一部分mybatis的dao调用进入了plugin,一小部分却不经过plugin。 例子请看如下单元测试代码： /** * 测试分页查询 */ @Test public void testQueryPage() { // 分页对象 Pager&lt;Account&gt; pager = new Pager&lt;&gt;(); pager.setCurrentPage(2); pager.setPageSize(10); // 查询参数 QueryParams queryParams = new QueryParams(); queryParams.setRole(&quot;ADMIN&quot;); // 调用查询接口 List&lt;Account&gt; accounts1 = accountDAO.queryPage(queryParams, pager); Assert.assertTrue(accounts1.size() == 1); // 调用查询接口 pager.setCurrentPage(1); List&lt;Account&gt; accounts2 = accountDAO.queryPage(queryParams, pager); Assert.assertTrue(accounts2.size() == 10); } mybatis plugin代码： /** * &lt;p&gt; * 数据库分页和排序插件，只拦截查询语句. * &lt;/p&gt; * */ @Intercepts({@Signature(type = StatementHandler.class, method = &quot;prepare&quot;, args = {Connection.class})}) public class QueryInterceptor implements Interceptor{ ... } 这时候，跑测试类，第二次调用dao接口的时候，没有进入mybatis的plugin，断言也是不通过的。这是由于mybatis的一级缓存的机制。 原因当几个查询出于同一个sqlsession查询的时候，并且mybatis认为是完全相同的查询，mybatis是使用一级缓存的结果，而不会走拦截StatementHandler接口的插件方法。（mybatis认为的完全相同的查询，不是指使用sqlsession查询时传递给算起来session的所有参数值完完全全相同，你只要保证statementId，rowBounds,最后生成的SQL语句，以及这个SQL语句所需要的参数完全一致就可以了。） 总结这个问题教育我们，test case的方法要尽量独立，测试用例尽量测试一个业务或者逻辑。 Ps:mybatis一级缓存机制参考这里;mybatis拦截器参考这里]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[java list循环中删除元素的坑]]></title>
      <url>%2F2016%2F01%2F07%2Flist-remove%2F</url>
      <content type="text"><![CDATA[背景当我们要循环一个list中的元素，并且要删除某个元素的时候，一点要小心谨慎！其中深埋了好几个坑！ 坑1请看如下代码： /** * 测试删除集合中的空白元素 */ @Test public void removeBlank() { List&lt;String&gt; list = new ArrayList&lt;&gt;(); list.add(&quot;1&quot;); list.add(&quot;2&quot;); list.add(&quot;3&quot;); list.add(&quot; &quot;); list.add(&quot; &quot;); for (String s : list) { if (StringUtils.isBlank(s)) { list.remove(s); } } System.out.println(&quot;list:&quot; + list); } 输出结果：list:[1, 2, 3, ] 。可以看到空白元素没有删除干净。 坑1解决办法请看如下代码： /** * 测试删除集合中的空白元素 */ @Test public void removeBlank() { List&lt;String&gt; list = new ArrayList&lt;&gt;(); list.add(&quot;1&quot;); list.add(&quot;2&quot;); list.add(&quot;3&quot;); list.add(&quot; &quot;); list.add(&quot; &quot;); Iterator&lt;String&gt; iterator = list.iterator(); while (iterator.hasNext()) { String s = iterator.next(); if (StringUtils.isBlank(s)) { iterator.remove(); } } System.out.println(&quot;list:&quot; + list); } 结果输出：list:[1, 2, 3]。解决办法其实就是用Iterator迭代器代替for循环。但是这个解决方法里还是隐藏了一个坑。 坑2请看如下代码： /** * 测试删除集合中的空白元素 */ @Test public void removeBlank() { List&lt;String&gt; list = Arrays.asList(&quot;1&quot;,&quot;2&quot;,&quot;3&quot;,&quot;&quot;,&quot; &quot;); Iterator&lt;String&gt; iterator = list.iterator(); while (iterator.hasNext()) { String s = iterator.next(); if (StringUtils.isBlank(s)) { iterator.remove(); } } System.out.println(&quot;list:&quot; + list); } 结果会直接报错：java.lang.UnsupportedOperationException。意思是不支持remove操作。只是把list的定义换成了Arrays.asList，却有完全不一样的运行结果，非常神奇。查看Arrays.asList的源码： /** * Returns a fixed-size list backed by the specified array. (Changes to * the returned list &quot;write through&quot; to the array.) This method acts * as bridge between array-based and collection-based APIs, in * combination with {@link Collection#toArray}. The returned list is * serializable and implements {@link RandomAccess}. * * &lt;p&gt;This method also provides a convenient way to create a fixed-size * list initialized to contain several elements: * &lt;pre&gt; * List&amp;lt;String&amp;gt; stooges = Arrays.asList(&quot;Larry&quot;, &quot;Moe&quot;, &quot;Curly&quot;); * &lt;/pre&gt; * * @param &lt;T&gt; the class of the objects in the array * @param a the array by which the list will be backed * @return a list view of the specified array */ @SafeVarargs @SuppressWarnings(&quot;varargs&quot;) public static &lt;T&gt; List&lt;T&gt; asList(T... a) { return new ArrayList&lt;&gt;(a); } 单从代码看：return new ArrayList&lt;&gt;(a);应该是一个普通的ArrayList啊？！查看注释：返回一个固定大小的list！也就是说add和remove操作肯定会报错。同时也说明了这里的ArrayList不是我们平时使用的ArrayList。继续跟踪这个ArrayList： /** * @serial include */ private static class ArrayList&lt;E&gt; extends AbstractList&lt;E&gt; implements RandomAccess, java.io.Serializable { private static final long serialVersionUID = -2764017481108945198L; private final E[] a; ArrayList(E[] array) { a = Objects.requireNonNull(array); } ... } 原来此处的ArrayList是Arrays的一个实现了AbstractList的内部类，并且没有覆盖add和remove方法，默认这2个方法是会直接报“UnsupportedOperationException”的。 坑2解决办法既然明白了报错原因，解决办法也很明显了： /** * 测试删除集合中的空白元素 */ @Test public void removeBlank() { List&lt;String&gt; list = Arrays.asList(&quot;1&quot;,&quot;2&quot;,&quot;3&quot;,&quot;&quot;,&quot; &quot;); List&lt;String&gt; result= new ArrayList&lt;&gt;(list); Iterator&lt;String&gt; iterator = result.iterator(); while (iterator.hasNext()) { String s = iterator.next(); if (StringUtils.isBlank(s)) { iterator.remove(); } } System.out.println(&quot;list:&quot; + result); } 反思通过踩这几个坑，再次验证了一个真理：在设计一个对外方法的时候，一点要谨慎处理集合和数组。因为你永远不知道客户端传给你的集合是什么，也不知道客户端是否会有对此集合有任何其他的不可控的操作。所以在使用客户端传递的集合对象时，最好拷贝一个新集合后再操作。 更新-2016.01.17之前的解决方法中违反了java其中的一个编码准则：变量的作用范围越小约好。 请看如下代码： @Test public void testForAndWhile() { List&lt;String&gt; names1 = Lists.newArrayList(&quot;张三&quot;, &quot;李四&quot;); Iterator&lt;String&gt; iterator1= names1.iterator(); while (iterator1.hasNext()) { String name = iterator1.next(); System.out.println(&quot;name1:&quot; + name); iterator1.remove(); } List&lt;String&gt; names2 = Lists.newArrayList(&quot;赵六&quot;, &quot;钱七&quot;); Iterator&lt;String&gt; iterator2= names2.iterator(); while (iterator1.hasNext()) { String name = iterator2.next(); System.out.println(&quot;name2:&quot; + name); iterator2.remove(); } } 这段代码的第二个循环不会打印任何东西，因为while条件中误用了第一个循环中的变量，造成的bug。但是这种bug却不会有任何编译错误和运行时错误，危害甚大。但是只要改成旧版for循环的形式，就可以很好的避免这种错误。 请看如下改进代码： @Test public void testForAndWhile() { List&lt;String&gt; names1 = Lists.newArrayList(&quot;张三&quot;, &quot;李四&quot;); for (Iterator&lt;String&gt; iterator= names1.iterator();iterator.hasNext();) { System.out.println(&quot;name1:&quot;+iterator.next()); iterator.remove(); } List&lt;String&gt; names2 = Lists.newArrayList(&quot;赵六&quot;, &quot;钱七&quot;); for (Iterator&lt;String&gt; iterator= names2.iterator();iterator.hasNext();) { System.out.println(&quot;name2:&quot;+iterator.next()); iterator.remove(); } } 这个时候，如果错误的引用循环1中的代码，会有编译时错误，就可以很好的避免这种问题、]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[关于windows下jetty锁文件的解决办法]]></title>
      <url>%2F2016%2F01%2F06%2Fjetty-lock-file%2F</url>
      <content type="text"><![CDATA[在windows环境中开发，当使用jetty作为容器时，可能会发生修改js、css文件而没有生效，甚至报错的情况。 产生原因这是因为jetty会使用内存映射文件来缓存静态文件，其中就包括js、css文件。而在windows下，使用内存映射文件会导致文件被锁定。 解决方法解决方法很简单，只需要再web.xml文件中配置相应的静态文件不使用内存映射文件来缓存即可： &lt;!--配置使windows下的jetty不锁定文件--&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;default&lt;/servlet-name&gt; &lt;url-pattern&gt;/static/*&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; &lt;servlet&gt; &lt;servlet-name&gt;default&lt;/servlet-name&gt; &lt;init-param&gt; &lt;param-name&gt;useFileMappedBuffer&lt;/param-name&gt; &lt;param-value&gt;false&lt;/param-value&gt; &lt;/init-param&gt; &lt;/servlet&gt;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[java enum的妙用]]></title>
      <url>%2F2015%2F12%2F14%2Fjava-enum%E7%9A%84%E5%A6%99%E7%94%A8%2F</url>
      <content type="text"><![CDATA[java中的枚举，大家应该并不陌生。可enum的特性和用法，可能并不是很了解。enum的出现主要是为了代替public static final的常量的。因为常量有诸多的不便，包括没有命名空间，无法按组隔离，使用容易遗忘，扩展不便，没有编译时错误约束等。于是enum出现了，本文将介绍一些enum巧妙的用法。 enum的特点enum具有以下特点： 单例，java中实现单例最快捷的方式 本质上是一个final类，并且继承java.lang.Enum 可以在switch判断语句上使用enum,但是并不推荐 可以设置具体的枚举值 利用抽象类构造符合开闭原则的代码当我们使用enum的时候，大部分人会用switch语句做判断而实现不同枚举使用不用的逻辑。例如以下一个计算器操作的例子： /** * 计算器操作枚举 * * @author zacard * @since 2015-12-14 10:17 */ public enum Operation { PLUS(&quot;+&quot;), MINUS(&quot;-&quot;), MULTIPLY(&quot;*&quot;), DIVISION(&quot;/&quot;); private String symbol; Operation(String symbol) { this.symbol = symbol; } @Override public String toString() { return symbol; } } /** * 测试 * * @author zacard * @since 2015-12-14 10:12 */ public class MyTest { // 计算 public int apply(Operation operation, int x, int y) { int result; switch (operation) { case PLUS: result = x + y; break; case MINUS: result = x - y; break; case MULTIPLY: result = x * y; break; case DIVISION: result = x / y; break; default: result = 0; break; } return result; } } 这是一个很常见的例子，但是确有极大的隐患。比如计算器操作类增加一个枚举：RADICAL(“√￣”)根号，很多客户端的代码就需要改，而且很容易遗忘，因为没有编译时错误的约束。并且大量的switch case语句使得代码冗余，更不符合开闭原则。 只需要对枚举类稍加改造，增加一个抽象方法，即可改变以上种种的问题，代码如下： /** * 计算器操作枚举 * * @author zacard * @since 2015-12-14 10:17 */ public enum Operation { PLUS(&quot;+&quot;) { @Override public int apply(int x, int y) { return x + y; } }, MINUS(&quot;-&quot;) { @Override public int apply(int x, int y) { return x - y; } }, MULTIPLY(&quot;*&quot;) { @Override public int apply(int x, int y) { return x * y; } }, DIVISION(&quot;/&quot;) { @Override public int apply(int x, int y) { return x / y; } }, // 新增加的操作，开根号 RADICAL(&quot;√￣&quot;) { @Override public int apply(int x, int y) { return (int) Math.sqrt(x); } }; private String symbol; Operation(String symbol) { this.symbol = symbol; } @Override public String toString() { return symbol; } // 计算 public abstract int apply(int x, int y); } /** * 测试 * * @author zacard * @since 2015-12-14 10:12 */ public class MyTest { // 计算 public int apply(Operation operation, int x, int y) { return operation.apply(x, y); } } 当定义了一个抽象方法apply的时候，枚举必须实现这个抽象方法，不然会编译报错，不会造成新增加一个枚举而造成逻辑遗漏的问题。同时，客户端调用的代码页变得异常简单和优雅。 利用接口实现可伸缩的枚举类我们知道枚举本质是继承Enum的类，并且java是单继承的。因此我们可以使用接口，让枚举实现接口，来构建可伸缩的枚举类，代码如下： /** * 计算器操作动作 * * @author Guoqw * @since 2015-12-14 13:09 */ public interface Action { // 计算 int apply(int x, int y); } /** * @author Guoqw * @since 2015-12-14 10:17 */ public enum Operation implements Action { PLUS(&quot;+&quot;) { @Override public int apply(int x, int y) { return x + y; } }, MINUS(&quot;-&quot;) { @Override public int apply(int x, int y) { return x - y; } }, MULTIPLY(&quot;*&quot;) { @Override public int apply(int x, int y) { return x * y; } }, DIVISION(&quot;/&quot;) { @Override public int apply(int x, int y) { return x / y; } }, RADICAL(&quot;√￣&quot;) { @Override public int apply(int x, int y) { return (int) Math.sqrt(x); } }; private String symbol; Operation(String symbol) { this.symbol = symbol; } @Override public String toString() { return symbol; } } 这样的好处是当我们要扩充计算器操作枚举类是，来的很方便，代码如下： /** * 计算器操作扩展类 * * @author Guoqw * @since 2015-12-14 13:13 */ public enum ExtendOperation implements Action { // 倒数 RECIPROCAL(&quot;1/x&quot;) { @Override public int apply(int x, int y) { return 1 / x; } }; private String symbol; ExtendOperation(String symbol) { this.symbol = symbol; } @Override public String toString() { return symbol; } }]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[使用log4jdbc更有效的记录java sql日志]]></title>
      <url>%2F2015%2F09%2F24%2Flog4jdbc20150924%2F</url>
      <content type="text"><![CDATA[Log4jdbc 是一个开源 SQL 日志框架，它使用代理模式实现对常用的 JDBC Driver（ Oracle , Derby , MySQL , PostgreSQL , H2 , HSQLDB , …）操作的拦截，记录真实 SQL ，可以将占位符与参数全部合并在一起显示，方便直接拷贝 SQL 在 MySQL 等客户端直接执行，加快调试速度。 Log4jdbc的特点Log4jdbc具有以下特点: 完全支持 JDBC3 和 JDBC4 配置简单，在大多数情况下，只需要将 JDBC 驱动类改成net.sf.log4jdbc.DriverSpy ，同时将 jdbc:log4jdbc 添加到现有的 JDBC URL 之前，最后配置日志记录的种类即可 将 Prepared Statements 中的绑定参数自动插入到对应的位置。在大多数情况下极大改善了可读性及调试工作 SQL 的耗时信息能被获取从而帮助判断哪些语句执行得过慢，同时这些信息可以被工具识别得到一个关于慢 SQL 的报表 SQL 连接信息也可以获取从而帮助诊断关于连接池或线程的问题 兼容任何 JDBC 驱动，需要 JDK1.4 及以上与 Slf4j1.x 开源软件，使用 Apache 2.0 License 使用步骤决定使用哪个版本的jar包JDK1.5:log4jdbc-log4j2-jdbc3.jar JDK1.6:log4jdbc-log4j2-jdbc4.jar JDK1.7:log4jdbc-log4j2-jdbc4.1.jar JDK1.8:log4jdbc-log4j2-jdbc4.1.jar 将 JAR 包添加进项目这里只介绍maven方式引入 &lt;!--log4jdbc--&gt; &lt;dependency&gt; &lt;groupId&gt;org.bgee.log4jdbc-log4j2&lt;/groupId&gt; &lt;artifactId&gt;log4jdbc-log4j2-jdbc4.1&lt;/artifactId&gt; &lt;version&gt;1.16&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;jcl-over-slf4j&lt;/artifactId&gt; &lt;version&gt;1.7.5&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt; &lt;version&gt;1.7.5&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt; &lt;version&gt;1.7.5&lt;/version&gt; &lt;/dependency&gt; 修改项目的JDBC驱动类#jdbc.driver=com.mysql.jdbc.Driver jdbc.driver=net.sf.log4jdbc.sql.jdbcapi.DriverSpy 将jdbc:log4添加到现有的JDBC URL之前#jdbc.url=jdbc:mysql://127.0.0.1:3306/test?useUnicode=true&amp;amp;characterEncoding=UTF-8 jdbc.url=jdbc:log4jdbc:mysql://127.0.0.1:3306/test?useUnicode=true&amp;amp;characterEncoding=UTF-8 配置日志记录的种类Log4jdbc 用以下几个可以配置的日志种类： jdbc.sqlonly : 仅记录 SQL jdbc.sqltiming ：记录 SQL 以及耗时信息 jdbc.audit ：记录除了 ResultSet 之外的所有 JDBC 调用信息，会产生大量的记录，有利于调试跟踪具体的 JDBC 问题 jdbc.resultset ：会产生更多的记录信息，因为记录了 ResultSet 的信息 jdbc.connection ：记录连接打开、关闭等信息，有利于调试数据库连接相关问题 以上日志种类都可以设置为 DEBUG , INFO 或 ERROR 级别。当设置为 FATAL 或 OFF 时，意味关闭记录。 以下是一个采用 Log4j 作为具体日志系统的典型配置，将这些配置到 log4j.properties 里面： log4j.logger.jdbc.sqlonly=OFF log4j.logger.jdbc.sqltiming=INFO log4j.logger.jdbc.audit=OFF log4j.logger.jdbc.resultset=OFF log4j.logger.jdbc.connection=OFF 添加log4jdbc.log4j2.properties文件这是最后一步，在项目的 CLASSPATH 路径下创建一个 log4jdbc.log4j2.properties 文件，告诉 Log4jdbc-log4j2 使用的是 Slf4j 来记录和打印日志，在该配置文件里增加： log4jdbc.spylogdelegator.name=net.sf.log4jdbc.log.slf4j.Slf4jSpyLogDelegator 运行项目，查看效果]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[反向代理工具ngrok使用说明]]></title>
      <url>%2F2015%2F09%2F17%2Fngrok-use-info%2F</url>
      <content type="text"><![CDATA[由于阿里支付和微信支付需要一个外网网址的回调url，本机测试代码的时候不是很方便。这里因此使用反向代理工具，可以生成一个外网网址，代理本机127.0.0.1和指定端口（包括80）。 经过研究，发现ngrok这个工具使用简单，配置方便且完全免费使用。由于ngrok被墙了，这里国内有人搭建了个类似ngrok的服务：Tunnel 使用说明 配置go语言环境brew install go 安装ngrokbrew install ngrok 运行命令./ngrok -config ngrok.cfg -subdomain [你喜欢的域名] [代理的端口] 例如： ./ngrok -config ngrok.cfg -subdomain zacard 80 查看运行情况出现如下情况： Tunnel Status online 表示代理成功了~]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[使用spring-data-jpa遇到的一个坑]]></title>
      <url>%2F2015%2F09%2F10%2Fspring-data-jpa-hole1%2F</url>
      <content type="text"><![CDATA[项目使用的是mybatis，相比于hibernate，更轻量更简洁。但是有点不好的地方是无法根据entity生成（修改）表。特别是项目丢给测试的时候，开发和测试不是一个数据库。测试往往还要手动根据sql创建一次表。于是考虑在单元测试状态自动生成相关表结构。 方案很显然：spring-data-jpa+hibernate搞定。 配置maven依赖&lt;dependency&gt; &lt;groupId&gt;org.springframework.data&lt;/groupId&gt; &lt;artifactId&gt;spring-data-jpa&lt;/artifactId&gt; &lt;version&gt;1.8.0.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.hibernate&lt;/groupId&gt; &lt;artifactId&gt;hibernate-entitymanager&lt;/artifactId&gt; &lt;version&gt;4.3.10.Final&lt;/version&gt; &lt;/dependency&gt; 配置spring-data-jpa.xml&lt;!-- Jpa Entity Manager 配置 --&gt; &lt;bean id=&quot;entityManagerFactory&quot; class=&quot;org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean&quot;&gt; &lt;property name=&quot;dataSource&quot; ref=&quot;dataSource&quot;/&gt; &lt;property name=&quot;jpaVendorAdapter&quot; ref=&quot;hibernateJpaVendorAdapter&quot;/&gt; &lt;property name=&quot;packagesToScan&quot; value=&quot;com.test.*.entities&quot;/&gt; &lt;property name=&quot;jpaProperties&quot;&gt; &lt;props&gt; &lt;prop key=&quot;hibernate.ejb.naming_strategy&quot;&gt;org.hibernate.cfg.ImprovedNamingStrategy&lt;/prop&gt; &lt;prop key=&quot;hibernate.hbm2ddl.auto&quot;&gt;update&lt;/prop&gt; &lt;/props&gt; &lt;/property&gt; &lt;/bean&gt; &lt;!-- 配置Spring Data的Hibernate接口 --&gt; &lt;bean id=&quot;hibernateJpaVendorAdapter&quot; class=&quot;org.springframework.orm.jpa.vendor.HibernateJpaVendorAdapter&quot;&gt; &lt;property name=&quot;database&quot; value=&quot;MYSQL&quot;/&gt; &lt;property name=&quot;showSql&quot; value=&quot;true&quot;/&gt; &lt;/bean&gt; 测试类package com.test.service; import com.alibaba.fastjson.JSON; import com.test.dao.AccountDao; import com.test.entities.Account; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.test.context.ContextConfiguration; import org.springframework.test.context.testng.AbstractTestNGSpringContextTests; import org.testng.annotations.Test; /** * spring-test with testng * @author zacard * @since 2015-09-10 12:53 */ @ContextConfiguration(locations = {&quot;classpath:spring-data-jpa.xml&quot;, &quot;classpath:spring-services.xml&quot;}) public class NormalServiceTest extends AbstractTestNGSpringContextTests { @Autowired private AccountDao accountDao; //测试MBG生成的代码是否能正确运行和jap生成表 @Test public void testMBG() { Account account = accountDao.selectByPrimaryKey(1); System.out.println(&quot;account json:&quot;+ JSON.toJSONString(account)); } } 输出正常，查看数据库表，也生成了。搞定~]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[关于maven中mybatis-generator的使用]]></title>
      <url>%2F2015%2F09%2F09%2Fmybatis-generator%2F</url>
      <content type="text"><![CDATA[之前生成mybatis对应的entity、dao、dao.xml啊都是自己写了一套gui工具生成的。感觉还挺好用的。就是通用性不是很强 = =! 今儿偶尔发现原来官方有生成工具，还挺强大的（可惜没有gui啊）。果断试用下（只试验在maven下的使用）。 ps：参考的官网 操作步骤在pom.xml中添加MBG的插件配置&lt;!--mybatis-generator--&gt; &lt;plugin&gt; &lt;groupId&gt;org.mybatis.generator&lt;/groupId&gt; &lt;artifactId&gt;mybatis-generator-maven-plugin&lt;/artifactId&gt; &lt;version&gt;1.3.0&lt;/version&gt; &lt;configuration&gt; &lt;!--配置文件路径--&gt; &lt;configurationFile&gt;${basedir}/src/main/resources/mybatis/generatorConfig.xml&lt;/configurationFile&gt; &lt;!--打印日志--&gt; &lt;verbose&gt;true&lt;/verbose&gt; &lt;!--覆盖存在的文件--&gt; &lt;overwrite&gt;true&lt;/overwrite&gt; &lt;/configuration&gt; &lt;/plugin&gt; 添加generatorConfig.xml&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt; &lt;!DOCTYPE generatorConfiguration PUBLIC &quot;-//mybatis.org//DTD MyBatis Generator Configuration 1.0//EN&quot; &quot;http://mybatis.org/dtd/mybatis-generator-config_1_0.dtd&quot; &gt; &lt;generatorConfiguration&gt; &lt;!-- Class Driver Path --&gt; &lt;classPathEntry location=&quot;/xxx/mysql-connector-java-5.1.35.jar&quot;/&gt; &lt;context id=&quot;context&quot; targetRuntime=&quot;MyBatis3&quot;&gt; &lt;commentGenerator&gt; &lt;!-- This property is used to specify whether MBG will include any coments in the generated code --&gt; &lt;property name=&quot;suppressAllComments&quot; value=&quot;false&quot;/&gt; &lt;!-- This property is used to specify whether MBG will include the generation timestamp in the generated comments --&gt; &lt;property name=&quot;suppressDate&quot; value=&quot;true&quot;/&gt; &lt;/commentGenerator&gt; &lt;jdbcConnection driverClass=&quot;com.mysql.jdbc.Driver&quot; connectionURL=&quot;jdbc:mysql://127.0.0.1:3306/test?useUnicode=true&amp;amp;characterEncoding=UTF-8&quot; userId=&quot;test&quot; password=&quot;123456&quot;/&gt; &lt;javaTypeResolver&gt; &lt;!-- This property is used to specify whether MyBatis Generator should force the use of java.math.BigDecimal for DECIMAL and NUMERIC fields, rather than substituting integral types when possible --&gt; &lt;property name=&quot;forceBigDecimals&quot; value=&quot;false&quot;/&gt; &lt;/javaTypeResolver&gt; &lt;javaModelGenerator targetPackage=&quot;com.xkeshi.entities&quot; targetProject=&quot;src/main/java&quot;&gt; &lt;!-- This property is used to select whether MyBatis Generator will generate different Java packages for the objects based on the catalog and schema of the introspected table --&gt; &lt;property name=&quot;enableSubPackages&quot; value=&quot;false&quot;/&gt; &lt;!-- This property is used to select whether MyBatis Generator adds code to trim the white space from character fields returned from the database --&gt; &lt;property name=&quot;trimStrings&quot; value=&quot;false&quot;/&gt; &lt;!-- 是否对model添加 构造函数 --&gt; &lt;property name=&quot;constructorBased&quot; value=&quot;true&quot;/&gt; &lt;/javaModelGenerator&gt; &lt;sqlMapGenerator targetPackage=&quot;com.xkeshi.dao&quot; targetProject=&quot;src/main/resources&quot;&gt; &lt;!-- This property is used to select whether MyBatis Generator will generate different Java packages for the objects based on the catalog and schema of the introspected table --&gt; &lt;property name=&quot;enableSubPackages&quot; value=&quot;false&quot;/&gt; &lt;/sqlMapGenerator&gt; &lt;javaClientGenerator targetPackage=&quot;com.xkeshi.dao&quot; targetProject=&quot;src/main/java&quot; type=&quot;XMLMAPPER&quot;&gt; &lt;!-- This property is used to select whether MyBatis Generator will generate different Java packages for the objects based on the catalog and schema of the introspected table --&gt; &lt;property name=&quot;enableSubPackages&quot; value=&quot;false&quot;/&gt; &lt;/javaClientGenerator&gt; &lt;table tableName=&quot;account&quot; enableCountByExample=&quot;false&quot; enableDeleteByExample=&quot;false&quot; enableSelectByExample=&quot;false&quot; enableUpdateByExample=&quot;false&quot;&gt; &lt;!--insert时id设置--&gt; &lt;generatedKey column=&quot;id&quot; sqlStatement=&quot;MySql&quot; identity=&quot;true&quot; type=&quot;pre&quot;/&gt; &lt;/table&gt; &lt;/context&gt; &lt;/generatorConfiguration&gt; 输入命令运行1$ mvn mybatis-generator:generate -e 这里-e参数是为了输出错误信息，方便排查问题。看到“BUILD SUCCESS”表示成功生成了~]]></content>
    </entry>

    
  
  
</search>
